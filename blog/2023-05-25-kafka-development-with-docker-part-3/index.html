<!doctype html><html class=position-relative itemscope itemtype=https://schema.org/WebPage lang=en data-bs-theme=light data-palette=blue-gray><head><script src=/assets/init/bundle.min.99cb2d6502b2c6f5d76f21079aa7b7ea5ad83125c684ac755e2a5af62cc7ad71.js integrity="sha256-mcstZQKyxvXXbyEHmqe36lrYMSXGhKx1Xipa9izHrXE=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Kafka Development with Docker - Part 3 Kafka Connect - Jaehyeon Kim</title>
<link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_16x16_resize_q75_h2_box_2.webp sizes=16x16 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_32x32_resize_q75_h2_box_2.webp sizes=32x32 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_150x150_resize_q75_h2_box_2.webp sizes=150x150 type=image/webp><link rel=apple-touch-icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_180x180_resize_q75_h2_box_2.webp sizes=180x180 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_192x192_resize_q75_h2_box_2.webp sizes=192x192 type=image/webp><link rel=mask-icon href=/safari-pinned-tab.svg color=#6f42c1><meta name=keywords content="Analytics,Real-time Analytics,Data Engineering,Data Streaming,Architecture"><meta name=description content="Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. In this post, I will illustrate how to set up a data ingestion pipeline using Kafka connectors. Fake customer and order data will be ingested into the corresponding topics using the MSK Data Generator source connector. The topic messages will then be saved into a S3 bucket using the Confluent S3 sink connector."><meta name=robots content="index, follow"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jaehyeon.me/blog/2023-05-25-kafka-development-with-docker-part-3/featured.png"><meta name=twitter:title content="Kafka Development with Docker - Part 3 Kafka Connect"><meta name=twitter:description content="Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. In this post, I will illustrate how to set up a data ingestion pipeline using Kafka connectors. Fake customer and order data will be ingested into the corresponding topics using the MSK Data Generator source connector. The topic messages will then be saved into a S3 bucket using the Confluent S3 sink connector."><meta property="og:title" content="Kafka Development with Docker - Part 3 Kafka Connect"><meta property="og:description" content="Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. In this post, I will illustrate how to set up a data ingestion pipeline using Kafka connectors. Fake customer and order data will be ingested into the corresponding topics using the MSK Data Generator source connector. The topic messages will then be saved into a S3 bucket using the Confluent S3 sink connector."><meta property="og:type" content="article"><meta property="og:url" content="https://jaehyeon.me/blog/2023-05-25-kafka-development-with-docker-part-3/"><meta property="og:image" content="https://jaehyeon.me/blog/2023-05-25-kafka-development-with-docker-part-3/featured.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2023-05-25T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-19T05:01:35+09:00"><meta itemprop=name content="Kafka Development with Docker - Part 3 Kafka Connect"><meta itemprop=description content="Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. In this post, I will illustrate how to set up a data ingestion pipeline using Kafka connectors. Fake customer and order data will be ingested into the corresponding topics using the MSK Data Generator source connector. The topic messages will then be saved into a S3 bucket using the Confluent S3 sink connector."><meta itemprop=datePublished content="2023-05-25T00:00:00+00:00"><meta itemprop=dateModified content="2023-07-19T05:01:35+09:00"><meta itemprop=wordCount content="1718"><meta itemprop=image content="https://jaehyeon.me/blog/2023-05-25-kafka-development-with-docker-part-3/featured.png"><meta itemprop=keywords content="Apache Kafka,Kafka Connect,Docker,Docker Compose,"><link rel=manifest href=/manifest.json><script async src="https://www.googletagmanager.com/gtag/js?id=G-076N8WCGWZ"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-076N8WCGWZ",{anonymize_ip:!1})}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2764466088407958"></script><link data-precache rel=stylesheet href="/assets/main/bundle.min.dc910a9364ba50e03d47ecf493e01f798a7ff46d1f793a172c8412e0c9867284.css" integrity="sha256-3JEKk2S6UOA9R+z0k+AfeYp/9G0feToXLIQS4MmGcoQ=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/katex/bundle.min.a06a916255e286562e9c3684403a944bb85aebe51b00e2f1ef537987349ead12.css integrity="sha256-oGqRYlXihlYunDaEQDqUS7ha6+UbAOLx71N5hzSerRI=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/viewer/bundle.min.8c1002839fa22c1350d6ae1eef6593120e108f973c41348be9b5065430566aaf.css integrity="sha256-jBACg5+iLBNQ1q4e72WTEg4Qj5c8QTSL6bUGVDBWaq8=" crossorigin=anonymous></head><body><header class="mb-4 sticky-top"><nav class="top-app-bar shadow navbar navbar-expand-xxl"><div class=container><a class="navbar-brand d-flex align-items-center flex-grow-1 flex-xxl-grow-0 justify-content-xxl-start ms-2 ms-xxl-0 mx-auto me-xxl-2" href=https://jaehyeon.me/>Jaehyeon Kim</a><div class="offcanvas-xxl offcanvas-end flex-grow-1" data-bs-scroll=true tabindex=-1 id=navbarMenus aria-labelledby=navbarMenusLabel><div class="offcanvas-header px-4 pb-0"><div class="offcanvas-title h5" id=navbarMenusLabel>Jaehyeon Kim</div><button type=button class="btn-close btn-close-white" data-bs-dismiss=offcanvas data-bs-target=#navbarMenus aria-label=Close></button></div><div class="offcanvas-body p-4 pt-0 p-xxl-0"><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center me-auto"><li class="nav-item col-12 col-xxl-auto dropdown px-0"><a href=# class="nav-link dropdown-toggle" id=navbarDropdownBlog role=button data-bs-toggle=dropdown aria-expanded=false><span class="menu-icon me-1"><i class="fas fa-fw fa-blog text-warning"></i></span>Blog</a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=navbarDropdownBlog data-bs-popper=none><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/archives/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-file-archive text-primary"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-0">Archives</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/series/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Series</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/series/_index.zh-cn/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">专栏</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/categories/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Categories</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/categories/_index.zh-cn/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">分类</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/tags/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Tags</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/tags/_index.zh-cn/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">标签</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li></ul></li></ul><hr class=d-xxl-none><form class="search-bar ms-auto my-auto" action=/search/ novalidate><div class="input-group align-items-center"><span class="btn btn-search disabled position-absolute left-0 border-0 px-1"><i class="fas fa-fw fa-search fa-lg"></i>
</span><input class="my-1 form-control border-white rounded-5 search-input bg-body" name=q type=search placeholder=Search aria-label=Search required>
<span class="search-shortcut position-absolute end-0 top-0 me-2"><kbd class="text-dark bg-white opacity-75 rounded-3 shadow border border-primary py-1 fw-bold">/</kbd></span></div></form><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center ms-md-auto"><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><nav class="social-links nav justify-content-center flex-row"><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fab fa-github"></i>
<span class="ms-1 d-xxl-none">Github</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fab fa-linkedin-in"></i>
<span class="ms-1 d-xxl-none">Linkedin</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fab fa-paypal"></i>
<span class="ms-1 d-xxl-none">Paypal</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-rss"></i>
<span class="ms-1 d-xxl-none">RSS</span></a></nav></li><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><div class="vr d-none d-xxl-flex h-100 mx-xxl-2 text-white"></div><hr class="d-xxl-none my-2"></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=fontSizeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-font"></i>
<span class=d-xxl-none>Font Size</span></a><ul class="font-size-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=fontSizeDropdown><li><button class="font-size-item dropdown-item" data-size=xs>
Extra Small</button></li><li><button class="font-size-item dropdown-item" data-size=sm>
Small</button></li><li><button class="font-size-item dropdown-item active" data-size=md>
Medium</button></li><li><button class="font-size-item dropdown-item" data-size=lg>
Large</button></li><li><button class="font-size-item dropdown-item" data-size=xl>
Extra Large</button></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=paletteDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-palette"></i>
<span class=d-xxl-none>Palette</span></a><ul class="palette-dropdown-menu dropdown-menu dropdown-menu-end px-2 row g-2" aria-labelledby=paletteDropdown><li class="col-4 my-1"><a role=button id=palette-blue aria-label=Blue class="btn btn-sm w-100 palette text-bg-blue" data-palette=blue></a></li><li class="col-4 my-1"><a role=button id=palette-blue-gray aria-label="Blue Gray" class="btn btn-sm w-100 palette text-bg-blue-gray" data-palette=blue-gray></a></li><li class="col-4 my-1"><a role=button id=palette-brown aria-label=Brown class="btn btn-sm w-100 palette text-bg-brown" data-palette=brown></a></li><li class="col-4 my-1"><a role=button id=palette-cyan aria-label=Cyan class="btn btn-sm w-100 palette text-bg-cyan" data-palette=cyan></a></li><li class="col-4 my-1"><a role=button id=palette-green aria-label=Green class="btn btn-sm w-100 palette text-bg-green" data-palette=green></a></li><li class="col-4 my-1"><a role=button id=palette-indigo aria-label=Indigo class="btn btn-sm w-100 palette text-bg-indigo" data-palette=indigo></a></li><li class="col-4 my-1"><a role=button id=palette-orange aria-label=Orange class="btn btn-sm w-100 palette text-bg-orange" data-palette=orange></a></li><li class="col-4 my-1"><a role=button id=palette-pink aria-label=Pink class="btn btn-sm w-100 palette text-bg-pink" data-palette=pink></a></li><li class="col-4 my-1"><a role=button id=palette-purple aria-label=Purple class="btn btn-sm w-100 palette text-bg-purple" data-palette=purple></a></li><li class="col-4 my-1"><a role=button id=palette-red aria-label=Red class="btn btn-sm w-100 palette text-bg-red" data-palette=red></a></li><li class="col-4 my-1"><a role=button id=palette-teal aria-label=Teal class="btn btn-sm w-100 palette text-bg-teal" data-palette=teal></a></li><li class="col-4 my-1"><a role=button id=palette-yellow aria-label=Yellow class="btn btn-sm w-100 palette text-bg-yellow" data-palette=yellow></a></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=modeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="mode-icon fas fa-fw fa-sun" id=modeIcon></i>
<span class=d-xxl-none>Mode</span></a><ul class="mode-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=modeDropdown><li class="mode-item active" data-color-mode=light data-icon=sun><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-sun"></i> Light</button></li><li class=mode-item data-color-mode=dark data-icon=moon><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-moon"></i> Dark</button></li><li class=mode-item data-color-mode=auto data-icon=adjust><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-adjust"></i> Auto</button></li></ul></li></ul></div></div><div class=d-flex><button class="navbar-toggler order-5 border-0" type=button data-bs-toggle=offcanvas data-bs-target=#navbarMenus aria-controls=navbarMenus aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-h"></i></button></div></div></nav></header><main class=container><div class="row content"><noscript><div class="alert alert-danger" role=alert>Your browser does not support JavaScript.</div></noscript><div class=col-xxl-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class="card-body pb-0"><ol class="hbs-breadcrumb breadcrumb flex-nowrap"><li class="breadcrumb-item text-surface"><a href=/>Home</a></li><li class="breadcrumb-item text-surface"><a href=/blog/>Blogs</a></li><li class="breadcrumb-item active">Kafka Development With Docker - Part 3 Kafka Connect</li></ol></div></nav><div class="post-panel-wrapper position-relative d-flex justify-content-center"><div class="d-flex flex-row justify-content-center rounded-5 border post-panel position-fixed px-3 py-1 surface shadow-1"><a class="action action-toc d-none d-xxl-block" href=#postTOC role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-toc d-block d-xxl-none" href=#post-toc-container role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-post-comments" href=#post-comments role=button aria-label=Comments title=Comments><i class="fas fa-fw fa-comments"></i>
</a><a id=sidebarToggler class="action action-sidebar-toggler d-none d-xxl-block" role=button title="Toggle sidebar"><i class="fas fa-fw fa-expand-alt" data-fa-transform=rotate-45></i></a></div></div><article class="row card component mb-4 post"><div class=card-header><h1 class="card-title post-title my-2">Kafka Development With Docker - Part 3 Kafka Connect</h1></div><div class=card-body><div class="post-meta mb-3"><span class="post-date me-1 mb-1" title="created on 2023-05-25 00:00:00 +0000 UTC, updated on 2023-07-18 20:01:35 +0000 UTC.">May 25, 2023</span><span class="post-reading-time me-1 mb-1">9 min read</span><a href=/categories/apache-kafka/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-category">
<i class="fas fa-fw fa-folder me-1"></i>Apache Kafka</a><a href=/series/kafka-development-with-docker/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-series">
<i class="fas fa-fw fa-columns me-1"></i>Kafka Development With Docker</a><a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Kafka</a><a href=/tags/docker/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Docker</a><a href=/tags/docker-compose/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Docker Compose</a><a href=/tags/kafka-connect/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Kafka Connect</a></div><picture class="d-flex justify-content-center"><source srcset=/blog/2023-05-25-kafka-development-with-docker-part-3/featured_hu7953614f0ee63f59b300b3ecccd65289_69998_0x270_resize_box_3.png type=image/png media="(max-width: 576px)" width=496 height=270><img class="post-featured-img h-auto w-auto mb-3" alt="Kafka Development with Docker - Part 3 Kafka Connect" src=/blog/2023-05-25-kafka-development-with-docker-part-3/featured_hu7953614f0ee63f59b300b3ecccd65289_69998_0x480_resize_box_3.png width=881 height=480 data-src=/blog/2023-05-25-kafka-development-with-docker-part-3/featured.png></picture><p class="lead mb-3 text-body-emphasis">Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. In this post, I will illustrate how to set up a data ingestion pipeline using Kafka connectors. Fake customer and order data will be ingested into the corresponding topics using the MSK Data Generator source connector. The topic messages will then be saved into a S3 bucket using the Confluent S3 sink connector.</p><div id=postTOC class="mb-3 text-surface"><h2 class=mb-3>Contents<a class="anchor ms-1" href=#postTOC></a></h2><nav id=TableOfContents><ul><li><a href=#kafka-connect-setup>Kafka Connect Setup</a><ul><li><a href=#connect-properties-file>Connect Properties File</a></li><li><a href=#download-connectors>Download Connectors</a></li></ul></li><li><a href=#start-docker-compose-services>Start Docker Compose Services</a></li><li><a href=#source-connector-creation>Source Connector Creation</a><ul><li><a href=#kafka-topics>Kafka Topics</a></li></ul></li><li><a href=#sink-connector-creation>Sink Connector Creation</a><ul><li><a href=#kafka-consumers>Kafka Consumers</a></li><li><a href=#s3-destination>S3 Destination</a></li></ul></li><li><a href=#summary>Summary</a></li></ul></nav><hr class=text-secondary></div><div class="post-content mb-3" data-bs-spy=scroll data-bs-target=#TableOfContents tabindex=0><div id=post-content-body><p>According to the documentation of <a href=https://kafka.apache.org/documentation/#connect target=_blank rel="noopener noreferrer">Apache Kafka<i class="fas fa-external-link-square-alt ms-1"></i></a>, <em>Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. It makes it simple to quickly define connectors that move large collections of data into and out of Kafka</em>. Kafka Connect supports two types of connectors - source and sink. Source connectors are used to ingest messages from external systems into Kafka topics while messages are ingested into external systems form Kafka topics with sink connectors. In this post, I will illustrate how to set up a data ingestion pipeline using Kafka connectors. Fake customer and order data will be ingested into the corresponding topics using the <a href=https://github.com/awslabs/amazon-msk-data-generator target=_blank rel="noopener noreferrer">MSK Data Generator<i class="fas fa-external-link-square-alt ms-1"></i></a> source connector. The topic messages will then be saved into a S3 bucket using the <a href=https://www.confluent.io/hub/confluentinc/kafka-connect-s3 target=_blank rel="noopener noreferrer">Confluent S3<i class="fas fa-external-link-square-alt ms-1"></i></a> sink connector.</p><ul><li><a href=/blog/2023-05-04-kafka-development-with-docker-part-1>Part 1 Cluster Setup</a></li><li><a href=/blog/2023-05-18-kafka-development-with-docker-part-2>Part 2 Management App</a></li><li><a href=/blog/2023-05-25-kafka-development-with-docker-part-3/#>Part 3 Kafka Connect</a> (this post)</li><li><a href=/blog/2023-06-01-kafka-development-with-docker-part-4>Part 4 Producer and Consumer</a></li><li><a href=/blog/2023-06-08-kafka-development-with-docker-part-5>Part 5 Glue Schema Registry</a></li><li><a href=/blog/2023-06-15-kafka-development-with-docker-part-6>Part 6 Kafka Connect with Glue Schema Registry</a></li><li><a href=/blog/2023-06-22-kafka-development-with-docker-part-7>Part 7 Producer and Consumer with Glue Schema Registry</a></li><li><a href=/blog/2023-06-29-kafka-development-with-docker-part-8>Part 8 SSL Encryption</a></li><li><a href=/blog/2023-07-06-kafka-development-with-docker-part-9>Part 9 SSL Authentication</a></li><li><a href=/blog/2023-07-13-kafka-development-with-docker-part-10>Part 10 SASL Authentication</a></li><li><a href=/blog/2023-07-20-kafka-development-with-docker-part-11>Part 11 Kafka Authorization</a></li></ul><h2 id=kafka-connect-setup data-numberify>Kafka Connect Setup<a class="anchor ms-1" href=#kafka-connect-setup></a></h2><p>We can use the same Docker image because <em>Kafka Connect</em> is included in the Kafka distribution. The Kafka Connect server runs as a separate docker compose service, and its key configurations are listed below.</p><ul><li>We&rsquo;ll run it as the <a href=https://docs.confluent.io/platform/current/connect/concepts.html#distributed-workers target=_blank rel="noopener noreferrer">distributed mode<i class="fas fa-external-link-square-alt ms-1"></i></a>, and it can be started by executing <em>connect-distributed.sh</em> on the Docker command.<ul><li>The startup script requires the properties file (<em>connect-distributed.properties</em>). It includes configurations such as Kafka broker server addresses - see below for details.</li></ul></li><li>The Connect server is accessible on port 8083, and we can manage connectors via a REST API as demonstrated below.</li><li>The properties file and connector sources are volume-mapped.</li><li>AWS credentials are added to environment variables as the sink connector requires permission to write data into S3.</li></ul><p>The source can be found in the <a href=https://github.com/jaehyeon-kim/kafka-pocs/tree/main/kafka-dev-with-docker/part-03 target=_blank rel="noopener noreferrer"><strong>GitHub repository</strong><i class="fas fa-external-link-square-alt ms-1"></i></a> of this post.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=ln> 1</span><span class=cl><span class=c># /kafka-dev-with-docker/part-03/compose-connect.yml</span><span class=w>
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=w></span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;3.5&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln> 3</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=w>  </span><span class=nt>kafka-connect</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 6</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/kafka:2.8.1</span><span class=w>
</span></span></span><span class=line><span class=ln> 7</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>connect</span><span class=w>
</span></span></span><span class=line><span class=ln> 8</span><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=p>&gt;</span><span class=sd>
</span></span></span><span class=line><span class=ln> 9</span><span class=cl><span class=sd>      /opt/bitnami/kafka/bin/connect-distributed.sh
</span></span></span><span class=line><span class=ln>10</span><span class=cl><span class=sd>      /opt/bitnami/kafka/config/connect-distributed.properties</span><span class=w>      
</span></span></span><span class=line><span class=ln>11</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>12</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;8083:8083&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>13</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=w>      </span>- <span class=l>kafkanet</span><span class=w>
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>16</span><span class=cl><span class=w>      </span><span class=nt>AWS_ACCESS_KEY_ID</span><span class=p>:</span><span class=w> </span><span class=l>$AWS_ACCESS_KEY_ID</span><span class=w>
</span></span></span><span class=line><span class=ln>17</span><span class=cl><span class=w>      </span><span class=nt>AWS_SECRET_ACCESS_KEY</span><span class=p>:</span><span class=w> </span><span class=l>$AWS_SECRET_ACCESS_KEY</span><span class=w>
</span></span></span><span class=line><span class=ln>18</span><span class=cl><span class=w>      </span><span class=nt>AWS_SESSION_TOKEN</span><span class=p>:</span><span class=w> </span><span class=l>$AWS_SESSION_TOKEN</span><span class=w>
</span></span></span><span class=line><span class=ln>19</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>20</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;./configs/connect-distributed.properties:/opt/bitnami/kafka/config/connect-distributed.properties&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>21</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;./connectors/confluent-s3/lib:/opt/connectors/confluent-s3&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>22</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;./connectors/msk-datagen:/opt/connectors/msk-datagen&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>23</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln>24</span><span class=cl><span class=w></span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>25</span><span class=cl><span class=w>  </span><span class=nt>kafkanet</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>26</span><span class=cl><span class=w>    </span><span class=nt>external</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=ln>27</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-network</span><span class=w>
</span></span></span></code></pre></div><h3 id=connect-properties-file data-numberify>Connect Properties File<a class="anchor ms-1" href=#connect-properties-file></a></h3><p>The properties file includes configurations of the Connect server. Below shows key config values.</p><ul><li>Bootstrap Server<ul><li>I changed the Kafka bootstrap server addresses. As it shares the same Docker network, we can take the service names (e.g. <em>kafka-0</em>) on port 9092.</li></ul></li><li>Cluster group id<ul><li>In distributed mode, multiple worker processes use the same <em>group.id</em>, and they automatically coordinate to schedule execution of connectors and tasks across all available workers.</li></ul></li><li>Converter-related properties<ul><li>Converters are necessary to have a Kafka Connect deployment support a particular data format when writing to or reading from Kafka.</li><li>By default, <em>org.apache.kafka.connect.json.JsonConverter</em> is set for both the key and value converters and schemas are enabled for both of them.</li><li>As shown later, these properties can be overridden when creating a connector.</li></ul></li><li>Topics for offsets, configs, status<ul><li>Several topics are created to manage connectors by multiple worker processes.</li></ul></li><li>Plugin path<ul><li>Paths that contains plugins (connectors, converters, transformations) can be set to a list of filesystem paths separated by commas (,)</li><li><code>/opt/connectors</code> is added and connector sources will be volume-mapped to it.</li></ul></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-java-properties data-lang=java-properties><span class=line><span class=ln> 1</span><span class=cl><span class=c1># kafka-dev-with-docker/part-03/configs/connect-distributed.properties</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl>
</span></span><span class=line><span class=ln> 3</span><span class=cl><span class=c1># A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=na>bootstrap.servers</span><span class=o>=</span><span class=s>kafka-0:9092,kafka-1:9092,kafka-2:9092</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>
</span></span><span class=line><span class=ln> 6</span><span class=cl><span class=c1># unique name for the cluster, used in forming the Connect cluster group. Note that this must not conflict with consumer group IDs</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl><span class=na>group.id</span><span class=o>=</span><span class=s>connect-cluster</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>
</span></span><span class=line><span class=ln> 9</span><span class=cl><span class=c1># The converters specify the format of data in Kafka and how to translate it into Connect data. Every Connect user will</span>
</span></span><span class=line><span class=ln>10</span><span class=cl><span class=c1># need to configure these based on the format they want their data in when loaded from or stored into Kafka</span>
</span></span><span class=line><span class=ln>11</span><span class=cl><span class=na>key.converter</span><span class=o>=</span><span class=s>org.apache.kafka.connect.json.JsonConverter</span>
</span></span><span class=line><span class=ln>12</span><span class=cl><span class=na>value.converter</span><span class=o>=</span><span class=s>org.apache.kafka.connect.json.JsonConverter</span>
</span></span><span class=line><span class=ln>13</span><span class=cl><span class=c1># Converter-specific settings can be passed in by prefixing the Converter&#39;s setting with the converter we want to apply</span>
</span></span><span class=line><span class=ln>14</span><span class=cl><span class=c1># it to</span>
</span></span><span class=line><span class=ln>15</span><span class=cl><span class=na>key.converter.schemas.enable</span><span class=o>=</span><span class=s>true</span>
</span></span><span class=line><span class=ln>16</span><span class=cl><span class=na>value.converter.schemas.enable</span><span class=o>=</span><span class=s>true</span>
</span></span><span class=line><span class=ln>17</span><span class=cl>
</span></span><span class=line><span class=ln>18</span><span class=cl><span class=c1># Topic to use for storing offsets.</span>
</span></span><span class=line><span class=ln>19</span><span class=cl><span class=na>offset.storage.topic</span><span class=o>=</span><span class=s>connect-offsets</span>
</span></span><span class=line><span class=ln>20</span><span class=cl><span class=na>offset.storage.replication.factor</span><span class=o>=</span><span class=s>1</span>
</span></span><span class=line><span class=ln>21</span><span class=cl><span class=c1>#offset.storage.partitions=25</span>
</span></span><span class=line><span class=ln>22</span><span class=cl>
</span></span><span class=line><span class=ln>23</span><span class=cl><span class=c1># Topic to use for storing connector and task configurations.</span>
</span></span><span class=line><span class=ln>24</span><span class=cl><span class=na>config.storage.topic</span><span class=o>=</span><span class=s>connect-configs</span>
</span></span><span class=line><span class=ln>25</span><span class=cl><span class=na>config.storage.replication.factor</span><span class=o>=</span><span class=s>1</span>
</span></span><span class=line><span class=ln>26</span><span class=cl>
</span></span><span class=line><span class=ln>27</span><span class=cl><span class=c1># Topic to use for storing statuses. </span>
</span></span><span class=line><span class=ln>28</span><span class=cl><span class=na>status.storage.topic</span><span class=o>=</span><span class=s>connect-status</span>
</span></span><span class=line><span class=ln>29</span><span class=cl><span class=na>status.storage.replication.factor</span><span class=o>=</span><span class=s>1</span>
</span></span><span class=line><span class=ln>30</span><span class=cl><span class=c1>#status.storage.partitions=5</span>
</span></span><span class=line><span class=ln>31</span><span class=cl>
</span></span><span class=line><span class=ln>32</span><span class=cl><span class=err>...</span>
</span></span><span class=line><span class=ln>33</span><span class=cl>
</span></span><span class=line><span class=ln>34</span><span class=cl><span class=c1># Set to a list of filesystem paths separated by commas (,) to enable class loading isolation for plugins</span>
</span></span><span class=line><span class=ln>35</span><span class=cl><span class=c1># (connectors, converters, transformations).</span>
</span></span><span class=line><span class=ln>36</span><span class=cl><span class=na>plugin.path</span><span class=o>=</span><span class=s>/opt/connectors</span>
</span></span></code></pre></div><h3 id=download-connectors data-numberify>Download Connectors<a class="anchor ms-1" href=#download-connectors></a></h3><p>The connector sources need to be downloaded into the respective host paths (<code>./connectors/confluent-s3</code> and <code>./connectors/msk-datagen</code>) so that they are volume-mapped to the container&rsquo;s plugin path (<code>/opt/connectors</code>). The following script downloads them into the host paths.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl><span class=c1># /kafka-dev-with-docker/part-03/download.sh</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1>#!/usr/bin/env bash</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl><span class=nv>SCRIPT_DIR</span><span class=o>=</span><span class=s2>&#34;</span><span class=k>$(</span><span class=nb>cd</span> <span class=k>$(</span>dirname <span class=s2>&#34;</span><span class=nv>$0</span><span class=s2>&#34;</span><span class=k>)</span><span class=p>;</span> <span class=nb>pwd</span><span class=k>)</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl>
</span></span><span class=line><span class=ln> 5</span><span class=cl><span class=nv>SRC_PATH</span><span class=o>=</span><span class=si>${</span><span class=nv>SCRIPT_DIR</span><span class=si>}</span>/connectors
</span></span><span class=line><span class=ln> 6</span><span class=cl>rm -rf <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span> <span class=o>&amp;&amp;</span> mkdir -p <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span>/msk-datagen
</span></span><span class=line><span class=ln> 7</span><span class=cl>
</span></span><span class=line><span class=ln> 8</span><span class=cl><span class=c1>## Confluent S3 Sink Connector</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl><span class=nb>echo</span> <span class=s2>&#34;downloading confluent s3 connector...&#34;</span>
</span></span><span class=line><span class=ln>10</span><span class=cl><span class=nv>DOWNLOAD_URL</span><span class=o>=</span>https://d1i4a15mxbxib1.cloudfront.net/api/plugins/confluentinc/kafka-connect-s3/versions/10.4.3/confluentinc-kafka-connect-s3-10.4.3.zip
</span></span><span class=line><span class=ln>11</span><span class=cl>
</span></span><span class=line><span class=ln>12</span><span class=cl>curl -o <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span>/confluent.zip <span class=si>${</span><span class=nv>DOWNLOAD_URL</span><span class=si>}</span> <span class=se>\
</span></span></span><span class=line><span class=ln>13</span><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> unzip -qq <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span>/confluent.zip -d <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span> <span class=se>\
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> rm <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span>/confluent.zip <span class=se>\
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> mv <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span>/<span class=k>$(</span>ls <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span> <span class=p>|</span> grep confluentinc-kafka-connect-s3<span class=k>)</span> <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span>/confluent-s3
</span></span><span class=line><span class=ln>16</span><span class=cl>
</span></span><span class=line><span class=ln>17</span><span class=cl><span class=c1>## MSK Data Generator Souce Connector</span>
</span></span><span class=line><span class=ln>18</span><span class=cl><span class=nb>echo</span> <span class=s2>&#34;downloading msk data generator...&#34;</span>
</span></span><span class=line><span class=ln>19</span><span class=cl><span class=nv>DOWNLOAD_URL</span><span class=o>=</span>https://github.com/awslabs/amazon-msk-data-generator/releases/download/v0.4.0/msk-data-generator-0.4-jar-with-dependencies.jar
</span></span><span class=line><span class=ln>20</span><span class=cl>
</span></span><span class=line><span class=ln>21</span><span class=cl>curl -L -o <span class=si>${</span><span class=nv>SRC_PATH</span><span class=si>}</span>/msk-datagen/msk-data-generator.jar <span class=si>${</span><span class=nv>DOWNLOAD_URL</span><span class=si>}</span>
</span></span></code></pre></div><p>Below shows the folder structure after the connectors are downloaded successfully.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl>$ tree connectors/ -d
</span></span><span class=line><span class=ln> 2</span><span class=cl>connectors/
</span></span><span class=line><span class=ln> 3</span><span class=cl>├── confluent-s3
</span></span><span class=line><span class=ln> 4</span><span class=cl>│   ├── assets
</span></span><span class=line><span class=ln> 5</span><span class=cl>│   ├── doc
</span></span><span class=line><span class=ln> 6</span><span class=cl>│   │   ├── licenses
</span></span><span class=line><span class=ln> 7</span><span class=cl>│   │   └── notices
</span></span><span class=line><span class=ln> 8</span><span class=cl>│   ├── etc
</span></span><span class=line><span class=ln> 9</span><span class=cl>│   └── lib
</span></span><span class=line><span class=ln>10</span><span class=cl>└── msk-datagen
</span></span></code></pre></div><h2 id=start-docker-compose-services data-numberify>Start Docker Compose Services<a class="anchor ms-1" href=#start-docker-compose-services></a></h2><p>There are 3 docker compose files for the Kafka cluster, Kafka Connect and management applications. We can run the whole services by starting them in order. The order matters as the Connect server relies on the Kafka cluster and <em>kpow</em> in <em>compose-ui.yml</em> fails if the Connect server is not up and running. Note the Connect server address is added to both the Kafka management apps in <em>compose-ui.yml</em>, and we are able to monitor and manage connectors on them.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl>$ <span class=nb>cd</span> kafka-dev-with-docker/part-03
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1># download connectors</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>$ ./download.sh
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=c1># starts 3 node kafka cluster</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>$ docker-compose -f compose-kafka.yml up -d
</span></span><span class=line><span class=ln> 6</span><span class=cl><span class=c1># starts kafka connect server in distributed mode</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>$ docker-compose -f compose-connect.yml up -d
</span></span><span class=line><span class=ln> 8</span><span class=cl><span class=c1># starts kafka-ui and kpow</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl><span class=c1># connect server address (http://kafka-connect:8083) is added</span>
</span></span><span class=line><span class=ln>10</span><span class=cl><span class=c1># check updated environment variables of each service</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>$ docker-compose -f compose-ui.yml up -d
</span></span></code></pre></div><h2 id=source-connector-creation data-numberify>Source Connector Creation<a class="anchor ms-1" href=#source-connector-creation></a></h2><p>As mentioned earlier, Kafka Connect provides a REST API that manages connectors. We can create a connector programmatically. The REST endpoint requires a JSON payload that includes connector configurations.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ <span class=nb>cd</span> kafka-dev-with-docker/part-03
</span></span><span class=line><span class=ln>2</span><span class=cl>$ curl -i -X POST -H <span class=s2>&#34;Accept:application/json&#34;</span> -H <span class=s2>&#34;Content-Type:application/json&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>3</span><span class=cl><span class=se></span>  http://localhost:8083/connectors/ -d @configs/source.json
</span></span></code></pre></div><p>The connector class (<em>connector.class</em>) is required for any connector and I set it for the MSK Data Generator. Also, as many as two workers are allocated to the connector (<em>tasks.max</em>). As mentioned earlier, the converter-related properties are overridden. Specifically, the key converter is set to the string converter as the keys of both topics are set to be primitive values (<em>genkp</em>). Also, schemas are not enabled for both the key and value.</p><p>The remaining properties are specific to the source connector. Basically it sends messages to two topics (<em>customer</em> and <em>order</em>). They are linked by the <em>customer_id</em> attribute of the <em>order</em> topic where the value is from the key of the <em>customer</em> topic. This is useful for practicing stream processing e.g. for joining two streams.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=ln> 1</span><span class=cl><span class=c1>// kafka-dev-with-docker/part-03/configs/source.json
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1></span><span class=p>{</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>  <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;order-source&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl>  <span class=nt>&#34;config&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>    <span class=nt>&#34;connector.class&#34;</span><span class=p>:</span> <span class=s2>&#34;com.amazonaws.mskdatagen.GeneratorSourceConnector&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl>    <span class=nt>&#34;tasks.max&#34;</span><span class=p>:</span> <span class=s2>&#34;2&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>    <span class=nt>&#34;key.converter&#34;</span><span class=p>:</span> <span class=s2>&#34;org.apache.kafka.connect.storage.StringConverter&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>    <span class=nt>&#34;key.converter.schemas.enable&#34;</span><span class=p>:</span> <span class=kc>false</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>    <span class=nt>&#34;value.converter&#34;</span><span class=p>:</span> <span class=s2>&#34;org.apache.kafka.connect.json.JsonConverter&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>    <span class=nt>&#34;value.converter.schemas.enable&#34;</span><span class=p>:</span> <span class=kc>false</span><span class=p>,</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>
</span></span><span class=line><span class=ln>12</span><span class=cl>    <span class=nt>&#34;genkp.customer.with&#34;</span><span class=p>:</span> <span class=s2>&#34;#{Code.isbn10}&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>    <span class=nt>&#34;genv.customer.name.with&#34;</span><span class=p>:</span> <span class=s2>&#34;#{Name.full_name}&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>14</span><span class=cl>
</span></span><span class=line><span class=ln>15</span><span class=cl>    <span class=nt>&#34;genkp.order.with&#34;</span><span class=p>:</span> <span class=s2>&#34;#{Internet.uuid}&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>    <span class=nt>&#34;genv.order.product_id.with&#34;</span><span class=p>:</span> <span class=s2>&#34;#{number.number_between &#39;101&#39;,&#39;109&#39;}&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>17</span><span class=cl>    <span class=nt>&#34;genv.order.quantity.with&#34;</span><span class=p>:</span> <span class=s2>&#34;#{number.number_between &#39;1&#39;,&#39;5&#39;}&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>    <span class=nt>&#34;genv.order.customer_id.matching&#34;</span><span class=p>:</span> <span class=s2>&#34;customer.key&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>19</span><span class=cl>
</span></span><span class=line><span class=ln>20</span><span class=cl>    <span class=nt>&#34;global.throttle.ms&#34;</span><span class=p>:</span> <span class=s2>&#34;500&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>21</span><span class=cl>    <span class=nt>&#34;global.history.records.max&#34;</span><span class=p>:</span> <span class=s2>&#34;1000&#34;</span>
</span></span><span class=line><span class=ln>22</span><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=ln>23</span><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Once created successfully, we can check the connector status as shown below.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ curl http://localhost:8083/connectors/order-source/status
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=ln> 1</span><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl>	<span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;order-source&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>	<span class=nt>&#34;connector&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl>		<span class=nt>&#34;state&#34;</span><span class=p>:</span> <span class=s2>&#34;RUNNING&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>		<span class=nt>&#34;worker_id&#34;</span><span class=p>:</span> <span class=s2>&#34;172.19.0.6:8083&#34;</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl>	<span class=p>},</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>	<span class=nt>&#34;tasks&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>		<span class=p>{</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>			<span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>			<span class=nt>&#34;state&#34;</span><span class=p>:</span> <span class=s2>&#34;RUNNING&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>			<span class=nt>&#34;worker_id&#34;</span><span class=p>:</span> <span class=s2>&#34;172.19.0.6:8083&#34;</span>
</span></span><span class=line><span class=ln>12</span><span class=cl>		<span class=p>},</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>		<span class=p>{</span>
</span></span><span class=line><span class=ln>14</span><span class=cl>			<span class=nt>&#34;id&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>			<span class=nt>&#34;state&#34;</span><span class=p>:</span> <span class=s2>&#34;RUNNING&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>			<span class=nt>&#34;worker_id&#34;</span><span class=p>:</span> <span class=s2>&#34;172.19.0.6:8083&#34;</span>
</span></span><span class=line><span class=ln>17</span><span class=cl>		<span class=p>}</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>	<span class=p>],</span>
</span></span><span class=line><span class=ln>19</span><span class=cl>	<span class=nt>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;source&#34;</span>
</span></span><span class=line><span class=ln>20</span><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>As we&rsquo;ve added the connector URL, the <em>Kafka Connect</em> menu gets appeared on <em>kafka-ui</em>. We can check the details of the connector on the app as well.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-05-25-kafka-development-with-docker-part-3/source-connector.png loading=lazy width=1222 height=420></picture></p><h3 id=kafka-topics data-numberify>Kafka Topics<a class="anchor ms-1" href=#kafka-topics></a></h3><p>As configured, the source connector ingests messages to the <em>customer</em> and <em>order</em> topics.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-05-25-kafka-development-with-docker-part-3/topics-01.png loading=lazy width=1222 height=426></picture></p><p>We can browse individual messages in the <em>Messages</em> tab of a topic.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-05-25-kafka-development-with-docker-part-3/topics-02.png loading=lazy width=1218 height=648></picture></p><h2 id=sink-connector-creation data-numberify>Sink Connector Creation<a class="anchor ms-1" href=#sink-connector-creation></a></h2><p>Similar to the source connector, we can create the sink connector using the REST API.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ <span class=nb>cd</span> kafka-dev-with-docker/part-03
</span></span><span class=line><span class=ln>2</span><span class=cl>$ curl -i -X POST -H <span class=s2>&#34;Accept:application/json&#34;</span> -H <span class=s2>&#34;Content-Type:application/json&#34;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>3</span><span class=cl><span class=se></span>  http://localhost:8083/connectors/ -d @configs/sink.json
</span></span></code></pre></div><p>The connector is configured to write messages from both the topics (<em>topics</em>) into a S3 bucket (<em>s3.bucket.name</em>) where files are prefixed by the partition number (<em>DefaultPartitioner</em>). Also, it invokes file commits every 60 seconds (<em>rotate.schedule.interval.ms</em>) or the number of messages reach 100 (<em>flush.size</em>). Like the source connector, it overrides the converter-related properties.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=ln> 1</span><span class=cl><span class=c1>// kafka-dev-with-docker/part-03/configs/sink.json
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1></span><span class=p>{</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>  <span class=nt>&#34;name&#34;</span><span class=p>:</span> <span class=s2>&#34;order-sink&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl>  <span class=nt>&#34;config&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>    <span class=nt>&#34;connector.class&#34;</span><span class=p>:</span> <span class=s2>&#34;io.confluent.connect.s3.S3SinkConnector&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl>    <span class=nt>&#34;storage.class&#34;</span><span class=p>:</span> <span class=s2>&#34;io.confluent.connect.s3.storage.S3Storage&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>    <span class=nt>&#34;format.class&#34;</span><span class=p>:</span> <span class=s2>&#34;io.confluent.connect.s3.format.json.JsonFormat&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>    <span class=nt>&#34;tasks.max&#34;</span><span class=p>:</span> <span class=s2>&#34;2&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>    <span class=nt>&#34;topics&#34;</span><span class=p>:</span> <span class=s2>&#34;order,customer&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>    <span class=nt>&#34;s3.bucket.name&#34;</span><span class=p>:</span> <span class=s2>&#34;kafka-dev-ap-southeast-2&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>    <span class=nt>&#34;s3.region&#34;</span><span class=p>:</span> <span class=s2>&#34;ap-southeast-2&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>12</span><span class=cl>    <span class=nt>&#34;flush.size&#34;</span><span class=p>:</span> <span class=s2>&#34;100&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>    <span class=nt>&#34;rotate.schedule.interval.ms&#34;</span><span class=p>:</span> <span class=s2>&#34;60000&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>14</span><span class=cl>    <span class=nt>&#34;timezone&#34;</span><span class=p>:</span> <span class=s2>&#34;Australia/Sydney&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>    <span class=nt>&#34;partitioner.class&#34;</span><span class=p>:</span> <span class=s2>&#34;io.confluent.connect.storage.partitioner.DefaultPartitioner&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>    <span class=nt>&#34;key.converter&#34;</span><span class=p>:</span> <span class=s2>&#34;org.apache.kafka.connect.storage.StringConverter&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>17</span><span class=cl>    <span class=nt>&#34;key.converter.schemas.enable&#34;</span><span class=p>:</span> <span class=kc>false</span><span class=p>,</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>    <span class=nt>&#34;value.converter&#34;</span><span class=p>:</span> <span class=s2>&#34;org.apache.kafka.connect.json.JsonConverter&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>19</span><span class=cl>    <span class=nt>&#34;value.converter.schemas.enable&#34;</span><span class=p>:</span> <span class=kc>false</span><span class=p>,</span>
</span></span><span class=line><span class=ln>20</span><span class=cl>    <span class=nt>&#34;errors.log.enable&#34;</span><span class=p>:</span> <span class=s2>&#34;true&#34;</span>
</span></span><span class=line><span class=ln>21</span><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=ln>22</span><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Below shows the sink connector details on <em>kafka-ui</em>.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-05-25-kafka-development-with-docker-part-3/sink-connector.png loading=lazy width=1219 height=353></picture></p><h3 id=kafka-consumers data-numberify>Kafka Consumers<a class="anchor ms-1" href=#kafka-consumers></a></h3><p>The sink connector creates a Kafka consumer, and it is named as <em>connect-order-sink</em>. We see that it subscribes the two topics and is in the stable state. It has two members because it is configured to have as many as 2 tasks.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-05-25-kafka-development-with-docker-part-3/consumer-01.png loading=lazy width=1222 height=361></picture></p><h3 id=s3-destination data-numberify>S3 Destination<a class="anchor ms-1" href=#s3-destination></a></h3><p>The sink connector writes messages of the two topics (<em>customer</em> and <em>order</em>), and topic names are used as prefixes.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-05-25-kafka-development-with-docker-part-3/s3-01.png loading=lazy width=1197 height=505></picture></p><p>As mentioned, the default partitioner prefixes files further by the partition number, and it can be checked below.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-05-25-kafka-development-with-docker-part-3/s3-02.png loading=lazy width=1200 height=533></picture></p><p>The files are generated by <code>&lt;topic>+&lt;partiton>+&lt;start-offset>.json</code>. The sink connector&rsquo;s format class is set to <em>io.confluent.connect.s3.format.json.JsonFormat</em> so that it writes to Json files.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-05-25-kafka-development-with-docker-part-3/s3-03.png loading=lazy width=1180 height=625></picture></p><h2 id=summary data-numberify>Summary<a class="anchor ms-1" href=#summary></a></h2><p>Kafka Connect is a tool for scalably and reliably streaming data between Apache Kafka and other systems. In this post, I illustrated how to set up a data ingestion pipeline using Kafka connectors. Fake customer and order data was ingested into the corresponding topics using the MSK Data Generator source connector. Also, the topic messages were saved into a S3 bucket using the Confluent S3 sink connector.</p></div></div></div><div class=card-footer><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-down post-prev-icon me-1" data-fa-transform=rotate-90></i>
<a href=/blog/2023-05-18-kafka-development-with-docker-part-2/>Kafka Development With Docker - Part 2 Management App</a></div><div class="post-nav post-next"><a href=/blog/2023-06-01-kafka-development-with-docker-part-4/>Kafka Development With Docker - Part 4 Producer and Consumer</a>
<i class="fas fa-fw fa-chevron-down post-next-icon ms-1" data-fa-transform=rotate-270></i></div></div></div></article><section class="related-posts row card component"><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Related Posts</h2></div><div class="card-body slide px-1"><div class="slide-inner row gx-0"><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2022-04-03-schema-registry-part2/featured_hu55ef0aeef397b55768e961367d004bbc_59689_500x0_resize_box_3.png media="(max-width: 576px)" height=252 width=500><img class=img-fluid height=91 width=180 alt=featured.png src=/blog/2022-04-03-schema-registry-part2/featured_hu55ef0aeef397b55768e961367d004bbc_59689_180x0_resize_box_3.png data-src=/blog/2022-04-03-schema-registry-part2/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2022-04-03-schema-registry-part2/>Use External Schema Registry With MSK Connect – Part 2 MSK Deployment</a><div class="post-meta mb-0">April 3, 2022</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2022-03-07-schema-registry-part1/featured_hu55ef0aeef397b55768e961367d004bbc_59689_500x0_resize_box_3.png media="(max-width: 576px)" height=252 width=500><img class=img-fluid height=91 width=180 alt=featured.png src=/blog/2022-03-07-schema-registry-part1/featured_hu55ef0aeef397b55768e961367d004bbc_59689_180x0_resize_box_3.png data-src=/blog/2022-03-07-schema-registry-part1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2022-03-07-schema-registry-part1/>Use External Schema Registry With MSK Connect – Part 1 Local Development</a><div class="post-meta mb-0">March 7, 2022</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2021-12-05-datalake-demo-part1/featured_hua25eccd3824300d3b1ed87f56797248c_164526_500x0_resize_box_3.png media="(max-width: 576px)" height=229 width=500><img class=img-fluid height=83 width=180 alt=featured.png src=/blog/2021-12-05-datalake-demo-part1/featured_hua25eccd3824300d3b1ed87f56797248c_164526_180x0_resize_box_3.png data-src=/blog/2021-12-05-datalake-demo-part1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2021-12-05-datalake-demo-part1/>Data Lake Demo Using Change Data Capture (CDC) on AWS – Part 1 Local Development</a><div class="post-meta mb-0">December 5, 2021</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-05-18-kafka-development-with-docker-part-2/featured_hu7e86619ffdcd5d184364188304c39e01_59675_500x0_resize_box_3.png media="(max-width: 576px)" height=234 width=500><img class=img-fluid height=84 width=180 alt=featured.png src=/blog/2023-05-18-kafka-development-with-docker-part-2/featured_hu7e86619ffdcd5d184364188304c39e01_59675_180x0_resize_box_3.png data-src=/blog/2023-05-18-kafka-development-with-docker-part-2/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-05-18-kafka-development-with-docker-part-2/>Kafka Development With Docker - Part 2 Management App</a><div class="post-meta mb-0">May 18, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-05-04-kafka-development-with-docker-part-1/featured_hu351ee075bb995e8f69034dc54fe8364b_98355_500x0_resize_box_3.png media="(max-width: 576px)" height=322 width=500><img class=img-fluid height=116 width=180 alt=featured.png src=/blog/2023-05-04-kafka-development-with-docker-part-1/featured_hu351ee075bb995e8f69034dc54fe8364b_98355_180x0_resize_box_3.png data-src=/blog/2023-05-04-kafka-development-with-docker-part-1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-05-04-kafka-development-with-docker-part-1/>Kafka Development With Docker - Part 1 Cluster Setup</a><div class="post-meta mb-0">May 4, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_500x0_resize_box_3.png media="(max-width: 576px)" height=305 width=500><img class=img-fluid height=110 width=180 alt=featured.png src=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_180x0_resize_box_3.png data-src=/blog/2023-04-12-integrate-glue-schema-registry/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-04-12-integrate-glue-schema-registry/>Integrate Glue Schema Registry With Your Python Kafka App</a><div class="post-meta mb-0">April 12, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-01-10-kafka-consumer-seek-offsets/featured_hua222fe3eeaae92dfa98b24cdf7061694_47217_500x0_resize_box_3.png media="(max-width: 576px)" height=368 width=500><img class=img-fluid height=132 width=180 alt=featured.png src=/blog/2023-01-10-kafka-consumer-seek-offsets/featured_hua222fe3eeaae92dfa98b24cdf7061694_47217_180x0_resize_box_3.png data-src=/blog/2023-01-10-kafka-consumer-seek-offsets/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-01-10-kafka-consumer-seek-offsets/>How to Configure Kafka Consumers to Seek Offsets by Timestamp</a><div class="post-meta mb-0">January 10, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2021-12-19-datalake-demo-part3/featured_hua25eccd3824300d3b1ed87f56797248c_164526_500x0_resize_box_3.png media="(max-width: 576px)" height=229 width=500><img class=img-fluid height=83 width=180 alt=featured.png src=/blog/2021-12-19-datalake-demo-part3/featured_hua25eccd3824300d3b1ed87f56797248c_164526_180x0_resize_box_3.png data-src=/blog/2021-12-19-datalake-demo-part3/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2021-12-19-datalake-demo-part3/>Data Lake Demo Using Change Data Capture (CDC) on AWS – Part 3 Implement Data Lake</a><div class="post-meta mb-0">December 19, 2021</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2021-12-12-datalake-demo-part2/featured_hua25eccd3824300d3b1ed87f56797248c_164526_500x0_resize_box_3.png media="(max-width: 576px)" height=229 width=500><img class=img-fluid height=83 width=180 alt=featured.png src=/blog/2021-12-12-datalake-demo-part2/featured_hua25eccd3824300d3b1ed87f56797248c_164526_180x0_resize_box_3.png data-src=/blog/2021-12-12-datalake-demo-part2/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2021-12-12-datalake-demo-part2/>Data Lake Demo Using Change Data Capture (CDC) on AWS – Part 2 Implement CDC</a><div class="post-meta mb-0">December 12, 2021</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-05-03-kafka-connect-for-aws-part-1/featured_hu86011ae8fa75383c328c2b5f29f8b87d_22272_500x0_resize_box_3.png media="(max-width: 576px)" height=169 width=500><img class=img-fluid height=61 width=180 alt=featured.png src=/blog/2023-05-03-kafka-connect-for-aws-part-1/featured_hu86011ae8fa75383c328c2b5f29f8b87d_22272_180x0_resize_box_3.png data-src=/blog/2023-05-03-kafka-connect-for-aws-part-1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-05-03-kafka-connect-for-aws-part-1/>Kafka Connect for AWS Services Integration - Part 1 Introduction</a><div class="post-meta mb-0">May 3, 2023</div></div></div></div><button class=slide-control-left>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i>
<span class=visually-hidden>Left</span>
</button>
<button class=slide-control-right>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-270></i>
<span class=visually-hidden>Right</span></button></div></section><div class="card component row post-comments" id=post-comments><div class=card-header><h2 class="card-title my-2 fs-4 text-surface">Comments</h2></div><div class=card-body><div class=giscus></div></div></div></div></div><aside class="col-xxl-4 sidebar d-flex"><div class="container d-flex flex-column"><div class="accordion profile"><div class="accordion-item card row text-center component"><div class="accordion-header card-header border-0" id=profile-header><a class="accordion-button d-lg-none mb-2 shadow-none p-0 bg-transparent text-surface" role=button data-bs-toggle=collapse href=#profile aria-expanded=true aria-controls=profile>Profile</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=profile aria-labelledby=profile-header><div class="col-12 d-flex align-items-center justify-content-center"><picture><img class="profile-avatar rounded-circle" alt="Jaehyeon Kim" src="https://jaehyeon.me/images/profile.png?v=def64c7ed1711a25afd88e36e3927ac7" loading=lazy data-viewer-invisible width=200 height=200></picture></div><div class="col-12 profile-meta"><div class="profile-name fw-fold fs-lg">Jaehyeon Kim</div><div class=profile-bio>Data Engineer 💡 Blogger ⚡ Data Streaming Enthusiast ☁ AWS Community Builder</div></div><nav class="social-links nav justify-content-center mt-1 justify-content-around"><a class="nav-link social-link" href=mailto:dottami@gmail.com title=Email><i class="fas fa-fw fa-2x fa-envelope" style=color:#0963ac></i>
</a><a class="nav-link social-link" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fa-2x fab fa-github"></i>
</a><a class="nav-link social-link" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fa-2x fab fa-linkedin-in" style=color:#0a66c2></i>
</a><a class="nav-link social-link" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fa-2x fab fa-paypal"></i></a></nav></div></div></div><div class="accordion taxonomies-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#taxonomies-toggle aria-expanded=true aria-controls=taxonomies-toggle>Taxonomies</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=taxonomies-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=taxonomyCategoriesTab data-bs-toggle=tab data-bs-target=#taxonomyCategories type=button role=tab aria-controls=taxonomyCategories aria-selected=true>
Categories</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyTagsTab data-bs-toggle=tab data-bs-target=#taxonomyTags type=button role=tab aria-controls=taxonomyTags aria-selected=true>
Tags</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomySeriesTab data-bs-toggle=tab data-bs-target=#taxonomySeries type=button role=tab aria-controls=taxonomySeries aria-selected=true>
Series</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyArchivesTab data-bs-toggle=tab data-bs-target=#taxonomyArchives type=button role=tab aria-controls=taxonomyArchives aria-selected=true>
Archives</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=taxonomyCategories role=tabpanel aria-labelledby=taxonomyCategoriesTab tabindex=0><a href=/categories/data-streaming/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Streaming">Data Streaming
<span class="badge badge-sm text-secondary bg-white ms-1">25</span>
</a><a href=/categories/data-engineering/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Engineering">Data Engineering
<span class="badge badge-sm text-secondary bg-white ms-1">24</span>
</a><a href=/categories/development/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Development>Development
<span class="badge badge-sm text-secondary bg-white ms-1">19</span>
</a><a href=/categories/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/categories/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/categories/machine-learning/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Machine Learning">Machine Learning
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/categories/general/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=General>General
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/categories/apache-beam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Beam">Apache Beam
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a></div><div class=tab-pane id=taxonomyTags role=tabpanel aria-labelledby=taxonomyTagsTab tabindex=0><a href=/tags/docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Docker>Docker
<span class="badge badge-sm text-secondary bg-white ms-1">51</span>
</a><a href=/tags/python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Python>Python
<span class="badge badge-sm text-secondary bg-white ms-1">47</span>
</a><a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">44</span>
</a><a href=/tags/aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=AWS>AWS
<span class="badge badge-sm text-secondary bg-white ms-1">43</span>
</a><a href=/tags/docker-compose/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Docker Compose">Docker Compose
<span class="badge badge-sm text-secondary bg-white ms-1">43</span>
</a><a href=/tags/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">36</span>
</a><a href=/tags/amazon-msk/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK">Amazon MSK
<span class="badge badge-sm text-secondary bg-white ms-1">21</span>
</a><a href=/tags/apache-spark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Spark">Apache Spark
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/tags/kafka-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Kafka Connect">Kafka Connect
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/tags/aws-lambda/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Lambda">AWS Lambda
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/tags/apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Flink">Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/tags/terraform/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Terraform>Terraform
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/tags/amazon-emr/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EMR">Amazon EMR
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/data-build-tool-dbt/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Data Build Tool (DBT)">Data Build Tool (DBT)
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/pyflink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PyFlink>PyFlink
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/amazon-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK Connect">Amazon MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">9</span>
</a><a href=/tags/kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Kubernetes>Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">8</span>
</a><a href=/tags/amazon-athena/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Athena">Amazon Athena
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/pyspark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PySpark>PySpark
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/amazon-dynamodb/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon DynamoDB">Amazon DynamoDB
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/apache-airflow/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Airflow">Apache Airflow
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/rserve/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Rserve>Rserve
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/visual-studio-code/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Visual Studio Code">Visual Studio Code
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/amazon-api-gateway/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon API Gateway">Amazon API Gateway
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-managed-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Managed Flink">Amazon Managed Flink
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-managed-service-for-apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Managed Service for Apache Flink">Amazon Managed Service for Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-quicksight/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon QuickSight">Amazon QuickSight
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/aws-glue/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Glue">AWS Glue
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/minikube/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Minikube>Minikube
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/opensearch/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=OpenSearch>OpenSearch
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/security/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Security>Security
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/shiny/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Shiny>Shiny
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-eks/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EKS">Amazon EKS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/amazon-opensearch-service/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon OpenSearch Service">Amazon OpenSearch Service
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/amazon-s3/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon S3">Amazon S3
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/apache-camel/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Camel">Apache Camel
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/apache-hudi/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Hudi">Apache Hudi
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/apache-iceberg/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Iceberg">Apache Iceberg
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/aws-sam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS SAM">AWS SAM
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Change Data Capture">Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=https://jaehyeon.me/tags class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=ALL>ALL
<span class="badge badge-sm text-secondary bg-white ms-1">97</span></a></div><div class=tab-pane id=taxonomySeries role=tabpanel aria-labelledby=taxonomySeriesTab tabindex=0><a href=/series/kafka-development-with-docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development With Docker">Kafka Development With Docker
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/series/real-time-streaming-with-kafka-and-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Real Time Streaming With Kafka and Flink">Real Time Streaming With Kafka and Flink
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/series/dbt-pizza-shop-demo/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT Pizza Shop Demo">DBT Pizza Shop Demo
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/series/tree-based-methods-in-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Tree Based Methods in R">Tree Based Methods in R
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/series/dbt-for-effective-data-transformation-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT for Effective Data Transformation on AWS">DBT for Effective Data Transformation on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/kafka-connect-for-aws-services-integration/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Connect for AWS Services Integration">Kafka Connect for AWS Services Integration
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/serverless-data-product/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Serverless Data Product">Serverless Data Product
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/series/data-lake-demo-using-change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Data Lake Demo Using Change Data Capture">Data Lake Demo Using Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/getting-started-with-pyflink-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Getting Started With Pyflink on AWS">Getting Started With Pyflink on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/kafka-development-on-kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development on Kubernetes">Kafka Development on Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/parallel-processing-on-single-machine/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Parallel Processing on Single Machine">Parallel Processing on Single Machine
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/apache-beam-local-development-with-python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Apache Beam Local Development With Python">Apache Beam Local Development With Python
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/api-development-with-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="API Development With R">API Development With R
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/integrate-schema-registry-with-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Integrate Schema Registry With MSK Connect">Integrate Schema Registry With MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/kafka-flink-and-dynamodb-for-real-time-fraud-detection/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka, Flink and DynamoDB for Real Time Fraud Detection">Kafka, Flink and DynamoDB for Real Time Fraud Detection
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/simplify-streaming-ingestion-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Simplify Streaming Ingestion on AWS">Simplify Streaming Ingestion on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a></div><div class=tab-pane id=taxonomyArchives role=tabpanel aria-labelledby=taxonomyArchivesTab tabindex=0><a href=/archives/2024/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2024>2024 <span class="badge badge-sm text-secondary bg-white ms-1">10</span>
</a><a href=/archives/2023/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2023>2023 <span class="badge badge-sm text-secondary bg-white ms-1">39</span>
</a><a href=/archives/2022/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2022>2022 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2021/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2021>2021 <span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/archives/2020/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2020>2020 <span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/archives/2019/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2019>2019 <span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/archives/2018/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2018>2018 <span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/archives/2017/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2017>2017 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2016/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2016>2016 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2015/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2015>2015 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2014/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2014>2014 <span class="badge badge-sm text-secondary bg-white ms-1">5</span></a></div></div></div></div></div><div class="accordion posts-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#posts-toggle aria-expanded=true aria-controls=posts-toggle>Posts</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=posts-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=featured-posts-tab data-bs-toggle=tab data-bs-target=#featured-posts type=button role=tab aria-controls=featured-posts aria-selected=true>
Featured Posts</button></li><li class=nav-item role=presentation><button class=nav-link id=recent-posts-tab data-bs-toggle=tab data-bs-target=#recent-posts type=button role=tab aria-controls=recent-posts aria-selected=true>
Recent Posts</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=featured-posts role=tabpanel aria-labelledby=featured-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-04-04-beam-local-dev-2/featured_huc60febc0cd72955054b95c3bf20650a7_55405_500x0_resize_box_3.png media="(max-width: 576px)" height=330 width=500><img class=img-fluid height=119 width=180 alt=featured.png src=/blog/2024-04-04-beam-local-dev-2/featured_huc60febc0cd72955054b95c3bf20650a7_55405_180x0_resize_box_3.png data-src=/blog/2024-04-04-beam-local-dev-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-04-04-beam-local-dev-2/>Apache Beam Local Development With Python - Part 2 Batch Pipelines</a><div class="post-meta mt-2"><span class=post-date>April 4, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_500x0_resize_box_3.png media="(max-width: 576px)" height=338 width=500><img class=img-fluid height=122 width=180 alt=featured.png src=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_180x0_resize_box_3.png data-src=/blog/2024-03-28-beam-local-dev-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-28-beam-local-dev-1/>Apache Beam Local Development With Python - Part 1 Pipeline, Notebook, SQL and DataFrame</a><div class="post-meta mt-2"><span class=post-date>March 28, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-14-dbt-pizza-shop-6/featured_hu72fe52c30196d9a511f344ff548f2036_82921_500x0_resize_box_3.png media="(max-width: 576px)" height=256 width=500><img class=img-fluid height=92 width=180 alt=featured.png src=/blog/2024-03-14-dbt-pizza-shop-6/featured_hu72fe52c30196d9a511f344ff548f2036_82921_180x0_resize_box_3.png data-src=/blog/2024-03-14-dbt-pizza-shop-6/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-14-dbt-pizza-shop-6/>Data Build Tool (Dbt) Pizza Shop Demo - Part 6 ETL on Amazon Athena via Airflow</a><div class="post-meta mt-2"><span class=post-date>March 14, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-07-dbt-pizza-shop-5/featured_hu5822ed54c6b6e6cff286a9a560a4b806_61499_500x0_resize_box_3.png media="(max-width: 576px)" height=187 width=500><img class=img-fluid height=67 width=180 alt=featured.png src=/blog/2024-03-07-dbt-pizza-shop-5/featured_hu5822ed54c6b6e6cff286a9a560a4b806_61499_180x0_resize_box_3.png data-src=/blog/2024-03-07-dbt-pizza-shop-5/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-07-dbt-pizza-shop-5/>Data Build Tool (Dbt) Pizza Shop Demo - Part 5 Modelling on Amazon Athena</a><div class="post-meta mt-2"><span class=post-date>March 7, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-02-22-dbt-pizza-shop-4/featured_hu487187112b89f2568f433199221f000a_89588_500x0_resize_box_3.png media="(max-width: 576px)" height=327 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2024-02-22-dbt-pizza-shop-4/featured_hu487187112b89f2568f433199221f000a_89588_180x0_resize_box_3.png data-src=/blog/2024-02-22-dbt-pizza-shop-4/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-02-22-dbt-pizza-shop-4/>Data Build Tool (Dbt) Pizza Shop Demo - Part 4 ETL on BigQuery via Airflow</a><div class="post-meta mt-2"><span class=post-date>February 22, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-02-08-dbt-pizza-shop-3/featured_hu5082aedceaa438015dc31206ac8f27c2_70297_500x0_resize_box_3.png media="(max-width: 576px)" height=241 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2024-02-08-dbt-pizza-shop-3/featured_hu5082aedceaa438015dc31206ac8f27c2_70297_180x0_resize_box_3.png data-src=/blog/2024-02-08-dbt-pizza-shop-3/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-02-08-dbt-pizza-shop-3/>Data Build Tool (Dbt) Pizza Shop Demo - Part 3 Modelling on BigQuery</a><div class="post-meta mt-2"><span class=post-date>February 8, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-25-dbt-pizza-shop-2/featured_hu32c9a8b2df36b3a1704029fc725738dd_77355_500x0_resize_box_3.png media="(max-width: 576px)" height=328 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2024-01-25-dbt-pizza-shop-2/featured_hu32c9a8b2df36b3a1704029fc725738dd_77355_180x0_resize_box_3.png data-src=/blog/2024-01-25-dbt-pizza-shop-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-25-dbt-pizza-shop-2/>Data Build Tool (Dbt) Pizza Shop Demo - Part 2 ETL on PostgreSQL via Airflow</a><div class="post-meta mt-2"><span class=post-date>January 25, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_500x0_resize_box_3.png media="(max-width: 576px)" height=238 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_180x0_resize_box_3.png data-src=/blog/2024-01-18-dbt-pizza-shop-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-18-dbt-pizza-shop-1/>Data Build Tool (Dbt) Pizza Shop Demo - Part 1 Modelling on PostgreSQL</a><div class="post-meta mt-2"><span class=post-date>January 18, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_180x0_resize_box_3.png data-src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-12-21-kafka-development-on-k8s-part-1/>Kafka Development on Kubernetes - Part 1 Cluster Setup</a><div class="post-meta mt-2"><span class=post-date>December 21, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-12-07-flink-spark-local-dev/featured_hu7a73c8ca7d8b8a4ddf49d1a9b8fe40bd_133053_500x0_resize_box_3.png media="(max-width: 576px)" height=373 width=500><img class=img-fluid height=134 width=180 alt=featured.png src=/blog/2023-12-07-flink-spark-local-dev/featured_hu7a73c8ca7d8b8a4ddf49d1a9b8fe40bd_133053_180x0_resize_box_3.png data-src=/blog/2023-12-07-flink-spark-local-dev/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-12-07-flink-spark-local-dev/>Setup Local Development Environment for Apache Flink and Spark Using EMR Container Images</a><div class="post-meta mt-2"><span class=post-date>December 7, 2023</span></div></div></div></li></ul></div><div class=tab-pane id=recent-posts role=tabpanel aria-labelledby=recent-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-04-04-beam-local-dev-2/featured_huc60febc0cd72955054b95c3bf20650a7_55405_500x0_resize_box_3.png media="(max-width: 576px)" height=330 width=500><img class=img-fluid height=119 width=180 alt=featured.png src=/blog/2024-04-04-beam-local-dev-2/featured_huc60febc0cd72955054b95c3bf20650a7_55405_180x0_resize_box_3.png data-src=/blog/2024-04-04-beam-local-dev-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-04-04-beam-local-dev-2/>Apache Beam Local Development With Python - Part 2 Batch Pipelines</a><div class="post-meta mt-2"><span class=post-date>April 4, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_500x0_resize_box_3.png media="(max-width: 576px)" height=338 width=500><img class=img-fluid height=122 width=180 alt=featured.png src=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_180x0_resize_box_3.png data-src=/blog/2024-03-28-beam-local-dev-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-28-beam-local-dev-1/>Apache Beam Local Development With Python - Part 1 Pipeline, Notebook, SQL and DataFrame</a><div class="post-meta mt-2"><span class=post-date>March 28, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-14-dbt-pizza-shop-6/featured_hu72fe52c30196d9a511f344ff548f2036_82921_500x0_resize_box_3.png media="(max-width: 576px)" height=256 width=500><img class=img-fluid height=92 width=180 alt=featured.png src=/blog/2024-03-14-dbt-pizza-shop-6/featured_hu72fe52c30196d9a511f344ff548f2036_82921_180x0_resize_box_3.png data-src=/blog/2024-03-14-dbt-pizza-shop-6/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-14-dbt-pizza-shop-6/>Data Build Tool (Dbt) Pizza Shop Demo - Part 6 ETL on Amazon Athena via Airflow</a><div class="post-meta mt-2"><span class=post-date>March 14, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-07-dbt-pizza-shop-5/featured_hu5822ed54c6b6e6cff286a9a560a4b806_61499_500x0_resize_box_3.png media="(max-width: 576px)" height=187 width=500><img class=img-fluid height=67 width=180 alt=featured.png src=/blog/2024-03-07-dbt-pizza-shop-5/featured_hu5822ed54c6b6e6cff286a9a560a4b806_61499_180x0_resize_box_3.png data-src=/blog/2024-03-07-dbt-pizza-shop-5/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-07-dbt-pizza-shop-5/>Data Build Tool (Dbt) Pizza Shop Demo - Part 5 Modelling on Amazon Athena</a><div class="post-meta mt-2"><span class=post-date>March 7, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-02-22-dbt-pizza-shop-4/featured_hu487187112b89f2568f433199221f000a_89588_500x0_resize_box_3.png media="(max-width: 576px)" height=327 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2024-02-22-dbt-pizza-shop-4/featured_hu487187112b89f2568f433199221f000a_89588_180x0_resize_box_3.png data-src=/blog/2024-02-22-dbt-pizza-shop-4/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-02-22-dbt-pizza-shop-4/>Data Build Tool (Dbt) Pizza Shop Demo - Part 4 ETL on BigQuery via Airflow</a><div class="post-meta mt-2"><span class=post-date>February 22, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-02-08-dbt-pizza-shop-3/featured_hu5082aedceaa438015dc31206ac8f27c2_70297_500x0_resize_box_3.png media="(max-width: 576px)" height=241 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2024-02-08-dbt-pizza-shop-3/featured_hu5082aedceaa438015dc31206ac8f27c2_70297_180x0_resize_box_3.png data-src=/blog/2024-02-08-dbt-pizza-shop-3/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-02-08-dbt-pizza-shop-3/>Data Build Tool (Dbt) Pizza Shop Demo - Part 3 Modelling on BigQuery</a><div class="post-meta mt-2"><span class=post-date>February 8, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-25-dbt-pizza-shop-2/featured_hu32c9a8b2df36b3a1704029fc725738dd_77355_500x0_resize_box_3.png media="(max-width: 576px)" height=328 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2024-01-25-dbt-pizza-shop-2/featured_hu32c9a8b2df36b3a1704029fc725738dd_77355_180x0_resize_box_3.png data-src=/blog/2024-01-25-dbt-pizza-shop-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-25-dbt-pizza-shop-2/>Data Build Tool (Dbt) Pizza Shop Demo - Part 2 ETL on PostgreSQL via Airflow</a><div class="post-meta mt-2"><span class=post-date>January 25, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_500x0_resize_box_3.png media="(max-width: 576px)" height=238 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_180x0_resize_box_3.png data-src=/blog/2024-01-18-dbt-pizza-shop-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-18-dbt-pizza-shop-1/>Data Build Tool (Dbt) Pizza Shop Demo - Part 1 Modelling on PostgreSQL</a><div class="post-meta mt-2"><span class=post-date>January 18, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-11-kafka-development-on-k8s-part-3/featured_hu95d566cb28d7f91b2d6baddb7d8bb440_97270_500x0_resize_box_3.png media="(max-width: 576px)" height=216 width=500><img class=img-fluid height=78 width=180 alt=featured.png src=/blog/2024-01-11-kafka-development-on-k8s-part-3/featured_hu95d566cb28d7f91b2d6baddb7d8bb440_97270_180x0_resize_box_3.png data-src=/blog/2024-01-11-kafka-development-on-k8s-part-3/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-11-kafka-development-on-k8s-part-3/>Kafka Development on Kubernetes - Part 3 Kafka Connect</a><div class="post-meta mt-2"><span class=post-date>January 11, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-04-kafka-development-on-k8s-part-2/featured_hu866886d7082b1c38bf0c33066b35072f_75889_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2024-01-04-kafka-development-on-k8s-part-2/featured_hu866886d7082b1c38bf0c33066b35072f_75889_180x0_resize_box_3.png data-src=/blog/2024-01-04-kafka-development-on-k8s-part-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-04-kafka-development-on-k8s-part-2/>Kafka Development on Kubernetes - Part 2 Producer and Consumer</a><div class="post-meta mt-2"><span class=post-date>January 4, 2024</span></div></div></div></li></ul></div></div></div></div></div></div></aside></div></main><footer class="footer mt-auto py-3 text-center container"><div class="offcanvas offcanvas-bottom h-auto" tabindex=-1 id=offcanvasActionsPanel aria-labelledby=offcanvasActionsPanelLabel><div class=offcanvas-header><div class="offcanvas-title h5" id=offcanvasActionsPanelLabel><i class="fas fa-fw fa-th-large me-1"></i>
Actions</div><button type=button class="btn-close ms-auto" data-bs-dismiss=offcanvas data-bs-target=offcanvasActionsPanel aria-label=Close></button></div><div class="offcanvas-body mt-2"><div class="actions d-flex overflow-auto align-items-center"><a role=button class="action action-go-back d-flex flex-column align-items-center me-3" href="javascript: window.history.back();"><span class="action-icon mb-2"><i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i></span> Go back
</a><a role=button class="action action-reload-page d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-redo-alt"></i></span> Reload
</a><a role=button class="action action-copy-url d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-link"></i></span> Copy URL</a></div></div></div><div class="row text-center"><div class="col-12 mt-2"><p class=mb-2>Jaehyeon Kim</p><p class="text-secondary mb-2"><small>Data Engineer 💡 Blogger ⚡ Data Streaming Enthusiast ☁ AWS Community Builder</small></p><div class="copyright mb-2 text-secondary"><small>Copyright © 2023-2024 Jaehyeon Kim. All Rights Reserved.</small></div><nav class="social-links nav justify-content-center mb-2 mt-3"><a class="nav-link social-link p-0 me-1 mb-2" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-2x fa-rss" style=color:#ea6221></i></a></nav></div><div class="col-12 col-lg-8 offset-0 offset-lg-1"></div></div></footer><script data-precache src=/assets/main/bundle.min.0ec8d79b95bd8d39246804f325aa5ba906dd898c752c661cb355262f78ecadcb.js integrity="sha256-DsjXm5W9jTkkaATzJapbqQbdiYx1LGYcs1UmL3jsrcs=" crossorigin=anonymous async></script><script data-precache src=/assets/icons/bundle.min.4f30d5267a9f2f9d45ed93969d45ec626100a969a8b91f71f753315a261e9034.js integrity="sha256-TzDVJnqfL51F7ZOWnUXsYmEAqWmouR9x91MxWiYekDQ=" crossorigin=anonymous defer></script><script data-precache src=/assets/viewer/bundle.min.06371891cfe6d10d36cba465c61c4d7cb17591a3be2fd9af4a38444d2074e709.js integrity="sha256-BjcYkc/m0Q02y6RlxhxNfLF1kaO+L9mvSjhETSB05wk=" crossorigin=anonymous defer></script><script data-precache defer src=/assets/katex/bundle.min.1a8cd88028fe1b600e81e2e780a8d8c388134c8237d5da89efed53ddfa28216e.js integrity="sha256-GozYgCj+G2AOgeLngKjYw4gTTII31dqJ7+1T3fooIW4=" crossorigin=anonymous></script><script data-precache defer src=/assets/mermaid/bundle.min.8d91e77f8b2cd5ebfd6d2af4e214fa37b555b15ad65dc1bdec5564ce709176f9.js integrity="sha256-jZHnf4ss1ev9bSr04hT6N7VVsVrWXcG97FVkznCRdvk=" crossorigin=anonymous></script><script src=/js/sw-register.js defer></script><script src=https://giscus.app/client.js data-repo=jaehyeon-kim/jaehyeon-kim.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkyNjgwMjU0NQ==" data-category data-category-id=DIC_kwDOAZj5cc4CV2fp data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous defer></script></body></html>