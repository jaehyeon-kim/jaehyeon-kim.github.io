<!doctype html><html class=position-relative itemscope itemtype=https://schema.org/WebPage lang=en data-bs-theme=light data-palette=blue-gray><head><script src=/assets/init/bundle.min.99cb2d6502b2c6f5d76f21079aa7b7ea5ad83125c684ac755e2a5af62cc7ad71.js integrity="sha256-mcstZQKyxvXXbyEHmqe36lrYMSXGhKx1Xipa9izHrXE=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Real Time Streaming with Kafka and Flink - Lab 2 Write data to Kafka from S3 using Flink - Jaehyeon Kim</title>
<link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_16x16_resize_q75_h2_box_2.webp sizes=16x16 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_32x32_resize_q75_h2_box_2.webp sizes=32x32 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_150x150_resize_q75_h2_box_2.webp sizes=150x150 type=image/webp><link rel=apple-touch-icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_180x180_resize_q75_h2_box_2.webp sizes=180x180 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_192x192_resize_q75_h2_box_2.webp sizes=192x192 type=image/webp><link rel=mask-icon href=/safari-pinned-tab.svg color=#6f42c1><meta name=keywords content="Analytics,Real-time Analytics,Data Engineering,Data Streaming,Architecture"><meta name=description content="In this lab, we will create a Pyflink application that reads records from S3 and sends them into a Kafka topic. A custom pipeline Jar file will be created as the Kafka cluster is authenticated by IAM, and it will be demonstrated how to execute the app in a Flink cluster deployed on Docker as well as locally as a typical Python app. We can assume the S3 data is static metadata that needs to be joined into another stream, and this exercise can be useful for data enrichment."><meta name=robots content="index, follow"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jaehyeon.me/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured.png"><meta name=twitter:title content="Real Time Streaming with Kafka and Flink - Lab 2 Write data to Kafka from S3 using Flink"><meta name=twitter:description content="In this lab, we will create a Pyflink application that reads records from S3 and sends them into a Kafka topic. A custom pipeline Jar file will be created as the Kafka cluster is authenticated by IAM, and it will be demonstrated how to execute the app in a Flink cluster deployed on Docker as well as locally as a typical Python app. We can assume the S3 data is static metadata that needs to be joined into another stream, and this exercise can be useful for data enrichment."><meta property="og:title" content="Real Time Streaming with Kafka and Flink - Lab 2 Write data to Kafka from S3 using Flink"><meta property="og:description" content="In this lab, we will create a Pyflink application that reads records from S3 and sends them into a Kafka topic. A custom pipeline Jar file will be created as the Kafka cluster is authenticated by IAM, and it will be demonstrated how to execute the app in a Flink cluster deployed on Docker as well as locally as a typical Python app. We can assume the S3 data is static metadata that needs to be joined into another stream, and this exercise can be useful for data enrichment."><meta property="og:type" content="article"><meta property="og:url" content="https://jaehyeon.me/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/"><meta property="og:image" content="https://jaehyeon.me/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2023-11-09T00:00:00+00:00"><meta property="article:modified_time" content="2023-12-15T09:27:31+11:00"><meta itemprop=name content="Real Time Streaming with Kafka and Flink - Lab 2 Write data to Kafka from S3 using Flink"><meta itemprop=description content="In this lab, we will create a Pyflink application that reads records from S3 and sends them into a Kafka topic. A custom pipeline Jar file will be created as the Kafka cluster is authenticated by IAM, and it will be demonstrated how to execute the app in a Flink cluster deployed on Docker as well as locally as a typical Python app. We can assume the S3 data is static metadata that needs to be joined into another stream, and this exercise can be useful for data enrichment."><meta itemprop=datePublished content="2023-11-09T00:00:00+00:00"><meta itemprop=dateModified content="2023-12-15T09:27:31+11:00"><meta itemprop=wordCount content="2995"><meta itemprop=image content="https://jaehyeon.me/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured.png"><meta itemprop=keywords content="AWS,Amazon MSK,Apache Kafka,Apache Flink,Pyflink,Docker,Docker Compose,Python,"><link rel=manifest href=/manifest.json><script async src="https://www.googletagmanager.com/gtag/js?id=G-076N8WCGWZ"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-076N8WCGWZ",{anonymize_ip:!1})}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2764466088407958"></script><link data-precache rel=stylesheet href="/assets/main/bundle.min.dc910a9364ba50e03d47ecf493e01f798a7ff46d1f793a172c8412e0c9867284.css" integrity="sha256-3JEKk2S6UOA9R+z0k+AfeYp/9G0feToXLIQS4MmGcoQ=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/katex/bundle.min.a06a916255e286562e9c3684403a944bb85aebe51b00e2f1ef537987349ead12.css integrity="sha256-oGqRYlXihlYunDaEQDqUS7ha6+UbAOLx71N5hzSerRI=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/viewer/bundle.min.8c1002839fa22c1350d6ae1eef6593120e108f973c41348be9b5065430566aaf.css integrity="sha256-jBACg5+iLBNQ1q4e72WTEg4Qj5c8QTSL6bUGVDBWaq8=" crossorigin=anonymous></head><body><header class="mb-4 sticky-top"><nav class="top-app-bar shadow navbar navbar-expand-xxl"><div class=container><a class="navbar-brand d-flex align-items-center flex-grow-1 flex-xxl-grow-0 justify-content-xxl-start ms-2 ms-xxl-0 mx-auto me-xxl-2" href=https://jaehyeon.me/>Jaehyeon Kim</a><div class="offcanvas-xxl offcanvas-end flex-grow-1" data-bs-scroll=true tabindex=-1 id=navbarMenus aria-labelledby=navbarMenusLabel><div class="offcanvas-header px-4 pb-0"><div class="offcanvas-title h5" id=navbarMenusLabel>Jaehyeon Kim</div><button type=button class="btn-close btn-close-white" data-bs-dismiss=offcanvas data-bs-target=#navbarMenus aria-label=Close></button></div><div class="offcanvas-body p-4 pt-0 p-xxl-0"><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center me-auto"><li class="nav-item col-12 col-xxl-auto dropdown px-0"><a href=# class="nav-link dropdown-toggle" id=navbarDropdownBlog role=button data-bs-toggle=dropdown aria-expanded=false><span class="menu-icon me-1"><i class="fas fa-fw fa-blog text-warning"></i></span>Blog</a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=navbarDropdownBlog data-bs-popper=none><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/archives/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-file-archive text-primary"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-0">Archives</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/series/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Series</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/series/_index.zh-cn/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">专栏</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/categories/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Categories</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/categories/_index.zh-cn/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">分类</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/tags/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Tags</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/tags/_index.zh-cn/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">标签</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li></ul></li></ul><hr class=d-xxl-none><form class="search-bar ms-auto my-auto" action=/search/ novalidate><div class="input-group align-items-center"><span class="btn btn-search disabled position-absolute left-0 border-0 px-1"><i class="fas fa-fw fa-search fa-lg"></i>
</span><input class="my-1 form-control border-white rounded-5 search-input bg-body" name=q type=search placeholder=Search aria-label=Search required>
<span class="search-shortcut position-absolute end-0 top-0 me-2"><kbd class="text-dark bg-white opacity-75 rounded-3 shadow border border-primary py-1 fw-bold">/</kbd></span></div></form><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center ms-md-auto"><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><nav class="social-links nav justify-content-center flex-row"><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fab fa-github"></i>
<span class="ms-1 d-xxl-none">Github</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fab fa-linkedin-in"></i>
<span class="ms-1 d-xxl-none">Linkedin</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fab fa-paypal"></i>
<span class="ms-1 d-xxl-none">Paypal</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-rss"></i>
<span class="ms-1 d-xxl-none">RSS</span></a></nav></li><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><div class="vr d-none d-xxl-flex h-100 mx-xxl-2 text-white"></div><hr class="d-xxl-none my-2"></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=fontSizeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-font"></i>
<span class=d-xxl-none>Font Size</span></a><ul class="font-size-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=fontSizeDropdown><li><button class="font-size-item dropdown-item" data-size=xs>
Extra Small</button></li><li><button class="font-size-item dropdown-item" data-size=sm>
Small</button></li><li><button class="font-size-item dropdown-item active" data-size=md>
Medium</button></li><li><button class="font-size-item dropdown-item" data-size=lg>
Large</button></li><li><button class="font-size-item dropdown-item" data-size=xl>
Extra Large</button></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=paletteDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-palette"></i>
<span class=d-xxl-none>Palette</span></a><ul class="palette-dropdown-menu dropdown-menu dropdown-menu-end px-2 row g-2" aria-labelledby=paletteDropdown><li class="col-4 my-1"><a role=button id=palette-blue aria-label=Blue class="btn btn-sm w-100 palette text-bg-blue" data-palette=blue></a></li><li class="col-4 my-1"><a role=button id=palette-blue-gray aria-label="Blue Gray" class="btn btn-sm w-100 palette text-bg-blue-gray" data-palette=blue-gray></a></li><li class="col-4 my-1"><a role=button id=palette-brown aria-label=Brown class="btn btn-sm w-100 palette text-bg-brown" data-palette=brown></a></li><li class="col-4 my-1"><a role=button id=palette-cyan aria-label=Cyan class="btn btn-sm w-100 palette text-bg-cyan" data-palette=cyan></a></li><li class="col-4 my-1"><a role=button id=palette-green aria-label=Green class="btn btn-sm w-100 palette text-bg-green" data-palette=green></a></li><li class="col-4 my-1"><a role=button id=palette-indigo aria-label=Indigo class="btn btn-sm w-100 palette text-bg-indigo" data-palette=indigo></a></li><li class="col-4 my-1"><a role=button id=palette-orange aria-label=Orange class="btn btn-sm w-100 palette text-bg-orange" data-palette=orange></a></li><li class="col-4 my-1"><a role=button id=palette-pink aria-label=Pink class="btn btn-sm w-100 palette text-bg-pink" data-palette=pink></a></li><li class="col-4 my-1"><a role=button id=palette-purple aria-label=Purple class="btn btn-sm w-100 palette text-bg-purple" data-palette=purple></a></li><li class="col-4 my-1"><a role=button id=palette-red aria-label=Red class="btn btn-sm w-100 palette text-bg-red" data-palette=red></a></li><li class="col-4 my-1"><a role=button id=palette-teal aria-label=Teal class="btn btn-sm w-100 palette text-bg-teal" data-palette=teal></a></li><li class="col-4 my-1"><a role=button id=palette-yellow aria-label=Yellow class="btn btn-sm w-100 palette text-bg-yellow" data-palette=yellow></a></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=modeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="mode-icon fas fa-fw fa-sun" id=modeIcon></i>
<span class=d-xxl-none>Mode</span></a><ul class="mode-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=modeDropdown><li class="mode-item active" data-color-mode=light data-icon=sun><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-sun"></i> Light</button></li><li class=mode-item data-color-mode=dark data-icon=moon><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-moon"></i> Dark</button></li><li class=mode-item data-color-mode=auto data-icon=adjust><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-adjust"></i> Auto</button></li></ul></li></ul></div></div><div class=d-flex><button class="navbar-toggler order-5 border-0" type=button data-bs-toggle=offcanvas data-bs-target=#navbarMenus aria-controls=navbarMenus aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-h"></i></button></div></div></nav></header><main class=container><div class="row content"><noscript><div class="alert alert-danger" role=alert>Your browser does not support JavaScript.</div></noscript><div class=col-xxl-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class="card-body pb-0"><ol class="hbs-breadcrumb breadcrumb flex-nowrap"><li class="breadcrumb-item text-surface"><a href=/>Home</a></li><li class="breadcrumb-item text-surface"><a href=/blog/>Blogs</a></li><li class="breadcrumb-item active">Real Time Streaming With Kafka and Flink - Lab 2 Write Data to Kafka From S3 Using Flink</li></ol></div></nav><div class="post-panel-wrapper position-relative d-flex justify-content-center"><div class="d-flex flex-row justify-content-center rounded-5 border post-panel position-fixed px-3 py-1 surface shadow-1"><a class="action action-toc d-none d-xxl-block" href=#postTOC role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-toc d-block d-xxl-none" href=#post-toc-container role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-post-comments" href=#post-comments role=button aria-label=Comments title=Comments><i class="fas fa-fw fa-comments"></i>
</a><a id=sidebarToggler class="action action-sidebar-toggler d-none d-xxl-block" role=button title="Toggle sidebar"><i class="fas fa-fw fa-expand-alt" data-fa-transform=rotate-45></i></a></div></div><article class="row card component mb-4 post"><div class=card-header><h1 class="card-title post-title my-2">Real Time Streaming With Kafka and Flink - Lab 2 Write Data to Kafka From S3 Using Flink</h1></div><div class=card-body><div class="post-meta mb-3"><span class="post-date me-1 mb-1" title="created on 2023-11-09 00:00:00 +0000 UTC, updated on 2023-12-14 22:27:31 +0000 UTC.">November 9, 2023</span><span class="post-reading-time me-1 mb-1">15 min read</span><a href=/categories/data-streaming/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-category">
<i class="fas fa-fw fa-folder me-1"></i>Data Streaming</a><a href=/series/real-time-streaming-with-kafka-and-flink/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-series">
<i class="fas fa-fw fa-columns me-1"></i>Real Time Streaming With Kafka and Flink</a><a href=/tags/amazon-msk/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Amazon MSK</a><a href=/tags/apache-flink/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Flink</a><a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Kafka</a><a href=/tags/aws/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">AWS</a><a href=/tags/docker/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Docker</a><a href=/tags/docker-compose/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Docker Compose</a><a href=/tags/pyflink/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Pyflink</a><a href=/tags/python/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Python</a></div><picture class="d-flex justify-content-center"><source srcset=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured_hucc8053169eb3042cf56156294e716152_139114_0x270_resize_box_3.png type=image/png media="(max-width: 576px)" width=448 height=270><img class="post-featured-img h-auto w-auto mb-3" alt="Real Time Streaming with Kafka and Flink - Lab 2 Write data to Kafka from S3 using Flink" src=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured_hucc8053169eb3042cf56156294e716152_139114_0x480_resize_box_3.png width=797 height=480 data-src=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured.png></picture><p class="lead mb-3 text-body-emphasis">In this lab, we will create a Pyflink application that reads records from S3 and sends them into a Kafka topic. A custom pipeline Jar file will be created as the Kafka cluster is authenticated by IAM, and it will be demonstrated how to execute the app in a Flink cluster deployed on Docker as well as locally as a typical Python app. We can assume the S3 data is static metadata that needs to be joined into another stream, and this exercise can be useful for data enrichment.</p><div id=postTOC class="mb-3 text-surface"><h2 class=mb-3>Contents<a class="anchor ms-1" href=#postTOC></a></h2><nav id=TableOfContents><ul><li><a href=#architecture>Architecture</a></li><li><a href=#infrastructure>Infrastructure</a><ul><li><a href=#aws-infrastructure>AWS Infrastructure</a></li><li><a href=#flink-cluster-on-docker>Flink Cluster on Docker</a><ul><li><a href=#docker-image-with-python-and-pyflink>Docker Image with Python and Pyflink</a></li><li><a href=#flink-cluster-on-docker-compose>Flink Cluster on Docker Compose</a></li></ul></li></ul></li><li><a href=#pyflink-application>Pyflink Application</a><ul><li><a href=#flink-pipeline-jar>Flink Pipeline Jar</a></li><li><a href=#application-source>Application Source</a></li><li><a href=#run-application>Run Application</a><ul><li><a href=#execute-on-local-flink-cluster>Execute on Local Flink Cluster</a></li><li><a href=#execute-locally>Execute Locally</a></li></ul></li><li><a href=#monitor-topic>Monitor Topic</a></li></ul></li><li><a href=#summary>Summary</a></li></ul></nav><hr class=text-secondary></div><div class="post-content mb-3" data-bs-spy=scroll data-bs-target=#TableOfContents tabindex=0><div id=post-content-body><p>In this lab, we will create a Pyflink application that reads records from S3 and sends them into a Kafka topic. A custom pipeline Jar file will be created as the Kafka cluster is authenticated by IAM, and it will be demonstrated how to execute the app in a Flink cluster deployed on Docker as well as locally as a typical Python app. We can assume the S3 data is static metadata that needs to be joined into another stream, and this exercise can be useful for data enrichment.</p><ul><li><a href=/blog/2023-10-05-real-time-streaming-with-kafka-and-flink-1>Introduction</a></li><li><a href=/blog/2023-10-26-real-time-streaming-with-kafka-and-flink-2>Lab 1 Produce data to Kafka using Lambda</a></li><li><a href=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/#>Lab 2 Write data to Kafka from S3 using Flink</a> (this post)</li><li><a href=/blog/2023-11-16-real-time-streaming-with-kafka-and-flink-4>Lab 3 Transform and write data to S3 from Kafka using Flink</a></li><li><a href=/blog/2023-11-23-real-time-streaming-with-kafka-and-flink-5>Lab 4 Clean, Aggregate, and Enrich Events with Flink</a></li><li><a href=/blog/2023-11-30-real-time-streaming-with-kafka-and-flink-6>Lab 5 Write data to DynamoDB using Kafka Connect</a></li><li><a href=/blog/2023-12-14-real-time-streaming-with-kafka-and-flink-7>Lab 6 Consume data from Kafka using Lambda</a></li></ul><p>[<strong>Update 2023-11-06</strong>] Initially I planned to deploy Pyflink applications on <a href=https://aws.amazon.com/managed-service-apache-flink/ target=_blank rel="noopener noreferrer">Amazon Managed Service for Apache Flink<i class="fas fa-external-link-square-alt ms-1"></i></a>, but I changed the plan to use a local Flink cluster deployed on Docker. The main reasons are</p><ol><li>It is not clear how to configure a Pyflink application for the managed service. For example, Apache Flink supports <a href=https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/filesystems/overview/ target=_blank rel="noopener noreferrer">pluggable file systems<i class="fas fa-external-link-square-alt ms-1"></i></a> and the required dependency (eg <em>flink-s3-fs-hadoop-1.15.2.jar</em>) should be placed under the <em>plugins</em> folder. However, the sample Pyflink applications from <a href=https://github.com/aws-samples/pyflink-getting-started/tree/main/pyflink-examples target=_blank rel="noopener noreferrer">pyflink-getting-started<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href=https://github.com/aws-samples/amazon-kinesis-data-analytics-blueprints/tree/main/apps/python-table-api/msk-serverless-to-s3-tableapi-python target=_blank rel="noopener noreferrer">amazon-kinesis-data-analytics-blueprints<i class="fas fa-external-link-square-alt ms-1"></i></a> either ignore the S3 jar file for deployment or package it together with other dependencies - <em>none of them uses the S3 jar file as a plugin</em>. I tried multiple different configurations, but all ended up with an error whose code is <em>CodeError.InvalidApplicationCode</em>. I don&rsquo;t have such an issue when I deploy the app on a local Flink cluster and I haven&rsquo;t found a way to configure the app for the managed service as yet.</li><li>The Pyflink app for <em>Lab 4</em> requires the OpenSearch sink connector and the connector is available on <em>1.16.0+</em>. However, the latest Flink version of the managed service is still <em>1.15.2</em> and the sink connector is not available on it. Normally the latest version of the managed service is behind two minor versions of the official release, but it seems to take a little longer to catch up at the moment - the version 1.18.0 was released a while ago.</li></ol><h2 id=architecture data-numberify>Architecture<a class="anchor ms-1" href=#architecture></a></h2><p>Sample taxi ride data is stored in a S3 bucket, and a Pyflink application reads and ingests it into a Kafka topic on Amazon MSK. As <a href=https://flink.apache.org/ target=_blank rel="noopener noreferrer">Apache Flink<i class="fas fa-external-link-square-alt ms-1"></i></a> supports both stream and batch processing, we are able to process static data without an issue. We can assume the S3 data is static metadata that needs to be joined into a stream, and this exercise can be useful for data enrichment.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured.png loading=lazy width=1230 height=741></picture></p><h2 id=infrastructure data-numberify>Infrastructure<a class="anchor ms-1" href=#infrastructure></a></h2><h3 id=aws-infrastructure data-numberify>AWS Infrastructure<a class="anchor ms-1" href=#aws-infrastructure></a></h3><p>The AWS infrastructure is created using <a href=https://www.terraform.io/ target=_blank rel="noopener noreferrer">Terraform<i class="fas fa-external-link-square-alt ms-1"></i></a> and the source can be found in the <a href=https://github.com/jaehyeon-kim/flink-demos/tree/master/real-time-streaming-aws target=_blank rel="noopener noreferrer"><strong>GitHub repository</strong><i class="fas fa-external-link-square-alt ms-1"></i></a> of this post - see the <a href=/blog/2023-10-26-real-time-streaming-with-kafka-and-flink-2>previous post</a> for details. The infrastructure can be deployed (as well as destroyed) using Terraform CLI as shown below.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl><span class=c1># initialize</span>
</span></span><span class=line><span class=ln>2</span><span class=cl>$ terraform init
</span></span><span class=line><span class=ln>3</span><span class=cl><span class=c1># create an execution plan</span>
</span></span><span class=line><span class=ln>4</span><span class=cl>$ terraform plan
</span></span><span class=line><span class=ln>5</span><span class=cl><span class=c1># execute the actions proposed in a Terraform plan</span>
</span></span><span class=line><span class=ln>6</span><span class=cl>$ terraform apply -auto-approve<span class=o>=</span><span class=nb>true</span>
</span></span><span class=line><span class=ln>7</span><span class=cl>
</span></span><span class=line><span class=ln>8</span><span class=cl><span class=c1># # destroy all remote objects</span>
</span></span><span class=line><span class=ln>9</span><span class=cl><span class=c1># $ terraform destroy -auto-approve=true</span>
</span></span></code></pre></div><h3 id=flink-cluster-on-docker data-numberify>Flink Cluster on Docker<a class="anchor ms-1" href=#flink-cluster-on-docker></a></h3><h4 id=docker-image-with-python-and-pyflink data-numberify>Docker Image with Python and Pyflink<a class="anchor ms-1" href=#docker-image-with-python-and-pyflink></a></h4><p>The <a href=https://hub.docker.com/_/flink target=_blank rel="noopener noreferrer">official Flink docker image<i class="fas fa-external-link-square-alt ms-1"></i></a> doesn&rsquo;t include Python and the Pyflink package, and we need to build a custom image from it. Beginning with placing the S3 jar file (<em>flink-s3-fs-hadoop-1.15.2.jar</em>) under the <em>plugins</em> folder, the following image instals Python and the Pyflink package. It can be built as follows.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ docker build -t<span class=o>=</span>real-time-streaming-aws:1.17.1 .
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=ln> 1</span><span class=cl><span class=c># Dockerfile</span><span class=err>
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=err></span><span class=k>FROM</span><span class=s> flink:1.17.1</span><span class=err>
</span></span></span><span class=line><span class=ln> 3</span><span class=cl><span class=err>
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=err></span><span class=k>ARG</span> PYTHON_VERSION<span class=err>
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=err></span><span class=k>ENV</span> <span class=nv>PYTHON_VERSION</span><span class=o>=</span><span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=k>:-</span><span class=nv>3</span><span class=p>.8.10</span><span class=si>}</span><span class=err>
</span></span></span><span class=line><span class=ln> 6</span><span class=cl><span class=err></span><span class=k>ARG</span> FLINK_VERSION<span class=err>
</span></span></span><span class=line><span class=ln> 7</span><span class=cl><span class=err></span><span class=k>ENV</span> <span class=nv>FLINK_VERSION</span><span class=o>=</span><span class=si>${</span><span class=nv>FLINK_VERSION</span><span class=k>:-</span><span class=nv>1</span><span class=p>.17.1</span><span class=si>}</span><span class=err>
</span></span></span><span class=line><span class=ln> 8</span><span class=cl><span class=err>
</span></span></span><span class=line><span class=ln> 9</span><span class=cl><span class=err></span><span class=k>RUN</span> mkdir ./plugins/s3-fs-hadoop <span class=se>\
</span></span></span><span class=line><span class=ln>10</span><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> cp ./opt/flink-s3-fs-hadoop-<span class=si>${</span><span class=nv>FLINK_VERSION</span><span class=si>}</span>.jar ./plugins/s3-fs-hadoop <span class=err>
</span></span></span><span class=line><span class=ln>11</span><span class=cl><span class=err>
</span></span></span><span class=line><span class=ln>12</span><span class=cl><span class=err></span><span class=k>RUN</span> apt-get update -y <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>13</span><span class=cl><span class=se></span>  apt-get install -y build-essential libssl-dev zlib1g-dev libbz2-dev libffi-dev liblzma-dev <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=se></span>  wget https://www.python.org/ftp/python/<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span>/Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span>.tgz <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=se></span>  tar -xvf Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span>.tgz <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>16</span><span class=cl><span class=se></span>  <span class=nb>cd</span> Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span> <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>17</span><span class=cl><span class=se></span>  ./configure --without-tests --enable-shared <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>18</span><span class=cl><span class=se></span>  make -j6 <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>19</span><span class=cl><span class=se></span>  make install <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>20</span><span class=cl><span class=se></span>  ldconfig /usr/local/lib <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>21</span><span class=cl><span class=se></span>  <span class=nb>cd</span> .. <span class=o>&amp;&amp;</span> rm -f Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span>.tgz <span class=o>&amp;&amp;</span> rm -rf Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span> <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>22</span><span class=cl><span class=se></span>  ln -s /usr/local/bin/python3 /usr/local/bin/python <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>23</span><span class=cl><span class=se></span>  apt-get clean <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>24</span><span class=cl><span class=se></span>  rm -rf /var/lib/apt/lists/*<span class=err>
</span></span></span><span class=line><span class=ln>25</span><span class=cl><span class=err>
</span></span></span><span class=line><span class=ln>26</span><span class=cl><span class=err></span><span class=c># install PyFlink</span><span class=err>
</span></span></span><span class=line><span class=ln>27</span><span class=cl><span class=err></span><span class=k>RUN</span> pip3 install apache-flink<span class=o>==</span><span class=si>${</span><span class=nv>FLINK_VERSION</span><span class=si>}</span><span class=err>
</span></span></span><span class=line><span class=ln>28</span><span class=cl><span class=err>
</span></span></span><span class=line><span class=ln>29</span><span class=cl><span class=err></span><span class=c># add kafka client for Flink SQL client, will be added manually</span><span class=err>
</span></span></span><span class=line><span class=ln>30</span><span class=cl><span class=err></span><span class=k>RUN</span> wget -P /etc/lib/ https://repo.maven.apache.org/maven2/org/apache/kafka/kafka-clients/3.2.3/kafka-clients-3.2.3.jar<span class=p>;</span><span class=err>
</span></span></span></code></pre></div><h4 id=flink-cluster-on-docker-compose data-numberify>Flink Cluster on Docker Compose<a class="anchor ms-1" href=#flink-cluster-on-docker-compose></a></h4><p>The docker compose file includes services for a Flink cluster and <a href=https://docs.kpow.io/ce/ target=_blank rel="noopener noreferrer">Kpow Community Edition<i class="fas fa-external-link-square-alt ms-1"></i></a>. For the Flink cluster, both a single master container (<em>jobmanager</em>) and one task container (<em>taskmanager</em>) are created. The former runs the job <em>Dispatcher</em> and <em>ResourceManager</em> while <em>TaskManager</em> is run in the latter. Once a Flink app (job) is submitted to the <em>Dispatcher</em>, it spawns a <em>JobManager</em> thread and provides the <em>JobGraph</em> for execution. The <em>JobManager</em> requests the necessary processing slots from the <em>ResourceManager</em> and deploys the job for execution once the requested slots have been received.</p><p>Kafka bootstrap server addresses and AWS credentials are required for the Flink cluster and kpow app, which are specified as environment variables. The bootstrap server addresses can be obtained via terraform (<code>terraform output -json | jq -r '.msk_bootstrap_brokers_sasl_iam.value'</code>) or from AWS Console.</p><p>Finally, see the <a href=/blog/2023-10-26-real-time-streaming-with-kafka-and-flink-2>previous post</a> for details about how to configure the <em>kpow</em> app.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=ln> 1</span><span class=cl><span class=c># compose-msk.yml</span><span class=w>
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=w></span><span class=c># see compose-local-kafka.yml for a local kafka cluster instead of msk</span><span class=w>
</span></span></span><span class=line><span class=ln> 3</span><span class=cl><span class=w></span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;3.5&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 6</span><span class=cl><span class=w>  </span><span class=nt>jobmanager</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 7</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>real-time-streaming-aws:1.17.1</span><span class=w>
</span></span></span><span class=line><span class=ln> 8</span><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>jobmanager</span><span class=w>
</span></span></span><span class=line><span class=ln> 9</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>jobmanager</span><span class=w>
</span></span></span><span class=line><span class=ln>10</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>11</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;8081:8081&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>12</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>13</span><span class=cl><span class=w>      </span>- <span class=l>appnet</span><span class=w>
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=w>      </span>- <span class=l>./loader:/etc/flink</span><span class=w>
</span></span></span><span class=line><span class=ln>16</span><span class=cl><span class=w>      </span>- <span class=l>./exporter:/etc/flink/exporter</span><span class=w>
</span></span></span><span class=line><span class=ln>17</span><span class=cl><span class=w>      </span>- <span class=l>./package:/etc/package</span><span class=w>
</span></span></span><span class=line><span class=ln>18</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>19</span><span class=cl><span class=w>      </span>- <span class=l>BOOTSTRAP_SERVERS=$BOOTSTRAP_SERVERS</span><span class=w>
</span></span></span><span class=line><span class=ln>20</span><span class=cl><span class=w>      </span>- <span class=l>RUNTIME_ENV=DOCKER</span><span class=w>
</span></span></span><span class=line><span class=ln>21</span><span class=cl><span class=w>      </span>- <span class=l>AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID</span><span class=w>
</span></span></span><span class=line><span class=ln>22</span><span class=cl><span class=w>      </span>- <span class=l>AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY</span><span class=w>
</span></span></span><span class=line><span class=ln>23</span><span class=cl><span class=w>      </span><span class=c># - AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN</span><span class=w>
</span></span></span><span class=line><span class=ln>24</span><span class=cl><span class=w>      </span>- <span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=ln>25</span><span class=cl><span class=sd>        FLINK_PROPERTIES=
</span></span></span><span class=line><span class=ln>26</span><span class=cl><span class=sd>        jobmanager.rpc.address: jobmanager
</span></span></span><span class=line><span class=ln>27</span><span class=cl><span class=sd>        state.backend: filesystem
</span></span></span><span class=line><span class=ln>28</span><span class=cl><span class=sd>        state.checkpoints.dir: file:///tmp/flink-checkpoints
</span></span></span><span class=line><span class=ln>29</span><span class=cl><span class=sd>        heartbeat.interval: 1000
</span></span></span><span class=line><span class=ln>30</span><span class=cl><span class=sd>        heartbeat.timeout: 5000
</span></span></span><span class=line><span class=ln>31</span><span class=cl><span class=sd>        rest.flamegraph.enabled: true
</span></span></span><span class=line><span class=ln>32</span><span class=cl><span class=sd>        web.backpressure.refresh-interval: 10000</span><span class=w>        
</span></span></span><span class=line><span class=ln>33</span><span class=cl><span class=w>  </span><span class=nt>taskmanager</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>34</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>real-time-streaming-aws:1.17.1</span><span class=w>
</span></span></span><span class=line><span class=ln>35</span><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>taskmanager</span><span class=w>
</span></span></span><span class=line><span class=ln>36</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>taskmanager</span><span class=w>
</span></span></span><span class=line><span class=ln>37</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>38</span><span class=cl><span class=w>      </span>- <span class=l>appnet</span><span class=w>
</span></span></span><span class=line><span class=ln>39</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>40</span><span class=cl><span class=w>      </span>- <span class=l>flink_data:/tmp/</span><span class=w>
</span></span></span><span class=line><span class=ln>41</span><span class=cl><span class=w>      </span>- <span class=l>./:/etc/flink</span><span class=w>
</span></span></span><span class=line><span class=ln>42</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>43</span><span class=cl><span class=w>      </span>- <span class=l>BOOTSTRAP_SERVERS=$BOOTSTRAP_SERVERS</span><span class=w>
</span></span></span><span class=line><span class=ln>44</span><span class=cl><span class=w>      </span>- <span class=l>RUNTIME_ENV=DOCKER</span><span class=w>
</span></span></span><span class=line><span class=ln>45</span><span class=cl><span class=w>      </span>- <span class=l>AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID</span><span class=w>
</span></span></span><span class=line><span class=ln>46</span><span class=cl><span class=w>      </span>- <span class=l>AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY</span><span class=w>
</span></span></span><span class=line><span class=ln>47</span><span class=cl><span class=w>      </span><span class=c># - AWS_SESSION_TOKEN=$AWS_SESSION_TOKEN</span><span class=w>
</span></span></span><span class=line><span class=ln>48</span><span class=cl><span class=w>      </span>- <span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=ln>49</span><span class=cl><span class=sd>        FLINK_PROPERTIES=
</span></span></span><span class=line><span class=ln>50</span><span class=cl><span class=sd>        jobmanager.rpc.address: jobmanager
</span></span></span><span class=line><span class=ln>51</span><span class=cl><span class=sd>        taskmanager.numberOfTaskSlots: 5
</span></span></span><span class=line><span class=ln>52</span><span class=cl><span class=sd>        state.backend: filesystem
</span></span></span><span class=line><span class=ln>53</span><span class=cl><span class=sd>        state.checkpoints.dir: file:///tmp/flink-checkpoints
</span></span></span><span class=line><span class=ln>54</span><span class=cl><span class=sd>        heartbeat.interval: 1000
</span></span></span><span class=line><span class=ln>55</span><span class=cl><span class=sd>        heartbeat.timeout: 5000</span><span class=w>        
</span></span></span><span class=line><span class=ln>56</span><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>57</span><span class=cl><span class=w>      </span>- <span class=l>jobmanager</span><span class=w>
</span></span></span><span class=line><span class=ln>58</span><span class=cl><span class=w>  </span><span class=nt>kpow</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>59</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>factorhouse/kpow-ce:91.5.1</span><span class=w>
</span></span></span><span class=line><span class=ln>60</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kpow</span><span class=w>
</span></span></span><span class=line><span class=ln>61</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>62</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;3000:3000&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>63</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>64</span><span class=cl><span class=w>      </span>- <span class=l>appnet</span><span class=w>
</span></span></span><span class=line><span class=ln>65</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>66</span><span class=cl><span class=w>      </span><span class=nt>AWS_ACCESS_KEY_ID</span><span class=p>:</span><span class=w> </span><span class=l>$AWS_ACCESS_KEY_ID</span><span class=w>
</span></span></span><span class=line><span class=ln>67</span><span class=cl><span class=w>      </span><span class=nt>AWS_SECRET_ACCESS_KEY</span><span class=p>:</span><span class=w> </span><span class=l>$AWS_SECRET_ACCESS_KEY</span><span class=w>
</span></span></span><span class=line><span class=ln>68</span><span class=cl><span class=w>      </span><span class=c># AWS_SESSION_TOKEN: $AWS_SESSION_TOKEN</span><span class=w>
</span></span></span><span class=line><span class=ln>69</span><span class=cl><span class=w>      </span><span class=nt>BOOTSTRAP</span><span class=p>:</span><span class=w> </span><span class=l>$BOOTSTRAP_SERVERS</span><span class=w>
</span></span></span><span class=line><span class=ln>70</span><span class=cl><span class=w>      </span><span class=nt>SECURITY_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=l>SASL_SSL</span><span class=w>
</span></span></span><span class=line><span class=ln>71</span><span class=cl><span class=w>      </span><span class=nt>SASL_MECHANISM</span><span class=p>:</span><span class=w> </span><span class=l>AWS_MSK_IAM</span><span class=w>
</span></span></span><span class=line><span class=ln>72</span><span class=cl><span class=w>      </span><span class=nt>SASL_JAAS_CONFIG</span><span class=p>:</span><span class=w> </span><span class=l>software.amazon.msk.auth.iam.IAMLoginModule required;</span><span class=w>
</span></span></span><span class=line><span class=ln>73</span><span class=cl><span class=w>      </span><span class=nt>SASL_CLIENT_CALLBACK_HANDLER_CLASS</span><span class=p>:</span><span class=w> </span><span class=l>software.amazon.msk.auth.iam.IAMClientCallbackHandler</span><span class=w>
</span></span></span><span class=line><span class=ln>74</span><span class=cl><span class=w>    </span><span class=nt>env_file</span><span class=p>:</span><span class=w> </span><span class=c># https://kpow.io/get-started/#individual</span><span class=w>
</span></span></span><span class=line><span class=ln>75</span><span class=cl><span class=w>      </span>- <span class=l>./kpow.env</span><span class=w>
</span></span></span><span class=line><span class=ln>76</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln>77</span><span class=cl><span class=w></span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>78</span><span class=cl><span class=w>  </span><span class=nt>appnet</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>79</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>app-network</span><span class=w>
</span></span></span><span class=line><span class=ln>80</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln>81</span><span class=cl><span class=w></span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>82</span><span class=cl><span class=w>  </span><span class=nt>flink_data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>83</span><span class=cl><span class=w>    </span><span class=nt>driver</span><span class=p>:</span><span class=w> </span><span class=l>local</span><span class=w>
</span></span></span><span class=line><span class=ln>84</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>flink_data</span><span class=w>
</span></span></span></code></pre></div><p>The Docker Compose services can be deployed as shown below.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ docker-compose -f compose-msk.yml up -d
</span></span></code></pre></div><h2 id=pyflink-application data-numberify>Pyflink Application<a class="anchor ms-1" href=#pyflink-application></a></h2><h3 id=flink-pipeline-jar data-numberify>Flink Pipeline Jar<a class="anchor ms-1" href=#flink-pipeline-jar></a></h3><p>We are going to include all dependent Jar files with the <code>--jarfile</code> option, and it only accepts a single Jar file. Therefore, we have to create a custom Uber jar file that consolidates all dependent Jar files. On top of the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/connectors/table/kafka/ target=_blank rel="noopener noreferrer">Apache Kafka SQL Connector<i class="fas fa-external-link-square-alt ms-1"></i></a>, we also need the <a href=https://github.com/aws/aws-msk-iam-auth target=_blank rel="noopener noreferrer">Amazon MSK Library for AWS Identity and Access Management (MSK IAM Auth)<i class="fas fa-external-link-square-alt ms-1"></i></a> as the MSK cluster is authenticated via IAM. Note that we have to build the Jar file based on the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/datastream/kafka/ target=_blank rel="noopener noreferrer">Apache Kafka Connector<i class="fas fa-external-link-square-alt ms-1"></i></a> instead of the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/table/kafka/ target=_blank rel="noopener noreferrer">Apache Kafka SQL Connector<i class="fas fa-external-link-square-alt ms-1"></i></a> because the <em>MSK IAM Auth</em> library is not compatible with the latter due to shade relocation. After some search, I found an example from the <a href=https://github.com/aws-samples/amazon-kinesis-data-analytics-blueprints/tree/main/apps/python-table-api/msk-serverless-to-s3-tableapi-python/src/uber-jar-for-pyflink target=_blank rel="noopener noreferrer">amazon-kinesis-data-analytics-blueprints<i class="fas fa-external-link-square-alt ms-1"></i></a> and was able to modify the POM file with necessary dependencies for this post. The modified POM file can be shown below, and it creates the Uber Jar for this post - <em>lab2-pipeline-1.0.0.jar</em>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-xml data-lang=xml><span class=line><span class=ln>  1</span><span class=cl><span class=c>&lt;!-- package/lab2-pipeline/pom.xml --&gt;</span>
</span></span><span class=line><span class=ln>  2</span><span class=cl><span class=nt>&lt;project</span> <span class=na>xmlns=</span><span class=s>&#34;http://maven.apache.org/POM/4.0.0&#34;</span> <span class=na>xmlns:xsi=</span><span class=s>&#34;http://www.w3.org/2001/XMLSchema-instance&#34;</span>
</span></span><span class=line><span class=ln>  3</span><span class=cl>	<span class=na>xsi:schemaLocation=</span><span class=s>&#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=ln>  4</span><span class=cl>	<span class=nt>&lt;modelVersion&gt;</span>4.0.0<span class=nt>&lt;/modelVersion&gt;</span>
</span></span><span class=line><span class=ln>  5</span><span class=cl>
</span></span><span class=line><span class=ln>  6</span><span class=cl>	<span class=nt>&lt;groupId&gt;</span>com.amazonaws.services.kinesisanalytics<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln>  7</span><span class=cl>	<span class=nt>&lt;artifactId&gt;</span>lab2-pipeline<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln>  8</span><span class=cl>	<span class=nt>&lt;version&gt;</span>1.0.0<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln>  9</span><span class=cl>	<span class=nt>&lt;packaging&gt;</span>jar<span class=nt>&lt;/packaging&gt;</span>
</span></span><span class=line><span class=ln> 10</span><span class=cl>
</span></span><span class=line><span class=ln> 11</span><span class=cl>	<span class=nt>&lt;name&gt;</span>Uber Jar for PyFlink App<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=ln> 12</span><span class=cl>
</span></span><span class=line><span class=ln> 13</span><span class=cl>	<span class=nt>&lt;properties&gt;</span>
</span></span><span class=line><span class=ln> 14</span><span class=cl>		<span class=nt>&lt;project.build.sourceEncoding&gt;</span>UTF-8<span class=nt>&lt;/project.build.sourceEncoding&gt;</span>
</span></span><span class=line><span class=ln> 15</span><span class=cl>		<span class=nt>&lt;flink.version&gt;</span>1.17.1<span class=nt>&lt;/flink.version&gt;</span>
</span></span><span class=line><span class=ln> 16</span><span class=cl>		<span class=nt>&lt;target.java.version&gt;</span>1.11<span class=nt>&lt;/target.java.version&gt;</span>
</span></span><span class=line><span class=ln> 17</span><span class=cl>		<span class=nt>&lt;jdk.version&gt;</span>11<span class=nt>&lt;/jdk.version&gt;</span>
</span></span><span class=line><span class=ln> 18</span><span class=cl>		<span class=nt>&lt;scala.binary.version&gt;</span>2.12<span class=nt>&lt;/scala.binary.version&gt;</span>
</span></span><span class=line><span class=ln> 19</span><span class=cl>		<span class=nt>&lt;kda.connectors.version&gt;</span>2.0.0<span class=nt>&lt;/kda.connectors.version&gt;</span>
</span></span><span class=line><span class=ln> 20</span><span class=cl>		<span class=nt>&lt;kda.runtime.version&gt;</span>1.2.0<span class=nt>&lt;/kda.runtime.version&gt;</span>
</span></span><span class=line><span class=ln> 21</span><span class=cl>		<span class=nt>&lt;kafka.clients.version&gt;</span>2.8.1<span class=nt>&lt;/kafka.clients.version&gt;</span>
</span></span><span class=line><span class=ln> 22</span><span class=cl>		<span class=nt>&lt;log4j.version&gt;</span>2.17.1<span class=nt>&lt;/log4j.version&gt;</span>
</span></span><span class=line><span class=ln> 23</span><span class=cl>		<span class=nt>&lt;aws-msk-iam-auth.version&gt;</span>1.1.7<span class=nt>&lt;/aws-msk-iam-auth.version&gt;</span>
</span></span><span class=line><span class=ln> 24</span><span class=cl>	<span class=nt>&lt;/properties&gt;</span>
</span></span><span class=line><span class=ln> 25</span><span class=cl>
</span></span><span class=line><span class=ln> 26</span><span class=cl>	<span class=nt>&lt;repositories&gt;</span>
</span></span><span class=line><span class=ln> 27</span><span class=cl>		<span class=nt>&lt;repository&gt;</span>
</span></span><span class=line><span class=ln> 28</span><span class=cl>			<span class=nt>&lt;id&gt;</span>apache.snapshots<span class=nt>&lt;/id&gt;</span>
</span></span><span class=line><span class=ln> 29</span><span class=cl>			<span class=nt>&lt;name&gt;</span>Apache Development Snapshot Repository<span class=nt>&lt;/name&gt;</span>
</span></span><span class=line><span class=ln> 30</span><span class=cl>			<span class=nt>&lt;url&gt;</span>https://repository.apache.org/content/repositories/snapshots/<span class=nt>&lt;/url&gt;</span>
</span></span><span class=line><span class=ln> 31</span><span class=cl>			<span class=nt>&lt;releases&gt;</span>
</span></span><span class=line><span class=ln> 32</span><span class=cl>				<span class=nt>&lt;enabled&gt;</span>false<span class=nt>&lt;/enabled&gt;</span>
</span></span><span class=line><span class=ln> 33</span><span class=cl>			<span class=nt>&lt;/releases&gt;</span>
</span></span><span class=line><span class=ln> 34</span><span class=cl>			<span class=nt>&lt;snapshots&gt;</span>
</span></span><span class=line><span class=ln> 35</span><span class=cl>				<span class=nt>&lt;enabled&gt;</span>true<span class=nt>&lt;/enabled&gt;</span>
</span></span><span class=line><span class=ln> 36</span><span class=cl>			<span class=nt>&lt;/snapshots&gt;</span>
</span></span><span class=line><span class=ln> 37</span><span class=cl>		<span class=nt>&lt;/repository&gt;</span>
</span></span><span class=line><span class=ln> 38</span><span class=cl>	<span class=nt>&lt;/repositories&gt;</span>
</span></span><span class=line><span class=ln> 39</span><span class=cl>
</span></span><span class=line><span class=ln> 40</span><span class=cl>	<span class=nt>&lt;dependencies&gt;</span>
</span></span><span class=line><span class=ln> 41</span><span class=cl>
</span></span><span class=line><span class=ln> 42</span><span class=cl>		<span class=nt>&lt;dependency&gt;</span>
</span></span><span class=line><span class=ln> 43</span><span class=cl>			<span class=nt>&lt;groupId&gt;</span>org.apache.flink<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln> 44</span><span class=cl>			<span class=nt>&lt;artifactId&gt;</span>flink-connector-base<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln> 45</span><span class=cl>			<span class=nt>&lt;version&gt;</span>${flink.version}<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln> 46</span><span class=cl>		<span class=nt>&lt;/dependency&gt;</span>
</span></span><span class=line><span class=ln> 47</span><span class=cl>
</span></span><span class=line><span class=ln> 48</span><span class=cl>		<span class=nt>&lt;dependency&gt;</span>
</span></span><span class=line><span class=ln> 49</span><span class=cl>			<span class=nt>&lt;groupId&gt;</span>org.apache.flink<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln> 50</span><span class=cl>			<span class=nt>&lt;artifactId&gt;</span>flink-connector-kafka<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln> 51</span><span class=cl>			<span class=nt>&lt;version&gt;</span>${flink.version}<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln> 52</span><span class=cl>		<span class=nt>&lt;/dependency&gt;</span>
</span></span><span class=line><span class=ln> 53</span><span class=cl>
</span></span><span class=line><span class=ln> 54</span><span class=cl>		<span class=nt>&lt;dependency&gt;</span>
</span></span><span class=line><span class=ln> 55</span><span class=cl>			<span class=nt>&lt;groupId&gt;</span>org.apache.flink<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln> 56</span><span class=cl>			<span class=nt>&lt;artifactId&gt;</span>flink-connector-files<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln> 57</span><span class=cl>			<span class=nt>&lt;version&gt;</span>${flink.version}<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln> 58</span><span class=cl>		<span class=nt>&lt;/dependency&gt;</span>
</span></span><span class=line><span class=ln> 59</span><span class=cl>
</span></span><span class=line><span class=ln> 60</span><span class=cl>		<span class=nt>&lt;dependency&gt;</span>
</span></span><span class=line><span class=ln> 61</span><span class=cl>			<span class=nt>&lt;groupId&gt;</span>org.apache.kafka<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln> 62</span><span class=cl>			<span class=nt>&lt;artifactId&gt;</span>kafka-clients<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln> 63</span><span class=cl>			<span class=nt>&lt;version&gt;</span>${kafka.clients.version}<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln> 64</span><span class=cl>		<span class=nt>&lt;/dependency&gt;</span>
</span></span><span class=line><span class=ln> 65</span><span class=cl>
</span></span><span class=line><span class=ln> 66</span><span class=cl>		<span class=nt>&lt;dependency&gt;</span>
</span></span><span class=line><span class=ln> 67</span><span class=cl>			<span class=nt>&lt;groupId&gt;</span>software.amazon.msk<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln> 68</span><span class=cl>			<span class=nt>&lt;artifactId&gt;</span>aws-msk-iam-auth<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln> 69</span><span class=cl>			<span class=nt>&lt;version&gt;</span>${aws-msk-iam-auth.version}<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln> 70</span><span class=cl>		<span class=nt>&lt;/dependency&gt;</span>
</span></span><span class=line><span class=ln> 71</span><span class=cl>
</span></span><span class=line><span class=ln> 72</span><span class=cl>		<span class=c>&lt;!-- Add logging framework, to produce console output when running in the IDE. --&gt;</span>
</span></span><span class=line><span class=ln> 73</span><span class=cl>		<span class=c>&lt;!-- These dependencies are excluded from the application JAR by default. --&gt;</span>
</span></span><span class=line><span class=ln> 74</span><span class=cl>		<span class=nt>&lt;dependency&gt;</span>
</span></span><span class=line><span class=ln> 75</span><span class=cl>			<span class=nt>&lt;groupId&gt;</span>org.apache.logging.log4j<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln> 76</span><span class=cl>			<span class=nt>&lt;artifactId&gt;</span>log4j-slf4j-impl<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln> 77</span><span class=cl>			<span class=nt>&lt;version&gt;</span>${log4j.version}<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln> 78</span><span class=cl>			<span class=nt>&lt;scope&gt;</span>runtime<span class=nt>&lt;/scope&gt;</span>
</span></span><span class=line><span class=ln> 79</span><span class=cl>		<span class=nt>&lt;/dependency&gt;</span>
</span></span><span class=line><span class=ln> 80</span><span class=cl>		<span class=nt>&lt;dependency&gt;</span>
</span></span><span class=line><span class=ln> 81</span><span class=cl>			<span class=nt>&lt;groupId&gt;</span>org.apache.logging.log4j<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln> 82</span><span class=cl>			<span class=nt>&lt;artifactId&gt;</span>log4j-api<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln> 83</span><span class=cl>			<span class=nt>&lt;version&gt;</span>${log4j.version}<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln> 84</span><span class=cl>			<span class=nt>&lt;scope&gt;</span>runtime<span class=nt>&lt;/scope&gt;</span>
</span></span><span class=line><span class=ln> 85</span><span class=cl>		<span class=nt>&lt;/dependency&gt;</span>
</span></span><span class=line><span class=ln> 86</span><span class=cl>		<span class=nt>&lt;dependency&gt;</span>
</span></span><span class=line><span class=ln> 87</span><span class=cl>			<span class=nt>&lt;groupId&gt;</span>org.apache.logging.log4j<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln> 88</span><span class=cl>			<span class=nt>&lt;artifactId&gt;</span>log4j-core<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln> 89</span><span class=cl>			<span class=nt>&lt;version&gt;</span>${log4j.version}<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln> 90</span><span class=cl>			<span class=nt>&lt;scope&gt;</span>runtime<span class=nt>&lt;/scope&gt;</span>
</span></span><span class=line><span class=ln> 91</span><span class=cl>		<span class=nt>&lt;/dependency&gt;</span>
</span></span><span class=line><span class=ln> 92</span><span class=cl>	<span class=nt>&lt;/dependencies&gt;</span>
</span></span><span class=line><span class=ln> 93</span><span class=cl>
</span></span><span class=line><span class=ln> 94</span><span class=cl>	<span class=nt>&lt;build&gt;</span>
</span></span><span class=line><span class=ln> 95</span><span class=cl>		<span class=nt>&lt;plugins&gt;</span>
</span></span><span class=line><span class=ln> 96</span><span class=cl>
</span></span><span class=line><span class=ln> 97</span><span class=cl>			<span class=c>&lt;!-- Java Compiler --&gt;</span>
</span></span><span class=line><span class=ln> 98</span><span class=cl>			<span class=nt>&lt;plugin&gt;</span>
</span></span><span class=line><span class=ln> 99</span><span class=cl>				<span class=nt>&lt;groupId&gt;</span>org.apache.maven.plugins<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln>100</span><span class=cl>				<span class=nt>&lt;artifactId&gt;</span>maven-compiler-plugin<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln>101</span><span class=cl>				<span class=nt>&lt;version&gt;</span>3.8.0<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln>102</span><span class=cl>				<span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=ln>103</span><span class=cl>					<span class=nt>&lt;source&gt;</span>${jdk.version}<span class=nt>&lt;/source&gt;</span>
</span></span><span class=line><span class=ln>104</span><span class=cl>					<span class=nt>&lt;target&gt;</span>${jdk.version}<span class=nt>&lt;/target&gt;</span>
</span></span><span class=line><span class=ln>105</span><span class=cl>				<span class=nt>&lt;/configuration&gt;</span>
</span></span><span class=line><span class=ln>106</span><span class=cl>			<span class=nt>&lt;/plugin&gt;</span>
</span></span><span class=line><span class=ln>107</span><span class=cl>
</span></span><span class=line><span class=ln>108</span><span class=cl>			<span class=c>&lt;!-- We use the maven-shade plugin to create a fat jar that contains all necessary dependencies. --&gt;</span>
</span></span><span class=line><span class=ln>109</span><span class=cl>			<span class=c>&lt;!-- Change the value of &lt;mainClass&gt;...&lt;/mainClass&gt; if your program entry point changes. --&gt;</span>
</span></span><span class=line><span class=ln>110</span><span class=cl>			<span class=nt>&lt;plugin&gt;</span>
</span></span><span class=line><span class=ln>111</span><span class=cl>				<span class=nt>&lt;groupId&gt;</span>org.apache.maven.plugins<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln>112</span><span class=cl>				<span class=nt>&lt;artifactId&gt;</span>maven-shade-plugin<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln>113</span><span class=cl>				<span class=nt>&lt;version&gt;</span>3.4.1<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln>114</span><span class=cl>				<span class=nt>&lt;executions&gt;</span>
</span></span><span class=line><span class=ln>115</span><span class=cl>					<span class=c>&lt;!-- Run shade goal on package phase --&gt;</span>
</span></span><span class=line><span class=ln>116</span><span class=cl>					<span class=nt>&lt;execution&gt;</span>
</span></span><span class=line><span class=ln>117</span><span class=cl>						<span class=nt>&lt;phase&gt;</span>package<span class=nt>&lt;/phase&gt;</span>
</span></span><span class=line><span class=ln>118</span><span class=cl>						<span class=nt>&lt;goals&gt;</span>
</span></span><span class=line><span class=ln>119</span><span class=cl>							<span class=nt>&lt;goal&gt;</span>shade<span class=nt>&lt;/goal&gt;</span>
</span></span><span class=line><span class=ln>120</span><span class=cl>						<span class=nt>&lt;/goals&gt;</span>
</span></span><span class=line><span class=ln>121</span><span class=cl>						<span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=ln>122</span><span class=cl>							<span class=nt>&lt;artifactSet&gt;</span>
</span></span><span class=line><span class=ln>123</span><span class=cl>								<span class=nt>&lt;excludes&gt;</span>
</span></span><span class=line><span class=ln>124</span><span class=cl>									<span class=nt>&lt;exclude&gt;</span>org.apache.flink:force-shading<span class=nt>&lt;/exclude&gt;</span>
</span></span><span class=line><span class=ln>125</span><span class=cl>									<span class=nt>&lt;exclude&gt;</span>com.google.code.findbugs:jsr305<span class=nt>&lt;/exclude&gt;</span>
</span></span><span class=line><span class=ln>126</span><span class=cl>									<span class=nt>&lt;exclude&gt;</span>org.slf4j:*<span class=nt>&lt;/exclude&gt;</span>
</span></span><span class=line><span class=ln>127</span><span class=cl>									<span class=nt>&lt;exclude&gt;</span>org.apache.logging.log4j:*<span class=nt>&lt;/exclude&gt;</span>
</span></span><span class=line><span class=ln>128</span><span class=cl>								<span class=nt>&lt;/excludes&gt;</span>
</span></span><span class=line><span class=ln>129</span><span class=cl>							<span class=nt>&lt;/artifactSet&gt;</span>
</span></span><span class=line><span class=ln>130</span><span class=cl>							<span class=nt>&lt;filters&gt;</span>
</span></span><span class=line><span class=ln>131</span><span class=cl>								<span class=nt>&lt;filter&gt;</span>
</span></span><span class=line><span class=ln>132</span><span class=cl>									<span class=c>&lt;!-- Do not copy the signatures in the META-INF folder.
</span></span></span><span class=line><span class=ln>133</span><span class=cl><span class=c>									Otherwise, this might cause SecurityExceptions when using the JAR. --&gt;</span>
</span></span><span class=line><span class=ln>134</span><span class=cl>									<span class=nt>&lt;artifact&gt;</span>*:*<span class=nt>&lt;/artifact&gt;</span>
</span></span><span class=line><span class=ln>135</span><span class=cl>									<span class=nt>&lt;excludes&gt;</span>
</span></span><span class=line><span class=ln>136</span><span class=cl>										<span class=nt>&lt;exclude&gt;</span>META-INF/*.SF<span class=nt>&lt;/exclude&gt;</span>
</span></span><span class=line><span class=ln>137</span><span class=cl>										<span class=nt>&lt;exclude&gt;</span>META-INF/*.DSA<span class=nt>&lt;/exclude&gt;</span>
</span></span><span class=line><span class=ln>138</span><span class=cl>										<span class=nt>&lt;exclude&gt;</span>META-INF/*.RSA<span class=nt>&lt;/exclude&gt;</span>
</span></span><span class=line><span class=ln>139</span><span class=cl>									<span class=nt>&lt;/excludes&gt;</span>
</span></span><span class=line><span class=ln>140</span><span class=cl>								<span class=nt>&lt;/filter&gt;</span>
</span></span><span class=line><span class=ln>141</span><span class=cl>							<span class=nt>&lt;/filters&gt;</span>
</span></span><span class=line><span class=ln>142</span><span class=cl>							<span class=nt>&lt;transformers&gt;</span>
</span></span><span class=line><span class=ln>143</span><span class=cl>								<span class=nt>&lt;transformer</span> <span class=na>implementation=</span><span class=s>&#34;org.apache.maven.plugins.shade.resource.ServicesResourceTransformer&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=ln>144</span><span class=cl>							<span class=nt>&lt;/transformers&gt;</span>
</span></span><span class=line><span class=ln>145</span><span class=cl>						<span class=nt>&lt;/configuration&gt;</span>
</span></span><span class=line><span class=ln>146</span><span class=cl>					<span class=nt>&lt;/execution&gt;</span>
</span></span><span class=line><span class=ln>147</span><span class=cl>				<span class=nt>&lt;/executions&gt;</span>
</span></span><span class=line><span class=ln>148</span><span class=cl>			<span class=nt>&lt;/plugin&gt;</span>
</span></span><span class=line><span class=ln>149</span><span class=cl>		<span class=nt>&lt;/plugins&gt;</span>
</span></span><span class=line><span class=ln>150</span><span class=cl>
</span></span><span class=line><span class=ln>151</span><span class=cl>		<span class=nt>&lt;pluginManagement&gt;</span>
</span></span><span class=line><span class=ln>152</span><span class=cl>			<span class=nt>&lt;plugins&gt;</span>
</span></span><span class=line><span class=ln>153</span><span class=cl>
</span></span><span class=line><span class=ln>154</span><span class=cl>				<span class=c>&lt;!-- This improves the out-of-the-box experience in Eclipse by resolving some warnings. --&gt;</span>
</span></span><span class=line><span class=ln>155</span><span class=cl>				<span class=nt>&lt;plugin&gt;</span>
</span></span><span class=line><span class=ln>156</span><span class=cl>					<span class=nt>&lt;groupId&gt;</span>org.eclipse.m2e<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln>157</span><span class=cl>					<span class=nt>&lt;artifactId&gt;</span>lifecycle-mapping<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln>158</span><span class=cl>					<span class=nt>&lt;version&gt;</span>1.0.0<span class=nt>&lt;/version&gt;</span>
</span></span><span class=line><span class=ln>159</span><span class=cl>					<span class=nt>&lt;configuration&gt;</span>
</span></span><span class=line><span class=ln>160</span><span class=cl>						<span class=nt>&lt;lifecycleMappingMetadata&gt;</span>
</span></span><span class=line><span class=ln>161</span><span class=cl>							<span class=nt>&lt;pluginExecutions&gt;</span>
</span></span><span class=line><span class=ln>162</span><span class=cl>								<span class=nt>&lt;pluginExecution&gt;</span>
</span></span><span class=line><span class=ln>163</span><span class=cl>									<span class=nt>&lt;pluginExecutionFilter&gt;</span>
</span></span><span class=line><span class=ln>164</span><span class=cl>										<span class=nt>&lt;groupId&gt;</span>org.apache.maven.plugins<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln>165</span><span class=cl>										<span class=nt>&lt;artifactId&gt;</span>maven-shade-plugin<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln>166</span><span class=cl>										<span class=nt>&lt;versionRange&gt;</span>[3.1.1,)<span class=nt>&lt;/versionRange&gt;</span>
</span></span><span class=line><span class=ln>167</span><span class=cl>										<span class=nt>&lt;goals&gt;</span>
</span></span><span class=line><span class=ln>168</span><span class=cl>											<span class=nt>&lt;goal&gt;</span>shade<span class=nt>&lt;/goal&gt;</span>
</span></span><span class=line><span class=ln>169</span><span class=cl>										<span class=nt>&lt;/goals&gt;</span>
</span></span><span class=line><span class=ln>170</span><span class=cl>									<span class=nt>&lt;/pluginExecutionFilter&gt;</span>
</span></span><span class=line><span class=ln>171</span><span class=cl>									<span class=nt>&lt;action&gt;</span>
</span></span><span class=line><span class=ln>172</span><span class=cl>										<span class=nt>&lt;ignore/&gt;</span>
</span></span><span class=line><span class=ln>173</span><span class=cl>									<span class=nt>&lt;/action&gt;</span>
</span></span><span class=line><span class=ln>174</span><span class=cl>								<span class=nt>&lt;/pluginExecution&gt;</span>
</span></span><span class=line><span class=ln>175</span><span class=cl>								<span class=nt>&lt;pluginExecution&gt;</span>
</span></span><span class=line><span class=ln>176</span><span class=cl>									<span class=nt>&lt;pluginExecutionFilter&gt;</span>
</span></span><span class=line><span class=ln>177</span><span class=cl>										<span class=nt>&lt;groupId&gt;</span>org.apache.maven.plugins<span class=nt>&lt;/groupId&gt;</span>
</span></span><span class=line><span class=ln>178</span><span class=cl>										<span class=nt>&lt;artifactId&gt;</span>maven-compiler-plugin<span class=nt>&lt;/artifactId&gt;</span>
</span></span><span class=line><span class=ln>179</span><span class=cl>										<span class=nt>&lt;versionRange&gt;</span>[3.1,)<span class=nt>&lt;/versionRange&gt;</span>
</span></span><span class=line><span class=ln>180</span><span class=cl>										<span class=nt>&lt;goals&gt;</span>
</span></span><span class=line><span class=ln>181</span><span class=cl>											<span class=nt>&lt;goal&gt;</span>testCompile<span class=nt>&lt;/goal&gt;</span>
</span></span><span class=line><span class=ln>182</span><span class=cl>											<span class=nt>&lt;goal&gt;</span>compile<span class=nt>&lt;/goal&gt;</span>
</span></span><span class=line><span class=ln>183</span><span class=cl>										<span class=nt>&lt;/goals&gt;</span>
</span></span><span class=line><span class=ln>184</span><span class=cl>									<span class=nt>&lt;/pluginExecutionFilter&gt;</span>
</span></span><span class=line><span class=ln>185</span><span class=cl>									<span class=nt>&lt;action&gt;</span>
</span></span><span class=line><span class=ln>186</span><span class=cl>										<span class=nt>&lt;ignore/&gt;</span>
</span></span><span class=line><span class=ln>187</span><span class=cl>									<span class=nt>&lt;/action&gt;</span>
</span></span><span class=line><span class=ln>188</span><span class=cl>								<span class=nt>&lt;/pluginExecution&gt;</span>
</span></span><span class=line><span class=ln>189</span><span class=cl>							<span class=nt>&lt;/pluginExecutions&gt;</span>
</span></span><span class=line><span class=ln>190</span><span class=cl>						<span class=nt>&lt;/lifecycleMappingMetadata&gt;</span>
</span></span><span class=line><span class=ln>191</span><span class=cl>					<span class=nt>&lt;/configuration&gt;</span>
</span></span><span class=line><span class=ln>192</span><span class=cl>				<span class=nt>&lt;/plugin&gt;</span>
</span></span><span class=line><span class=ln>193</span><span class=cl>			<span class=nt>&lt;/plugins&gt;</span>
</span></span><span class=line><span class=ln>194</span><span class=cl>		<span class=nt>&lt;/pluginManagement&gt;</span>
</span></span><span class=line><span class=ln>195</span><span class=cl>	<span class=nt>&lt;/build&gt;</span>
</span></span><span class=line><span class=ln>196</span><span class=cl><span class=nt>&lt;/project&gt;</span>
</span></span></code></pre></div><p>The Uber Jar file can be built using the following script (<em>build.sh</em>).</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl><span class=c1># build.sh</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1>#!/usr/bin/env bash</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl><span class=nv>SCRIPT_DIR</span><span class=o>=</span><span class=s2>&#34;</span><span class=k>$(</span><span class=nb>cd</span> <span class=k>$(</span>dirname <span class=s2>&#34;</span><span class=nv>$0</span><span class=s2>&#34;</span><span class=k>)</span><span class=p>;</span> <span class=nb>pwd</span><span class=k>)</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=nv>SRC_PATH</span><span class=o>=</span><span class=nv>$SCRIPT_DIR</span>/package
</span></span><span class=line><span class=ln> 5</span><span class=cl>
</span></span><span class=line><span class=ln> 6</span><span class=cl><span class=c1># remove contents under $SRC_PATH (except for the folders beginging with lab)</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl><span class=nb>shopt</span> -s extglob
</span></span><span class=line><span class=ln> 8</span><span class=cl>rm -rf <span class=nv>$SRC_PATH</span>/!<span class=o>(</span>lab*<span class=o>)</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>
</span></span><span class=line><span class=ln>10</span><span class=cl><span class=c1>## Generate Uber Jar for PyFlink app for MSK cluster with IAM authN</span>
</span></span><span class=line><span class=ln>11</span><span class=cl><span class=nb>echo</span> <span class=s2>&#34;generate Uber jar for PyFlink app...&#34;</span>
</span></span><span class=line><span class=ln>12</span><span class=cl>mkdir <span class=nv>$SRC_PATH</span>/lib
</span></span><span class=line><span class=ln>13</span><span class=cl>mvn clean install -f <span class=nv>$SRC_PATH</span>/lab2-pipeline/pom.xml <span class=se>\
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> mv <span class=nv>$SRC_PATH</span>/lab2-pipeline/target/lab2-pipeline-1.0.0.jar <span class=nv>$SRC_PATH</span>/lib <span class=se>\
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=se></span>  <span class=o>&amp;&amp;</span> rm -rf <span class=nv>$SRC_PATH</span>/lab2-pipeline/target
</span></span></code></pre></div><h3 id=application-source data-numberify>Application Source<a class="anchor ms-1" href=#application-source></a></h3><p>The Flink application is developed using the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/dev/python/table_api_tutorial/ target=_blank rel="noopener noreferrer">Table API<i class="fas fa-external-link-square-alt ms-1"></i></a>. The source uses the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/connectors/table/filesystem/ target=_blank rel="noopener noreferrer">FileSystem SQL Connector<i class="fas fa-external-link-square-alt ms-1"></i></a> and a table is created to read records in a S3 bucket. As mentioned earlier, the S3 file system is accessible as the S3 jar file (<em>flink-s3-fs-hadoop-1.17.1.jar</em>) is placed under the <em>plugins</em> folder of the custom Docker image. The sink table is created to write the source records into a Kafka topic. As the Kafka cluster is authenticated via IAM, additional table options are configured.</p><p>In the <em>main</em> method, we create all the source and sink tables after mapping relevant application properties. Then the output records are inserted into the output Kafka topic. Note that the output records are printed in the terminal additionally when the app is running locally for ease of checking them.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=ln>  1</span><span class=cl><span class=c1># loader/processor.py</span>
</span></span><span class=line><span class=ln>  2</span><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=ln>  3</span><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=ln>  4</span><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=ln>  5</span><span class=cl>
</span></span><span class=line><span class=ln>  6</span><span class=cl><span class=kn>from</span> <span class=nn>pyflink.table</span> <span class=kn>import</span> <span class=n>EnvironmentSettings</span><span class=p>,</span> <span class=n>TableEnvironment</span>
</span></span><span class=line><span class=ln>  7</span><span class=cl>
</span></span><span class=line><span class=ln>  8</span><span class=cl><span class=n>RUNTIME_ENV</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;RUNTIME_ENV&#34;</span><span class=p>,</span> <span class=s2>&#34;LOCAL&#34;</span><span class=p>)</span>  <span class=c1># LOCAL or DOCKER</span>
</span></span><span class=line><span class=ln>  9</span><span class=cl><span class=n>BOOTSTRAP_SERVERS</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;BOOTSTRAP_SERVERS&#34;</span><span class=p>)</span>  <span class=c1># overwrite app config</span>
</span></span><span class=line><span class=ln> 10</span><span class=cl>
</span></span><span class=line><span class=ln> 11</span><span class=cl><span class=n>env_settings</span> <span class=o>=</span> <span class=n>EnvironmentSettings</span><span class=o>.</span><span class=n>in_streaming_mode</span><span class=p>()</span>
</span></span><span class=line><span class=ln> 12</span><span class=cl><span class=n>table_env</span> <span class=o>=</span> <span class=n>TableEnvironment</span><span class=o>.</span><span class=n>create</span><span class=p>(</span><span class=n>env_settings</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 13</span><span class=cl>
</span></span><span class=line><span class=ln> 14</span><span class=cl><span class=k>if</span> <span class=n>RUNTIME_ENV</span> <span class=o>==</span> <span class=s2>&#34;LOCAL&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 15</span><span class=cl>    <span class=n>CURRENT_DIR</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>realpath</span><span class=p>(</span><span class=vm>__file__</span><span class=p>))</span>
</span></span><span class=line><span class=ln> 16</span><span class=cl>    <span class=n>PARENT_DIR</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>CURRENT_DIR</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 17</span><span class=cl>    <span class=n>PIPELINE_JAR</span> <span class=o>=</span> <span class=s2>&#34;lab2-pipeline-1.0.0.jar&#34;</span>
</span></span><span class=line><span class=ln> 18</span><span class=cl>    <span class=n>APPLICATION_PROPERTIES_FILE_PATH</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>CURRENT_DIR</span><span class=p>,</span> <span class=s2>&#34;application_properties.json&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 19</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;file://</span><span class=si>{</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>PARENT_DIR</span><span class=p>,</span> <span class=s1>&#39;package&#39;</span><span class=p>,</span> <span class=s1>&#39;lib&#39;</span><span class=p>,</span> <span class=n>PIPELINE_JAR</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 20</span><span class=cl>    <span class=n>table_env</span><span class=o>.</span><span class=n>get_config</span><span class=p>()</span><span class=o>.</span><span class=n>set</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 21</span><span class=cl>        <span class=s2>&#34;pipeline.jars&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 22</span><span class=cl>        <span class=sa>f</span><span class=s2>&#34;file://</span><span class=si>{</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>PARENT_DIR</span><span class=p>,</span> <span class=s1>&#39;package&#39;</span><span class=p>,</span> <span class=s1>&#39;lib&#39;</span><span class=p>,</span> <span class=n>PIPELINE_JAR</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 23</span><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=ln> 24</span><span class=cl><span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 25</span><span class=cl>    <span class=n>APPLICATION_PROPERTIES_FILE_PATH</span> <span class=o>=</span> <span class=s2>&#34;/etc/flink/loader/application_properties.json&#34;</span>
</span></span><span class=line><span class=ln> 26</span><span class=cl>
</span></span><span class=line><span class=ln> 27</span><span class=cl>
</span></span><span class=line><span class=ln> 28</span><span class=cl><span class=k>def</span> <span class=nf>get_application_properties</span><span class=p>():</span>
</span></span><span class=line><span class=ln> 29</span><span class=cl>    <span class=k>if</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>isfile</span><span class=p>(</span><span class=n>APPLICATION_PROPERTIES_FILE_PATH</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 30</span><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>APPLICATION_PROPERTIES_FILE_PATH</span><span class=p>,</span> <span class=s2>&#34;r&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>file</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 31</span><span class=cl>            <span class=n>contents</span> <span class=o>=</span> <span class=n>file</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=ln> 32</span><span class=cl>            <span class=n>properties</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>contents</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 33</span><span class=cl>            <span class=k>return</span> <span class=n>properties</span>
</span></span><span class=line><span class=ln> 34</span><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 35</span><span class=cl>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;A file at &#39;</span><span class=si>{</span><span class=n>APPLICATION_PROPERTIES_FILE_PATH</span><span class=si>}</span><span class=s2>&#39; was not found&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 36</span><span class=cl>
</span></span><span class=line><span class=ln> 37</span><span class=cl>
</span></span><span class=line><span class=ln> 38</span><span class=cl><span class=k>def</span> <span class=nf>property_map</span><span class=p>(</span><span class=n>props</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span> <span class=n>property_group_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 39</span><span class=cl>    <span class=k>for</span> <span class=n>prop</span> <span class=ow>in</span> <span class=n>props</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 40</span><span class=cl>        <span class=k>if</span> <span class=n>prop</span><span class=p>[</span><span class=s2>&#34;PropertyGroupId&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=n>property_group_id</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 41</span><span class=cl>            <span class=k>return</span> <span class=n>prop</span><span class=p>[</span><span class=s2>&#34;PropertyMap&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln> 42</span><span class=cl>
</span></span><span class=line><span class=ln> 43</span><span class=cl>
</span></span><span class=line><span class=ln> 44</span><span class=cl><span class=k>def</span> <span class=nf>inject_security_opts</span><span class=p>(</span><span class=n>opts</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span> <span class=n>bootstrap_servers</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 45</span><span class=cl>    <span class=k>if</span> <span class=n>re</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=s2>&#34;9098$&#34;</span><span class=p>,</span> <span class=n>bootstrap_servers</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 46</span><span class=cl>        <span class=n>opts</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=ln> 47</span><span class=cl>            <span class=o>**</span><span class=n>opts</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 48</span><span class=cl>            <span class=o>**</span><span class=p>{</span>
</span></span><span class=line><span class=ln> 49</span><span class=cl>                <span class=s2>&#34;properties.security.protocol&#34;</span><span class=p>:</span> <span class=s2>&#34;SASL_SSL&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 50</span><span class=cl>                <span class=s2>&#34;properties.sasl.mechanism&#34;</span><span class=p>:</span> <span class=s2>&#34;AWS_MSK_IAM&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 51</span><span class=cl>                <span class=s2>&#34;properties.sasl.jaas.config&#34;</span><span class=p>:</span> <span class=s2>&#34;software.amazon.msk.auth.iam.IAMLoginModule required;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 52</span><span class=cl>                <span class=s2>&#34;properties.sasl.client.callback.handler.class&#34;</span><span class=p>:</span> <span class=s2>&#34;software.amazon.msk.auth.iam.IAMClientCallbackHandler&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 53</span><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=ln> 54</span><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=ln> 55</span><span class=cl>    <span class=k>return</span> <span class=s2>&#34;, &#34;</span><span class=o>.</span><span class=n>join</span><span class=p>({</span><span class=sa>f</span><span class=s2>&#34;&#39;</span><span class=si>{</span><span class=n>k</span><span class=si>}</span><span class=s2>&#39; = &#39;</span><span class=si>{</span><span class=n>v</span><span class=si>}</span><span class=s2>&#39;&#34;</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>opts</span><span class=o>.</span><span class=n>items</span><span class=p>()})</span>
</span></span><span class=line><span class=ln> 56</span><span class=cl>
</span></span><span class=line><span class=ln> 57</span><span class=cl>
</span></span><span class=line><span class=ln> 58</span><span class=cl><span class=k>def</span> <span class=nf>create_source_table</span><span class=p>(</span><span class=n>table_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>file_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 59</span><span class=cl>    <span class=n>stmt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=ln> 60</span><span class=cl><span class=s2>    CREATE TABLE </span><span class=si>{</span><span class=n>table_name</span><span class=si>}</span><span class=s2> (
</span></span></span><span class=line><span class=ln> 61</span><span class=cl><span class=s2>        id                  VARCHAR,
</span></span></span><span class=line><span class=ln> 62</span><span class=cl><span class=s2>        vendor_id           INT,
</span></span></span><span class=line><span class=ln> 63</span><span class=cl><span class=s2>        pickup_datetime     VARCHAR,
</span></span></span><span class=line><span class=ln> 64</span><span class=cl><span class=s2>        dropoff_datetime    VARCHAR,
</span></span></span><span class=line><span class=ln> 65</span><span class=cl><span class=s2>        passenger_count     INT,
</span></span></span><span class=line><span class=ln> 66</span><span class=cl><span class=s2>        pickup_longitude    VARCHAR,
</span></span></span><span class=line><span class=ln> 67</span><span class=cl><span class=s2>        pickup_latitude     VARCHAR,
</span></span></span><span class=line><span class=ln> 68</span><span class=cl><span class=s2>        dropoff_longitude   VARCHAR,
</span></span></span><span class=line><span class=ln> 69</span><span class=cl><span class=s2>        dropoff_latitude    VARCHAR,
</span></span></span><span class=line><span class=ln> 70</span><span class=cl><span class=s2>        store_and_fwd_flag  VARCHAR,
</span></span></span><span class=line><span class=ln> 71</span><span class=cl><span class=s2>        gc_distance         DOUBLE,
</span></span></span><span class=line><span class=ln> 72</span><span class=cl><span class=s2>        trip_duration       INT,
</span></span></span><span class=line><span class=ln> 73</span><span class=cl><span class=s2>        google_distance     VARCHAR,
</span></span></span><span class=line><span class=ln> 74</span><span class=cl><span class=s2>        google_duration     VARCHAR
</span></span></span><span class=line><span class=ln> 75</span><span class=cl><span class=s2>    ) WITH (
</span></span></span><span class=line><span class=ln> 76</span><span class=cl><span class=s2>        &#39;connector&#39;= &#39;filesystem&#39;,
</span></span></span><span class=line><span class=ln> 77</span><span class=cl><span class=s2>        &#39;format&#39; = &#39;csv&#39;,
</span></span></span><span class=line><span class=ln> 78</span><span class=cl><span class=s2>        &#39;path&#39; = &#39;</span><span class=si>{</span><span class=n>file_path</span><span class=si>}</span><span class=s2>&#39;
</span></span></span><span class=line><span class=ln> 79</span><span class=cl><span class=s2>    )
</span></span></span><span class=line><span class=ln> 80</span><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=ln> 81</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>stmt</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 82</span><span class=cl>    <span class=k>return</span> <span class=n>stmt</span>
</span></span><span class=line><span class=ln> 83</span><span class=cl>
</span></span><span class=line><span class=ln> 84</span><span class=cl>
</span></span><span class=line><span class=ln> 85</span><span class=cl><span class=k>def</span> <span class=nf>create_sink_table</span><span class=p>(</span><span class=n>table_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>topic_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>bootstrap_servers</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 86</span><span class=cl>    <span class=n>opts</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=ln> 87</span><span class=cl>        <span class=s2>&#34;connector&#34;</span><span class=p>:</span> <span class=s2>&#34;kafka&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 88</span><span class=cl>        <span class=s2>&#34;topic&#34;</span><span class=p>:</span> <span class=n>topic_name</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 89</span><span class=cl>        <span class=s2>&#34;properties.bootstrap.servers&#34;</span><span class=p>:</span> <span class=n>bootstrap_servers</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 90</span><span class=cl>        <span class=s2>&#34;format&#34;</span><span class=p>:</span> <span class=s2>&#34;json&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 91</span><span class=cl>        <span class=s2>&#34;key.format&#34;</span><span class=p>:</span> <span class=s2>&#34;json&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 92</span><span class=cl>        <span class=s2>&#34;key.fields&#34;</span><span class=p>:</span> <span class=s2>&#34;id&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 93</span><span class=cl>        <span class=s2>&#34;properties.allow.auto.create.topics&#34;</span><span class=p>:</span> <span class=s2>&#34;true&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 94</span><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=ln> 95</span><span class=cl>
</span></span><span class=line><span class=ln> 96</span><span class=cl>    <span class=n>stmt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=ln> 97</span><span class=cl><span class=s2>    CREATE TABLE </span><span class=si>{</span><span class=n>table_name</span><span class=si>}</span><span class=s2> (
</span></span></span><span class=line><span class=ln> 98</span><span class=cl><span class=s2>        id                  VARCHAR,
</span></span></span><span class=line><span class=ln> 99</span><span class=cl><span class=s2>        vendor_id           INT,
</span></span></span><span class=line><span class=ln>100</span><span class=cl><span class=s2>        pickup_datetime     VARCHAR,
</span></span></span><span class=line><span class=ln>101</span><span class=cl><span class=s2>        dropoff_datetime    VARCHAR,
</span></span></span><span class=line><span class=ln>102</span><span class=cl><span class=s2>        passenger_count     INT,
</span></span></span><span class=line><span class=ln>103</span><span class=cl><span class=s2>        pickup_longitude    VARCHAR,
</span></span></span><span class=line><span class=ln>104</span><span class=cl><span class=s2>        pickup_latitude     VARCHAR,
</span></span></span><span class=line><span class=ln>105</span><span class=cl><span class=s2>        dropoff_longitude   VARCHAR,
</span></span></span><span class=line><span class=ln>106</span><span class=cl><span class=s2>        dropoff_latitude    VARCHAR,
</span></span></span><span class=line><span class=ln>107</span><span class=cl><span class=s2>        store_and_fwd_flag  VARCHAR,
</span></span></span><span class=line><span class=ln>108</span><span class=cl><span class=s2>        gc_distance         DOUBLE,
</span></span></span><span class=line><span class=ln>109</span><span class=cl><span class=s2>        trip_duration       INT,
</span></span></span><span class=line><span class=ln>110</span><span class=cl><span class=s2>        google_distance     VARCHAR,
</span></span></span><span class=line><span class=ln>111</span><span class=cl><span class=s2>        google_duration     VARCHAR
</span></span></span><span class=line><span class=ln>112</span><span class=cl><span class=s2>    ) WITH (
</span></span></span><span class=line><span class=ln>113</span><span class=cl><span class=s2>        </span><span class=si>{</span><span class=n>inject_security_opts</span><span class=p>(</span><span class=n>opts</span><span class=p>,</span> <span class=n>bootstrap_servers</span><span class=p>)</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=ln>114</span><span class=cl><span class=s2>    )
</span></span></span><span class=line><span class=ln>115</span><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=ln>116</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>stmt</span><span class=p>)</span>
</span></span><span class=line><span class=ln>117</span><span class=cl>    <span class=k>return</span> <span class=n>stmt</span>
</span></span><span class=line><span class=ln>118</span><span class=cl>
</span></span><span class=line><span class=ln>119</span><span class=cl>
</span></span><span class=line><span class=ln>120</span><span class=cl><span class=k>def</span> <span class=nf>create_print_table</span><span class=p>(</span><span class=n>table_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln>121</span><span class=cl>    <span class=n>stmt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=ln>122</span><span class=cl><span class=s2>    CREATE TABLE sink_print (
</span></span></span><span class=line><span class=ln>123</span><span class=cl><span class=s2>        id                  VARCHAR,
</span></span></span><span class=line><span class=ln>124</span><span class=cl><span class=s2>        vendor_id           INT,
</span></span></span><span class=line><span class=ln>125</span><span class=cl><span class=s2>        pickup_datetime     VARCHAR,
</span></span></span><span class=line><span class=ln>126</span><span class=cl><span class=s2>        dropoff_datetime    VARCHAR,
</span></span></span><span class=line><span class=ln>127</span><span class=cl><span class=s2>        passenger_count     INT,
</span></span></span><span class=line><span class=ln>128</span><span class=cl><span class=s2>        pickup_longitude    VARCHAR,
</span></span></span><span class=line><span class=ln>129</span><span class=cl><span class=s2>        pickup_latitude     VARCHAR,
</span></span></span><span class=line><span class=ln>130</span><span class=cl><span class=s2>        dropoff_longitude   VARCHAR,
</span></span></span><span class=line><span class=ln>131</span><span class=cl><span class=s2>        dropoff_latitude    VARCHAR,
</span></span></span><span class=line><span class=ln>132</span><span class=cl><span class=s2>        store_and_fwd_flag  VARCHAR,
</span></span></span><span class=line><span class=ln>133</span><span class=cl><span class=s2>        gc_distance         DOUBLE,
</span></span></span><span class=line><span class=ln>134</span><span class=cl><span class=s2>        trip_duration       INT,
</span></span></span><span class=line><span class=ln>135</span><span class=cl><span class=s2>        google_distance     VARCHAR,
</span></span></span><span class=line><span class=ln>136</span><span class=cl><span class=s2>        google_duration     VARCHAR
</span></span></span><span class=line><span class=ln>137</span><span class=cl><span class=s2>    ) WITH (
</span></span></span><span class=line><span class=ln>138</span><span class=cl><span class=s2>        &#39;connector&#39;= &#39;print&#39;
</span></span></span><span class=line><span class=ln>139</span><span class=cl><span class=s2>    )
</span></span></span><span class=line><span class=ln>140</span><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=ln>141</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>stmt</span><span class=p>)</span>
</span></span><span class=line><span class=ln>142</span><span class=cl>    <span class=k>return</span> <span class=n>stmt</span>
</span></span><span class=line><span class=ln>143</span><span class=cl>
</span></span><span class=line><span class=ln>144</span><span class=cl>
</span></span><span class=line><span class=ln>145</span><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=ln>146</span><span class=cl>    <span class=c1>#### map source/sink properties</span>
</span></span><span class=line><span class=ln>147</span><span class=cl>    <span class=n>props</span> <span class=o>=</span> <span class=n>get_application_properties</span><span class=p>()</span>
</span></span><span class=line><span class=ln>148</span><span class=cl>    <span class=c1>## source</span>
</span></span><span class=line><span class=ln>149</span><span class=cl>    <span class=n>source_property_group_key</span> <span class=o>=</span> <span class=s2>&#34;source.config.0&#34;</span>
</span></span><span class=line><span class=ln>150</span><span class=cl>    <span class=n>source_properties</span> <span class=o>=</span> <span class=n>property_map</span><span class=p>(</span><span class=n>props</span><span class=p>,</span> <span class=n>source_property_group_key</span><span class=p>)</span>
</span></span><span class=line><span class=ln>151</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;&gt;&gt; source properties&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>152</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>source_properties</span><span class=p>)</span>
</span></span><span class=line><span class=ln>153</span><span class=cl>    <span class=n>source_table_name</span> <span class=o>=</span> <span class=n>source_properties</span><span class=p>[</span><span class=s2>&#34;table.name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>154</span><span class=cl>    <span class=n>source_file_path</span> <span class=o>=</span> <span class=n>source_properties</span><span class=p>[</span><span class=s2>&#34;file.path&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>155</span><span class=cl>    <span class=c1>## sink</span>
</span></span><span class=line><span class=ln>156</span><span class=cl>    <span class=n>sink_property_group_key</span> <span class=o>=</span> <span class=s2>&#34;sink.config.0&#34;</span>
</span></span><span class=line><span class=ln>157</span><span class=cl>    <span class=n>sink_properties</span> <span class=o>=</span> <span class=n>property_map</span><span class=p>(</span><span class=n>props</span><span class=p>,</span> <span class=n>sink_property_group_key</span><span class=p>)</span>
</span></span><span class=line><span class=ln>158</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;&gt;&gt; sink properties&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>159</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>sink_properties</span><span class=p>)</span>
</span></span><span class=line><span class=ln>160</span><span class=cl>    <span class=n>sink_table_name</span> <span class=o>=</span> <span class=n>sink_properties</span><span class=p>[</span><span class=s2>&#34;table.name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>161</span><span class=cl>    <span class=n>sink_topic_name</span> <span class=o>=</span> <span class=n>sink_properties</span><span class=p>[</span><span class=s2>&#34;topic.name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>162</span><span class=cl>    <span class=n>sink_bootstrap_servers</span> <span class=o>=</span> <span class=n>BOOTSTRAP_SERVERS</span> <span class=ow>or</span> <span class=n>sink_properties</span><span class=p>[</span><span class=s2>&#34;bootstrap.servers&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>163</span><span class=cl>    <span class=c1>## print</span>
</span></span><span class=line><span class=ln>164</span><span class=cl>    <span class=n>print_table_name</span> <span class=o>=</span> <span class=s2>&#34;sink_print&#34;</span>
</span></span><span class=line><span class=ln>165</span><span class=cl>    <span class=c1>#### create tables</span>
</span></span><span class=line><span class=ln>166</span><span class=cl>    <span class=n>table_env</span><span class=o>.</span><span class=n>execute_sql</span><span class=p>(</span><span class=n>create_source_table</span><span class=p>(</span><span class=n>source_table_name</span><span class=p>,</span> <span class=n>source_file_path</span><span class=p>))</span>
</span></span><span class=line><span class=ln>167</span><span class=cl>    <span class=n>table_env</span><span class=o>.</span><span class=n>execute_sql</span><span class=p>(</span>
</span></span><span class=line><span class=ln>168</span><span class=cl>        <span class=n>create_sink_table</span><span class=p>(</span><span class=n>sink_table_name</span><span class=p>,</span> <span class=n>sink_topic_name</span><span class=p>,</span> <span class=n>sink_bootstrap_servers</span><span class=p>)</span>
</span></span><span class=line><span class=ln>169</span><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=ln>170</span><span class=cl>    <span class=n>table_env</span><span class=o>.</span><span class=n>execute_sql</span><span class=p>(</span><span class=n>create_print_table</span><span class=p>(</span><span class=n>print_table_name</span><span class=p>))</span>
</span></span><span class=line><span class=ln>171</span><span class=cl>    <span class=c1>#### insert into sink tables</span>
</span></span><span class=line><span class=ln>172</span><span class=cl>    <span class=k>if</span> <span class=n>RUNTIME_ENV</span> <span class=o>==</span> <span class=s2>&#34;LOCAL&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=ln>173</span><span class=cl>        <span class=n>source_table</span> <span class=o>=</span> <span class=n>table_env</span><span class=o>.</span><span class=n>from_path</span><span class=p>(</span><span class=n>source_table_name</span><span class=p>)</span>
</span></span><span class=line><span class=ln>174</span><span class=cl>        <span class=n>statement_set</span> <span class=o>=</span> <span class=n>table_env</span><span class=o>.</span><span class=n>create_statement_set</span><span class=p>()</span>
</span></span><span class=line><span class=ln>175</span><span class=cl>        <span class=n>statement_set</span><span class=o>.</span><span class=n>add_insert</span><span class=p>(</span><span class=n>sink_table_name</span><span class=p>,</span> <span class=n>source_table</span><span class=p>)</span>
</span></span><span class=line><span class=ln>176</span><span class=cl>        <span class=n>statement_set</span><span class=o>.</span><span class=n>add_insert</span><span class=p>(</span><span class=n>print_table_name</span><span class=p>,</span> <span class=n>source_table</span><span class=p>)</span>
</span></span><span class=line><span class=ln>177</span><span class=cl>        <span class=n>statement_set</span><span class=o>.</span><span class=n>execute</span><span class=p>()</span><span class=o>.</span><span class=n>wait</span><span class=p>()</span>
</span></span><span class=line><span class=ln>178</span><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=ln>179</span><span class=cl>        <span class=n>table_result</span> <span class=o>=</span> <span class=n>table_env</span><span class=o>.</span><span class=n>execute_sql</span><span class=p>(</span>
</span></span><span class=line><span class=ln>180</span><span class=cl>            <span class=sa>f</span><span class=s2>&#34;INSERT INTO </span><span class=si>{</span><span class=n>sink_table_name</span><span class=si>}</span><span class=s2> SELECT * FROM </span><span class=si>{</span><span class=n>source_table_name</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=ln>181</span><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=ln>182</span><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=n>table_result</span><span class=o>.</span><span class=n>get_job_client</span><span class=p>()</span><span class=o>.</span><span class=n>get_job_status</span><span class=p>())</span>
</span></span><span class=line><span class=ln>183</span><span class=cl>
</span></span><span class=line><span class=ln>184</span><span class=cl>
</span></span><span class=line><span class=ln>185</span><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=ln>186</span><span class=cl>    <span class=n>main</span><span class=p>()</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=ln> 1</span><span class=cl><span class=c1>// loader/application_properties.json
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1></span><span class=p>[</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl>    <span class=nt>&#34;PropertyGroupId&#34;</span><span class=p>:</span> <span class=s2>&#34;kinesis.analytics.flink.run.options&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>    <span class=nt>&#34;PropertyMap&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl>      <span class=nt>&#34;python&#34;</span><span class=p>:</span> <span class=s2>&#34;processor.py&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>      <span class=nt>&#34;jarfile&#34;</span><span class=p>:</span> <span class=s2>&#34;package/lib/lab2-pipeline-1.0.0.jar&#34;</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>    <span class=nt>&#34;PropertyGroupId&#34;</span><span class=p>:</span> <span class=s2>&#34;source.config.0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>12</span><span class=cl>    <span class=nt>&#34;PropertyMap&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>      <span class=nt>&#34;table.name&#34;</span><span class=p>:</span> <span class=s2>&#34;taxi_trip_source&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>14</span><span class=cl>      <span class=nt>&#34;file.path&#34;</span><span class=p>:</span> <span class=s2>&#34;s3://&lt;s3-bucket-name-to-replace&gt;/taxi-csv/&#34;</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=ln>17</span><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>    <span class=nt>&#34;PropertyGroupId&#34;</span><span class=p>:</span> <span class=s2>&#34;sink.config.0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>19</span><span class=cl>    <span class=nt>&#34;PropertyMap&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=ln>20</span><span class=cl>      <span class=nt>&#34;table.name&#34;</span><span class=p>:</span> <span class=s2>&#34;taxi_trip_sink&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>21</span><span class=cl>      <span class=nt>&#34;topic.name&#34;</span><span class=p>:</span> <span class=s2>&#34;taxi-trip&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>22</span><span class=cl>      <span class=nt>&#34;bootstrap.servers&#34;</span><span class=p>:</span> <span class=s2>&#34;localhost:29092&#34;</span>
</span></span><span class=line><span class=ln>23</span><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=ln>24</span><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=ln>25</span><span class=cl><span class=p>]</span>
</span></span></code></pre></div><h3 id=run-application data-numberify>Run Application<a class="anchor ms-1" href=#run-application></a></h3><h4 id=execute-on-local-flink-cluster data-numberify>Execute on Local Flink Cluster<a class="anchor ms-1" href=#execute-on-local-flink-cluster></a></h4><p>We can run the application in the Flink cluster on Docker and the steps are shown below. Either the Kafka cluster on Amazon MSK or a local Kafka cluster can be used depending on which Docker Compose file we use. In either way, we can check the job details on the Flink web UI on <em>localhost:8081</em>. Note that, if we use the local Kafka cluster option, we have to start the producer application in a different terminal.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl><span class=c1>## prep - update s3 bucket name in loader/application_properties.json</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl>
</span></span><span class=line><span class=ln> 3</span><span class=cl><span class=c1>## set aws credentials environment variables</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=nb>export</span> <span class=nv>AWS_ACCESS_KEY_ID</span><span class=o>=</span>&lt;aws-access-key-id&gt;
</span></span><span class=line><span class=ln> 5</span><span class=cl><span class=nb>export</span> <span class=nv>AWS_SECRET_ACCESS_KEY</span><span class=o>=</span>&lt;aws-secret-access-key&gt;
</span></span><span class=line><span class=ln> 6</span><span class=cl><span class=c1># export AWS_SESSION_TOKEN=&lt;aws-session-token&gt;</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>
</span></span><span class=line><span class=ln> 8</span><span class=cl><span class=c1>## run docker compose service</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl><span class=c1># with msk cluster</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>docker-compose -f compose-msk.yml up -d
</span></span><span class=line><span class=ln>11</span><span class=cl><span class=c1># # or with local Kafka cluster</span>
</span></span><span class=line><span class=ln>12</span><span class=cl><span class=c1># docker-compose -f compose-local-kafka.yml up -d</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>
</span></span><span class=line><span class=ln>14</span><span class=cl><span class=c1>## run the producer application in another terminal</span>
</span></span><span class=line><span class=ln>15</span><span class=cl><span class=c1># python producer/app.py </span>
</span></span><span class=line><span class=ln>16</span><span class=cl>
</span></span><span class=line><span class=ln>17</span><span class=cl><span class=c1>## submit pyflink application</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>docker <span class=nb>exec</span> jobmanager /opt/flink/bin/flink run <span class=se>\
</span></span></span><span class=line><span class=ln>19</span><span class=cl><span class=se></span>    --python /etc/flink/loader/processor.py <span class=se>\
</span></span></span><span class=line><span class=ln>20</span><span class=cl><span class=se></span>    --jarfile /etc/flink/package/lib/lab2-pipeline-1.0.0.jar <span class=se>\
</span></span></span><span class=line><span class=ln>21</span><span class=cl><span class=se></span>    -d
</span></span></code></pre></div><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/flink-job.png loading=lazy width=1216 height=860></picture></p><h4 id=execute-locally data-numberify>Execute Locally<a class="anchor ms-1" href=#execute-locally></a></h4><p>The application can also be executed locally by specifying the runtime environment (<em>RUNTIME_ENV</em>) and bootstrap server addresses (<em>BOOTSTRAP_SERVERS</em>) as shown below.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ <span class=nv>RUNTIME_ENV</span><span class=o>=</span>LOCAL <span class=nv>BOOTSTRAP_SERVERS</span><span class=o>=</span>localhost:29092 python loader/processor.py
</span></span></code></pre></div><p>Note, in order for the Flink app to be able to access the S3 file system, we have to place the S3 jar file (<em>flink-s3-fs-hadoop-1.17.1.jar</em>) in the <em>lib</em> folder of the Pyflink package. For example, my virtual environment is in the <em>venv</em> folder and I can add the Jar file in the <em>venv/lib/python3.8/site-packages/pyflink/lib</em> folder. The package also has the <em>plugins</em> folder but it didn&rsquo;t work when I placed the Jar file under it.</p><h3 id=monitor-topic data-numberify>Monitor Topic<a class="anchor ms-1" href=#monitor-topic></a></h3><p>We can see the topic (<em>taxi-rides</em>) is created, and the details of the topic can be found on the <em>Topics</em> menu on <em>localhost:3000</em>.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/kafka-topic.png loading=lazy width=1200 height=806></picture></p><p>Also, we can inspect topic messages in the <em>Data</em> tab as shown below.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/kafka-message.png loading=lazy width=1196 height=817></picture></p><h2 id=summary data-numberify>Summary<a class="anchor ms-1" href=#summary></a></h2><p>In this lab, we created a Pyflink application that reads records from S3 and sends them into a Kafka topic. A custom pipeline Jar file was created as the Kafka cluster is authenticated by IAM, and it was demonstrated how to execute the app in a Flink cluster deployed on Docker as well as locally as a typical Python app.</p></div></div></div><div class=card-footer><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-down post-prev-icon me-1" data-fa-transform=rotate-90></i>
<a href=/blog/2023-11-02-stateful-stream-processing/>Benefits and Opportunities of Stateful Stream Processing</a></div><div class="post-nav post-next"><a href=/blog/2023-11-16-real-time-streaming-with-kafka-and-flink-4/>Real Time Streaming With Kafka and Flink - Lab 3 Transform and Write Data to S3 From Kafka Using Flink</a>
<i class="fas fa-fw fa-chevron-down post-next-icon ms-1" data-fa-transform=rotate-270></i></div></div></div></article><section class="related-posts row card component"><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Related Posts</h2></div><div class="card-body slide px-1"><div class="slide-inner row gx-0"><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-10-05-real-time-streaming-with-kafka-and-flink-1/featured_hua45c2e579ce8f6bc0318d15d62654514_138141_500x0_resize_box_3.png media="(max-width: 576px)" height=299 width=500><img class=img-fluid height=108 width=180 alt=featured.png src=/blog/2023-10-05-real-time-streaming-with-kafka-and-flink-1/featured_hua45c2e579ce8f6bc0318d15d62654514_138141_180x0_resize_box_3.png data-src=/blog/2023-10-05-real-time-streaming-with-kafka-and-flink-1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-10-05-real-time-streaming-with-kafka-and-flink-1/>Real Time Streaming With Kafka and Flink - Introduction</a><div class="post-meta mb-0">October 5, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/featured_hue908d327a4e776f04c90ce3d9151d268_74618_500x0_resize_box_3.png media="(max-width: 576px)" height=256 width=500><img class=img-fluid height=92 width=180 alt=featured.png src=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/featured_hue908d327a4e776f04c90ce3d9151d268_74618_180x0_resize_box_3.png data-src=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/>Getting Started With Pyflink on AWS - Part 3 AWS Managed Flink and MSK</a><div class="post-meta mb-0">September 4, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2/featured_huff907a4f1fb46be4b7ff165486006a38_64005_500x0_resize_box_3.png media="(max-width: 576px)" height=328 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2/featured_huff907a4f1fb46be4b7ff165486006a38_64005_180x0_resize_box_3.png data-src=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2/>Getting Started With Pyflink on AWS - Part 2 Local Flink and MSK</a><div class="post-meta mb-0">August 28, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured_hu6470c0101df93a224de5159e363e8665_55960_500x0_resize_box_3.png media="(max-width: 576px)" height=289 width=500><img class=img-fluid height=104 width=180 alt=featured.png src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured_hu6470c0101df93a224de5159e363e8665_55960_180x0_resize_box_3.png data-src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/>Getting Started With Pyflink on AWS - Part 1 Local Flink and Local Kafka</a><div class="post-meta mb-0">August 17, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-10-26-real-time-streaming-with-kafka-and-flink-2/featured_hufd07a51d08fbb1dcf00355523276b259_138560_500x0_resize_box_3.png media="(max-width: 576px)" height=297 width=500><img class=img-fluid height=107 width=180 alt=featured.png src=/blog/2023-10-26-real-time-streaming-with-kafka-and-flink-2/featured_hufd07a51d08fbb1dcf00355523276b259_138560_180x0_resize_box_3.png data-src=/blog/2023-10-26-real-time-streaming-with-kafka-and-flink-2/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-10-26-real-time-streaming-with-kafka-and-flink-2/>Real Time Streaming With Kafka and Flink - Lab 1 Produce Data to Kafka Using Lambda</a><div class="post-meta mb-0">October 26, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_500x0_resize_box_3.png media="(max-width: 576px)" height=241 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_180x0_resize_box_3.png data-src=/blog/2023-10-19-build-pyflink-apps/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-10-19-build-pyflink-apps/>Building Apache Flink Applications in Python</a><div class="post-meta mb-0">October 19, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-08-10-fraud-detection-part-1/featured_hu0e6881a0b5c39bbfe5c0b72138bca889_72929_500x0_resize_box_3.png media="(max-width: 576px)" height=213 width=500><img class=img-fluid height=77 width=180 alt=featured.png src=/blog/2023-08-10-fraud-detection-part-1/featured_hu0e6881a0b5c39bbfe5c0b72138bca889_72929_180x0_resize_box_3.png data-src=/blog/2023-08-10-fraud-detection-part-1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-08-10-fraud-detection-part-1/>Kafka, Flink and DynamoDB for Real Time Fraud Detection - Part 1 Local Development</a><div class="post-meta mb-0">August 10, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_500x0_resize_box_3.png media="(max-width: 576px)" height=305 width=500><img class=img-fluid height=110 width=180 alt=featured.png src=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_180x0_resize_box_3.png data-src=/blog/2023-04-12-integrate-glue-schema-registry/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-04-12-integrate-glue-schema-registry/>Integrate Glue Schema Registry With Your Python Kafka App</a><div class="post-meta mb-0">April 12, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-10-30-kafka-connect-for-aws-part-5/featured_hue6ace805e51d39c2a79d7a3e7795d500_85575_500x0_resize_box_3.png media="(max-width: 576px)" height=440 width=500><img class=img-fluid height=158 width=180 alt=featured.png src=/blog/2023-10-30-kafka-connect-for-aws-part-5/featured_hue6ace805e51d39c2a79d7a3e7795d500_85575_180x0_resize_box_3.png data-src=/blog/2023-10-30-kafka-connect-for-aws-part-5/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-10-30-kafka-connect-for-aws-part-5/>Kafka Connect for AWS Services Integration - Part 5 Deploy Aiven OpenSearch Sink Connector</a><div class="post-meta mb-0">October 30, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-09-14-fraud-detection-part-2/featured_hu6e12c35fe727128749446c930c7ac3f6_66221_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2023-09-14-fraud-detection-part-2/featured_hu6e12c35fe727128749446c930c7ac3f6_66221_180x0_resize_box_3.png data-src=/blog/2023-09-14-fraud-detection-part-2/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-09-14-fraud-detection-part-2/>Kafka, Flink and DynamoDB for Real Time Fraud Detection - Part 2 Deployment via AWS Managed Flink</a><div class="post-meta mb-0">September 14, 2023</div></div></div></div><button class=slide-control-left>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i>
<span class=visually-hidden>Left</span>
</button>
<button class=slide-control-right>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-270></i>
<span class=visually-hidden>Right</span></button></div></section><div class="card component row post-comments" id=post-comments><div class=card-header><h2 class="card-title my-2 fs-4 text-surface">Comments</h2></div><div class=card-body><div class=giscus></div></div></div></div></div><aside class="col-xxl-4 sidebar d-flex"><div class="container d-flex flex-column"><div class="accordion profile"><div class="accordion-item card row text-center component"><div class="accordion-header card-header border-0" id=profile-header><a class="accordion-button d-lg-none mb-2 shadow-none p-0 bg-transparent text-surface" role=button data-bs-toggle=collapse href=#profile aria-expanded=true aria-controls=profile>Profile</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=profile aria-labelledby=profile-header><div class="col-12 d-flex align-items-center justify-content-center"><picture><img class="profile-avatar rounded-circle" alt="Jaehyeon Kim" src="https://jaehyeon.me/images/profile.png?v=8f13fa1fdd27b8314549ce76fc3fadf4" loading=lazy data-viewer-invisible width=200 height=200></picture></div><div class="col-12 profile-meta"><div class="profile-name fw-fold fs-lg">Jaehyeon Kim</div><div class=profile-bio>Data Engineer 💡 Blogger ⚡ Data Streaming Enthusiast ☁ AWS Community Builder</div></div><nav class="social-links nav justify-content-center mt-1 justify-content-around"><a class="nav-link social-link" href=mailto:dottami@gmail.com title=Email><i class="fas fa-fw fa-2x fa-envelope" style=color:#0963ac></i>
</a><a class="nav-link social-link" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fa-2x fab fa-github"></i>
</a><a class="nav-link social-link" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fa-2x fab fa-linkedin-in" style=color:#0a66c2></i>
</a><a class="nav-link social-link" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fa-2x fab fa-paypal"></i></a></nav></div></div></div><div class="accordion taxonomies-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#taxonomies-toggle aria-expanded=true aria-controls=taxonomies-toggle>Taxonomies</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=taxonomies-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=taxonomyCategoriesTab data-bs-toggle=tab data-bs-target=#taxonomyCategories type=button role=tab aria-controls=taxonomyCategories aria-selected=true>
Categories</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyTagsTab data-bs-toggle=tab data-bs-target=#taxonomyTags type=button role=tab aria-controls=taxonomyTags aria-selected=true>
Tags</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomySeriesTab data-bs-toggle=tab data-bs-target=#taxonomySeries type=button role=tab aria-controls=taxonomySeries aria-selected=true>
Series</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyArchivesTab data-bs-toggle=tab data-bs-target=#taxonomyArchives type=button role=tab aria-controls=taxonomyArchives aria-selected=true>
Archives</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=taxonomyCategories role=tabpanel aria-labelledby=taxonomyCategoriesTab tabindex=0><a href=/categories/data-streaming/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Streaming">Data Streaming
<span class="badge badge-sm text-secondary bg-white ms-1">25</span>
</a><a href=/categories/data-engineering/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Engineering">Data Engineering
<span class="badge badge-sm text-secondary bg-white ms-1">24</span>
</a><a href=/categories/development/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Development>Development
<span class="badge badge-sm text-secondary bg-white ms-1">19</span>
</a><a href=/categories/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/categories/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/categories/machine-learning/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Machine Learning">Machine Learning
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/categories/general/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=General>General
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/categories/apache-beam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Beam">Apache Beam
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyTags role=tabpanel aria-labelledby=taxonomyTagsTab tabindex=0><a href=/tags/docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Docker>Docker
<span class="badge badge-sm text-secondary bg-white ms-1">51</span>
</a><a href=/tags/python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Python>Python
<span class="badge badge-sm text-secondary bg-white ms-1">46</span>
</a><a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">44</span>
</a><a href=/tags/aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=AWS>AWS
<span class="badge badge-sm text-secondary bg-white ms-1">43</span>
</a><a href=/tags/docker-compose/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Docker Compose">Docker Compose
<span class="badge badge-sm text-secondary bg-white ms-1">43</span>
</a><a href=/tags/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">36</span>
</a><a href=/tags/amazon-msk/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK">Amazon MSK
<span class="badge badge-sm text-secondary bg-white ms-1">21</span>
</a><a href=/tags/apache-spark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Spark">Apache Spark
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/tags/kafka-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Kafka Connect">Kafka Connect
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/tags/aws-lambda/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Lambda">AWS Lambda
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/tags/terraform/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Terraform>Terraform
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/tags/apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Flink">Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">13</span>
</a><a href=/tags/amazon-emr/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EMR">Amazon EMR
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/data-build-tool-dbt/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Data Build Tool (DBT)">Data Build Tool (DBT)
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/pyflink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PyFlink>PyFlink
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/amazon-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK Connect">Amazon MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">9</span>
</a><a href=/tags/kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Kubernetes>Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">8</span>
</a><a href=/tags/amazon-athena/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Athena">Amazon Athena
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/pyspark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PySpark>PySpark
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/amazon-dynamodb/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon DynamoDB">Amazon DynamoDB
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/apache-airflow/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Airflow">Apache Airflow
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/rserve/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Rserve>Rserve
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/visual-studio-code/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Visual Studio Code">Visual Studio Code
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/amazon-api-gateway/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon API Gateway">Amazon API Gateway
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-managed-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Managed Flink">Amazon Managed Flink
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-managed-service-for-apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Managed Service for Apache Flink">Amazon Managed Service for Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-quicksight/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon QuickSight">Amazon QuickSight
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/aws-glue/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Glue">AWS Glue
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/minikube/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Minikube>Minikube
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/opensearch/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=OpenSearch>OpenSearch
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/security/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Security>Security
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/shiny/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Shiny>Shiny
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-eks/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EKS">Amazon EKS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/amazon-opensearch-service/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon OpenSearch Service">Amazon OpenSearch Service
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/amazon-s3/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon S3">Amazon S3
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/apache-camel/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Camel">Apache Camel
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/apache-hudi/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Hudi">Apache Hudi
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/apache-iceberg/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Iceberg">Apache Iceberg
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/aws-sam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS SAM">AWS SAM
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Change Data Capture">Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=https://jaehyeon.me/tags class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=ALL>ALL
<span class="badge badge-sm text-secondary bg-white ms-1">97</span></a></div><div class=tab-pane id=taxonomySeries role=tabpanel aria-labelledby=taxonomySeriesTab tabindex=0><a href=/series/kafka-development-with-docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development With Docker">Kafka Development With Docker
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/series/real-time-streaming-with-kafka-and-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Real Time Streaming With Kafka and Flink">Real Time Streaming With Kafka and Flink
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/series/dbt-pizza-shop-demo/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT Pizza Shop Demo">DBT Pizza Shop Demo
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/series/tree-based-methods-in-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Tree Based Methods in R">Tree Based Methods in R
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/series/dbt-for-effective-data-transformation-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT for Effective Data Transformation on AWS">DBT for Effective Data Transformation on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/kafka-connect-for-aws-services-integration/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Connect for AWS Services Integration">Kafka Connect for AWS Services Integration
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/serverless-data-product/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Serverless Data Product">Serverless Data Product
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/series/data-lake-demo-using-change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Data Lake Demo Using Change Data Capture">Data Lake Demo Using Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/getting-started-with-pyflink-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Getting Started With Pyflink on AWS">Getting Started With Pyflink on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/kafka-development-on-kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development on Kubernetes">Kafka Development on Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/parallel-processing-on-single-machine/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Parallel Processing on Single Machine">Parallel Processing on Single Machine
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/api-development-with-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="API Development With R">API Development With R
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/integrate-schema-registry-with-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Integrate Schema Registry With MSK Connect">Integrate Schema Registry With MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/kafka-flink-and-dynamodb-for-real-time-fraud-detection/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka, Flink and DynamoDB for Real Time Fraud Detection">Kafka, Flink and DynamoDB for Real Time Fraud Detection
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/simplify-streaming-ingestion-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Simplify Streaming Ingestion on AWS">Simplify Streaming Ingestion on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/apache-beam-local-development-with-python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Apache Beam Local Development With Python">Apache Beam Local Development With Python
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyArchives role=tabpanel aria-labelledby=taxonomyArchivesTab tabindex=0><a href=/archives/2024/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2024>2024 <span class="badge badge-sm text-secondary bg-white ms-1">9</span>
</a><a href=/archives/2023/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2023>2023 <span class="badge badge-sm text-secondary bg-white ms-1">39</span>
</a><a href=/archives/2022/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2022>2022 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2021/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2021>2021 <span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/archives/2020/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2020>2020 <span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/archives/2019/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2019>2019 <span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/archives/2018/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2018>2018 <span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/archives/2017/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2017>2017 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2016/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2016>2016 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2015/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2015>2015 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2014/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2014>2014 <span class="badge badge-sm text-secondary bg-white ms-1">5</span></a></div></div></div></div></div><div class="accordion posts-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#posts-toggle aria-expanded=true aria-controls=posts-toggle>Posts</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=posts-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=featured-posts-tab data-bs-toggle=tab data-bs-target=#featured-posts type=button role=tab aria-controls=featured-posts aria-selected=true>
Featured Posts</button></li><li class=nav-item role=presentation><button class=nav-link id=recent-posts-tab data-bs-toggle=tab data-bs-target=#recent-posts type=button role=tab aria-controls=recent-posts aria-selected=true>
Recent Posts</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=featured-posts role=tabpanel aria-labelledby=featured-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_500x0_resize_box_3.png media="(max-width: 576px)" height=338 width=500><img class=img-fluid height=122 width=180 alt=featured.png src=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_180x0_resize_box_3.png data-src=/blog/2024-03-28-beam-local-dev-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-28-beam-local-dev-1/>Apache Beam Local Development With Python - Part 1 Pipeline, Notebook, SQL and DataFrame</a><div class="post-meta mt-2"><span class=post-date>March 28, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-14-dbt-pizza-shop-6/featured_hu72fe52c30196d9a511f344ff548f2036_82921_500x0_resize_box_3.png media="(max-width: 576px)" height=256 width=500><img class=img-fluid height=92 width=180 alt=featured.png src=/blog/2024-03-14-dbt-pizza-shop-6/featured_hu72fe52c30196d9a511f344ff548f2036_82921_180x0_resize_box_3.png data-src=/blog/2024-03-14-dbt-pizza-shop-6/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-14-dbt-pizza-shop-6/>Data Build Tool (Dbt) Pizza Shop Demo - Part 6 ETL on Amazon Athena via Airflow</a><div class="post-meta mt-2"><span class=post-date>March 14, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-07-dbt-pizza-shop-5/featured_hu5822ed54c6b6e6cff286a9a560a4b806_61499_500x0_resize_box_3.png media="(max-width: 576px)" height=187 width=500><img class=img-fluid height=67 width=180 alt=featured.png src=/blog/2024-03-07-dbt-pizza-shop-5/featured_hu5822ed54c6b6e6cff286a9a560a4b806_61499_180x0_resize_box_3.png data-src=/blog/2024-03-07-dbt-pizza-shop-5/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-07-dbt-pizza-shop-5/>Data Build Tool (Dbt) Pizza Shop Demo - Part 5 Modelling on Amazon Athena</a><div class="post-meta mt-2"><span class=post-date>March 7, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-02-22-dbt-pizza-shop-4/featured_hu487187112b89f2568f433199221f000a_89588_500x0_resize_box_3.png media="(max-width: 576px)" height=327 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2024-02-22-dbt-pizza-shop-4/featured_hu487187112b89f2568f433199221f000a_89588_180x0_resize_box_3.png data-src=/blog/2024-02-22-dbt-pizza-shop-4/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-02-22-dbt-pizza-shop-4/>Data Build Tool (Dbt) Pizza Shop Demo - Part 4 ETL on BigQuery via Airflow</a><div class="post-meta mt-2"><span class=post-date>February 22, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-02-08-dbt-pizza-shop-3/featured_hu5082aedceaa438015dc31206ac8f27c2_70297_500x0_resize_box_3.png media="(max-width: 576px)" height=241 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2024-02-08-dbt-pizza-shop-3/featured_hu5082aedceaa438015dc31206ac8f27c2_70297_180x0_resize_box_3.png data-src=/blog/2024-02-08-dbt-pizza-shop-3/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-02-08-dbt-pizza-shop-3/>Data Build Tool (Dbt) Pizza Shop Demo - Part 3 Modelling on BigQuery</a><div class="post-meta mt-2"><span class=post-date>February 8, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-25-dbt-pizza-shop-2/featured_hu32c9a8b2df36b3a1704029fc725738dd_77355_500x0_resize_box_3.png media="(max-width: 576px)" height=328 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2024-01-25-dbt-pizza-shop-2/featured_hu32c9a8b2df36b3a1704029fc725738dd_77355_180x0_resize_box_3.png data-src=/blog/2024-01-25-dbt-pizza-shop-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-25-dbt-pizza-shop-2/>Data Build Tool (Dbt) Pizza Shop Demo - Part 2 ETL on PostgreSQL via Airflow</a><div class="post-meta mt-2"><span class=post-date>January 25, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_500x0_resize_box_3.png media="(max-width: 576px)" height=238 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_180x0_resize_box_3.png data-src=/blog/2024-01-18-dbt-pizza-shop-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-18-dbt-pizza-shop-1/>Data Build Tool (Dbt) Pizza Shop Demo - Part 1 Modelling on PostgreSQL</a><div class="post-meta mt-2"><span class=post-date>January 18, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_180x0_resize_box_3.png data-src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-12-21-kafka-development-on-k8s-part-1/>Kafka Development on Kubernetes - Part 1 Cluster Setup</a><div class="post-meta mt-2"><span class=post-date>December 21, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-12-07-flink-spark-local-dev/featured_hu7a73c8ca7d8b8a4ddf49d1a9b8fe40bd_133053_500x0_resize_box_3.png media="(max-width: 576px)" height=373 width=500><img class=img-fluid height=134 width=180 alt=featured.png src=/blog/2023-12-07-flink-spark-local-dev/featured_hu7a73c8ca7d8b8a4ddf49d1a9b8fe40bd_133053_180x0_resize_box_3.png data-src=/blog/2023-12-07-flink-spark-local-dev/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-12-07-flink-spark-local-dev/>Setup Local Development Environment for Apache Flink and Spark Using EMR Container Images</a><div class="post-meta mt-2"><span class=post-date>December 7, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_500x0_resize_box_3.png media="(max-width: 576px)" height=241 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_180x0_resize_box_3.png data-src=/blog/2023-10-19-build-pyflink-apps/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-10-19-build-pyflink-apps/>Building Apache Flink Applications in Python</a><div class="post-meta mt-2"><span class=post-date>October 19, 2023</span></div></div></div></li></ul></div><div class=tab-pane id=recent-posts role=tabpanel aria-labelledby=recent-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_500x0_resize_box_3.png media="(max-width: 576px)" height=338 width=500><img class=img-fluid height=122 width=180 alt=featured.png src=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_180x0_resize_box_3.png data-src=/blog/2024-03-28-beam-local-dev-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-28-beam-local-dev-1/>Apache Beam Local Development With Python - Part 1 Pipeline, Notebook, SQL and DataFrame</a><div class="post-meta mt-2"><span class=post-date>March 28, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-14-dbt-pizza-shop-6/featured_hu72fe52c30196d9a511f344ff548f2036_82921_500x0_resize_box_3.png media="(max-width: 576px)" height=256 width=500><img class=img-fluid height=92 width=180 alt=featured.png src=/blog/2024-03-14-dbt-pizza-shop-6/featured_hu72fe52c30196d9a511f344ff548f2036_82921_180x0_resize_box_3.png data-src=/blog/2024-03-14-dbt-pizza-shop-6/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-14-dbt-pizza-shop-6/>Data Build Tool (Dbt) Pizza Shop Demo - Part 6 ETL on Amazon Athena via Airflow</a><div class="post-meta mt-2"><span class=post-date>March 14, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-07-dbt-pizza-shop-5/featured_hu5822ed54c6b6e6cff286a9a560a4b806_61499_500x0_resize_box_3.png media="(max-width: 576px)" height=187 width=500><img class=img-fluid height=67 width=180 alt=featured.png src=/blog/2024-03-07-dbt-pizza-shop-5/featured_hu5822ed54c6b6e6cff286a9a560a4b806_61499_180x0_resize_box_3.png data-src=/blog/2024-03-07-dbt-pizza-shop-5/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-07-dbt-pizza-shop-5/>Data Build Tool (Dbt) Pizza Shop Demo - Part 5 Modelling on Amazon Athena</a><div class="post-meta mt-2"><span class=post-date>March 7, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-02-22-dbt-pizza-shop-4/featured_hu487187112b89f2568f433199221f000a_89588_500x0_resize_box_3.png media="(max-width: 576px)" height=327 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2024-02-22-dbt-pizza-shop-4/featured_hu487187112b89f2568f433199221f000a_89588_180x0_resize_box_3.png data-src=/blog/2024-02-22-dbt-pizza-shop-4/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-02-22-dbt-pizza-shop-4/>Data Build Tool (Dbt) Pizza Shop Demo - Part 4 ETL on BigQuery via Airflow</a><div class="post-meta mt-2"><span class=post-date>February 22, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-02-08-dbt-pizza-shop-3/featured_hu5082aedceaa438015dc31206ac8f27c2_70297_500x0_resize_box_3.png media="(max-width: 576px)" height=241 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2024-02-08-dbt-pizza-shop-3/featured_hu5082aedceaa438015dc31206ac8f27c2_70297_180x0_resize_box_3.png data-src=/blog/2024-02-08-dbt-pizza-shop-3/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-02-08-dbt-pizza-shop-3/>Data Build Tool (Dbt) Pizza Shop Demo - Part 3 Modelling on BigQuery</a><div class="post-meta mt-2"><span class=post-date>February 8, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-25-dbt-pizza-shop-2/featured_hu32c9a8b2df36b3a1704029fc725738dd_77355_500x0_resize_box_3.png media="(max-width: 576px)" height=328 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2024-01-25-dbt-pizza-shop-2/featured_hu32c9a8b2df36b3a1704029fc725738dd_77355_180x0_resize_box_3.png data-src=/blog/2024-01-25-dbt-pizza-shop-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-25-dbt-pizza-shop-2/>Data Build Tool (Dbt) Pizza Shop Demo - Part 2 ETL on PostgreSQL via Airflow</a><div class="post-meta mt-2"><span class=post-date>January 25, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_500x0_resize_box_3.png media="(max-width: 576px)" height=238 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_180x0_resize_box_3.png data-src=/blog/2024-01-18-dbt-pizza-shop-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-18-dbt-pizza-shop-1/>Data Build Tool (Dbt) Pizza Shop Demo - Part 1 Modelling on PostgreSQL</a><div class="post-meta mt-2"><span class=post-date>January 18, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-11-kafka-development-on-k8s-part-3/featured_hu95d566cb28d7f91b2d6baddb7d8bb440_97270_500x0_resize_box_3.png media="(max-width: 576px)" height=216 width=500><img class=img-fluid height=78 width=180 alt=featured.png src=/blog/2024-01-11-kafka-development-on-k8s-part-3/featured_hu95d566cb28d7f91b2d6baddb7d8bb440_97270_180x0_resize_box_3.png data-src=/blog/2024-01-11-kafka-development-on-k8s-part-3/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-11-kafka-development-on-k8s-part-3/>Kafka Development on Kubernetes - Part 3 Kafka Connect</a><div class="post-meta mt-2"><span class=post-date>January 11, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-04-kafka-development-on-k8s-part-2/featured_hu866886d7082b1c38bf0c33066b35072f_75889_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2024-01-04-kafka-development-on-k8s-part-2/featured_hu866886d7082b1c38bf0c33066b35072f_75889_180x0_resize_box_3.png data-src=/blog/2024-01-04-kafka-development-on-k8s-part-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-04-kafka-development-on-k8s-part-2/>Kafka Development on Kubernetes - Part 2 Producer and Consumer</a><div class="post-meta mt-2"><span class=post-date>January 4, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_180x0_resize_box_3.png data-src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-12-21-kafka-development-on-k8s-part-1/>Kafka Development on Kubernetes - Part 1 Cluster Setup</a><div class="post-meta mt-2"><span class=post-date>December 21, 2023</span></div></div></div></li></ul></div></div></div></div></div></div></aside></div></main><footer class="footer mt-auto py-3 text-center container"><div class="offcanvas offcanvas-bottom h-auto" tabindex=-1 id=offcanvasActionsPanel aria-labelledby=offcanvasActionsPanelLabel><div class=offcanvas-header><div class="offcanvas-title h5" id=offcanvasActionsPanelLabel><i class="fas fa-fw fa-th-large me-1"></i>
Actions</div><button type=button class="btn-close ms-auto" data-bs-dismiss=offcanvas data-bs-target=offcanvasActionsPanel aria-label=Close></button></div><div class="offcanvas-body mt-2"><div class="actions d-flex overflow-auto align-items-center"><a role=button class="action action-go-back d-flex flex-column align-items-center me-3" href="javascript: window.history.back();"><span class="action-icon mb-2"><i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i></span> Go back
</a><a role=button class="action action-reload-page d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-redo-alt"></i></span> Reload
</a><a role=button class="action action-copy-url d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-link"></i></span> Copy URL</a></div></div></div><div class="row text-center"><div class="col-12 mt-2"><p class=mb-2>Jaehyeon Kim</p><p class="text-secondary mb-2"><small>Data Engineer 💡 Blogger ⚡ Data Streaming Enthusiast ☁ AWS Community Builder</small></p><div class="copyright mb-2 text-secondary"><small>Copyright © 2023-2024 Jaehyeon Kim. All Rights Reserved.</small></div><nav class="social-links nav justify-content-center mb-2 mt-3"><a class="nav-link social-link p-0 me-1 mb-2" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-2x fa-rss" style=color:#ea6221></i></a></nav></div><div class="col-12 col-lg-8 offset-0 offset-lg-1"></div></div></footer><script data-precache src=/assets/main/bundle.min.0ec8d79b95bd8d39246804f325aa5ba906dd898c752c661cb355262f78ecadcb.js integrity="sha256-DsjXm5W9jTkkaATzJapbqQbdiYx1LGYcs1UmL3jsrcs=" crossorigin=anonymous async></script><script data-precache src=/assets/icons/bundle.min.4f30d5267a9f2f9d45ed93969d45ec626100a969a8b91f71f753315a261e9034.js integrity="sha256-TzDVJnqfL51F7ZOWnUXsYmEAqWmouR9x91MxWiYekDQ=" crossorigin=anonymous defer></script><script data-precache src=/assets/viewer/bundle.min.06371891cfe6d10d36cba465c61c4d7cb17591a3be2fd9af4a38444d2074e709.js integrity="sha256-BjcYkc/m0Q02y6RlxhxNfLF1kaO+L9mvSjhETSB05wk=" crossorigin=anonymous defer></script><script data-precache defer src=/assets/katex/bundle.min.1a8cd88028fe1b600e81e2e780a8d8c388134c8237d5da89efed53ddfa28216e.js integrity="sha256-GozYgCj+G2AOgeLngKjYw4gTTII31dqJ7+1T3fooIW4=" crossorigin=anonymous></script><script data-precache defer src=/assets/mermaid/bundle.min.8d91e77f8b2cd5ebfd6d2af4e214fa37b555b15ad65dc1bdec5564ce709176f9.js integrity="sha256-jZHnf4ss1ev9bSr04hT6N7VVsVrWXcG97FVkznCRdvk=" crossorigin=anonymous></script><script src=/js/sw-register.js defer></script><script src=https://giscus.app/client.js data-repo=jaehyeon-kim/jaehyeon-kim.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkyNjgwMjU0NQ==" data-category data-category-id=DIC_kwDOAZj5cc4CV2fp data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous defer></script></body></html>