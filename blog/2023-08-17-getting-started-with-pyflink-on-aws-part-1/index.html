<!doctype html><html class=position-relative itemscope itemtype=https://schema.org/WebPage lang=en data-bs-theme=light data-palette=blue-gray><head><script src=/assets/init/bundle.min.a17e164974693b81cda45a486ffbd5320efd6516e5c4059f032185e39c4ddac9.js integrity="sha256-oX4WSXRpO4HNpFpIb/vVMg79ZRblxAWfAyGF45xN2sk=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Getting Started with Pyflink on AWS - Part 1 Local Flink and Local Kafka - Jaehyeon Kim</title>
<link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_16x16_resize_q75_h2_box_2.webp sizes=16x16 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_32x32_resize_q75_h2_box_2.webp sizes=32x32 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_150x150_resize_q75_h2_box_2.webp sizes=150x150 type=image/webp><link rel=apple-touch-icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_180x180_resize_q75_h2_box_2.webp sizes=180x180 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_192x192_resize_q75_h2_box_2.webp sizes=192x192 type=image/webp><link rel=mask-icon href=/safari-pinned-tab.svg color=#6f42c1><meta name=keywords content="Analytics,Real-time Analytics,Data Engineering,Data Streaming,Architecture"><meta name=description content="Apache Flink is widely used for building real-time stream processing applications. On AWS, Amazon Managed Service for Apache Flink is the easiest option to develop a Flink app as it provides the underlying infrastructure. Updating a guide from AWS, this series of posts discuss how to develop and deploy a Flink (Pyflink) application via KDA where the data source and sink are Kafka topics. In part 1, the app will be developed locally targeting a Kafka cluster created by Docker. Furthermore, it will be executed in a virtual environment as well as in a local Flink cluster for improved monitoring."><meta name=robots content="index, follow"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jaehyeon.me/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured.png"><meta name=twitter:title content="Getting Started with Pyflink on AWS - Part 1 Local Flink and Local Kafka"><meta name=twitter:description content="Apache Flink is widely used for building real-time stream processing applications. On AWS, Amazon Managed Service for Apache Flink is the easiest option to develop a Flink app as it provides the underlying infrastructure. Updating a guide from AWS, this series of posts discuss how to develop and deploy a Flink (Pyflink) application via KDA where the data source and sink are Kafka topics. In part 1, the app will be developed locally targeting a Kafka cluster created by Docker. Furthermore, it will be executed in a virtual environment as well as in a local Flink cluster for improved monitoring."><meta property="og:title" content="Getting Started with Pyflink on AWS - Part 1 Local Flink and Local Kafka"><meta property="og:description" content="Apache Flink is widely used for building real-time stream processing applications. On AWS, Amazon Managed Service for Apache Flink is the easiest option to develop a Flink app as it provides the underlying infrastructure. Updating a guide from AWS, this series of posts discuss how to develop and deploy a Flink (Pyflink) application via KDA where the data source and sink are Kafka topics. In part 1, the app will be developed locally targeting a Kafka cluster created by Docker. Furthermore, it will be executed in a virtual environment as well as in a local Flink cluster for improved monitoring."><meta property="og:type" content="article"><meta property="og:url" content="https://jaehyeon.me/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/"><meta property="og:image" content="https://jaehyeon.me/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2023-08-17T00:00:00+00:00"><meta property="article:modified_time" content="2024-04-15T08:44:15+10:00"><meta itemprop=name content="Getting Started with Pyflink on AWS - Part 1 Local Flink and Local Kafka"><meta itemprop=description content="Apache Flink is widely used for building real-time stream processing applications. On AWS, Amazon Managed Service for Apache Flink is the easiest option to develop a Flink app as it provides the underlying infrastructure. Updating a guide from AWS, this series of posts discuss how to develop and deploy a Flink (Pyflink) application via KDA where the data source and sink are Kafka topics. In part 1, the app will be developed locally targeting a Kafka cluster created by Docker. Furthermore, it will be executed in a virtual environment as well as in a local Flink cluster for improved monitoring."><meta itemprop=datePublished content="2023-08-17T00:00:00+00:00"><meta itemprop=dateModified content="2024-04-15T08:44:15+10:00"><meta itemprop=wordCount content="3339"><meta itemprop=image content="https://jaehyeon.me/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured.png"><meta itemprop=keywords content="Apache Flink,Pyflink,Apache Kafka,Amazon Managed Service for Apache Flink,Amazon Managed Flink,Amazon MSK,Python,Docker,Docker Compose,"><link rel=manifest href=/manifest.json><script async src="https://www.googletagmanager.com/gtag/js?id=G-076N8WCGWZ"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-076N8WCGWZ",{anonymize_ip:!1})}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2764466088407958"></script><link data-precache rel=stylesheet href="/assets/main/bundle.min.dc910a9364ba50e03d47ecf493e01f798a7ff46d1f793a172c8412e0c9867284.css" integrity="sha256-3JEKk2S6UOA9R+z0k+AfeYp/9G0feToXLIQS4MmGcoQ=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/katex/bundle.min.0e62515e6b767fdcffc08f3d4ab9197f6849689a486b42ab0c98b5e7732e1f58.css integrity="sha256-DmJRXmt2f9z/wI89SrkZf2hJaJpIa0KrDJi153MuH1g=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/viewer/bundle.min.8c1002839fa22c1350d6ae1eef6593120e108f973c41348be9b5065430566aaf.css integrity="sha256-jBACg5+iLBNQ1q4e72WTEg4Qj5c8QTSL6bUGVDBWaq8=" crossorigin=anonymous></head><body><header class="mb-4 sticky-top"><nav class="top-app-bar shadow navbar navbar-expand-xxl"><div class=container><a class="navbar-brand d-flex align-items-center flex-grow-1 flex-xxl-grow-0 justify-content-xxl-start ms-2 ms-xxl-0 mx-auto me-xxl-2" href=https://jaehyeon.me/>Jaehyeon Kim</a><div class="offcanvas-xxl offcanvas-end flex-grow-1" data-bs-scroll=true tabindex=-1 id=navbarMenus aria-labelledby=navbarMenusLabel><div class="offcanvas-header px-4 pb-0"><div class="offcanvas-title h5" id=navbarMenusLabel>Jaehyeon Kim</div><button type=button class="btn-close btn-close-white" data-bs-dismiss=offcanvas data-bs-target=#navbarMenus aria-label=Close></button></div><div class="offcanvas-body p-4 pt-0 p-xxl-0"><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center me-auto"><li class="nav-item col-12 col-xxl-auto dropdown px-0"><a href=# class="nav-link dropdown-toggle" id=navbarDropdownBlog role=button data-bs-toggle=dropdown aria-expanded=false><span class="menu-icon me-1"><i class="fas fa-fw fa-blog text-warning"></i></span>Blog</a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=navbarDropdownBlog data-bs-popper=none><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/archives/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-file-archive text-primary"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-0">Archives</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/series/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Series</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/categories/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Categories</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/tags/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Tags</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li></ul></li></ul><hr class=d-xxl-none><form class="search-bar ms-auto my-auto" action=/search/ novalidate><div class="input-group align-items-center"><span class="btn btn-search disabled position-absolute left-0 border-0 px-1"><i class="fas fa-fw fa-search fa-lg"></i>
</span><input class="my-1 form-control border-white rounded-5 search-input bg-body" name=q type=search placeholder=Search aria-label=Search required>
<span class="search-shortcut position-absolute end-0 top-0 me-2"><kbd class="text-dark bg-white opacity-75 rounded-3 shadow border border-primary py-1 fw-bold">/</kbd></span></div></form><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center ms-md-auto"><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><nav class="social-links nav justify-content-center flex-row"><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fab fa-github"></i>
<span class="ms-1 d-xxl-none">Github</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fab fa-linkedin-in"></i>
<span class="ms-1 d-xxl-none">Linkedin</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fab fa-paypal"></i>
<span class="ms-1 d-xxl-none">Paypal</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-rss"></i>
<span class="ms-1 d-xxl-none">RSS</span></a></nav></li><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><div class="vr d-none d-xxl-flex h-100 mx-xxl-2 text-white"></div><hr class="d-xxl-none my-2"></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=fontSizeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-font"></i>
<span class=d-xxl-none>Font Size</span></a><ul class="font-size-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=fontSizeDropdown><li><button class="font-size-item dropdown-item" data-size=xs>
Extra Small</button></li><li><button class="font-size-item dropdown-item" data-size=sm>
Small</button></li><li><button class="font-size-item dropdown-item active" data-size=md>
Medium</button></li><li><button class="font-size-item dropdown-item" data-size=lg>
Large</button></li><li><button class="font-size-item dropdown-item" data-size=xl>
Extra Large</button></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=paletteDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-palette"></i>
<span class=d-xxl-none>Palette</span></a><ul class="palette-dropdown-menu dropdown-menu dropdown-menu-end px-2 row g-2" aria-labelledby=paletteDropdown><li class="col-4 my-1"><a role=button id=palette-blue aria-label=Blue class="btn btn-sm w-100 palette text-bg-blue" data-palette=blue></a></li><li class="col-4 my-1"><a role=button id=palette-blue-gray aria-label="Blue Gray" class="btn btn-sm w-100 palette text-bg-blue-gray" data-palette=blue-gray></a></li><li class="col-4 my-1"><a role=button id=palette-brown aria-label=Brown class="btn btn-sm w-100 palette text-bg-brown" data-palette=brown></a></li><li class="col-4 my-1"><a role=button id=palette-cyan aria-label=Cyan class="btn btn-sm w-100 palette text-bg-cyan" data-palette=cyan></a></li><li class="col-4 my-1"><a role=button id=palette-green aria-label=Green class="btn btn-sm w-100 palette text-bg-green" data-palette=green></a></li><li class="col-4 my-1"><a role=button id=palette-indigo aria-label=Indigo class="btn btn-sm w-100 palette text-bg-indigo" data-palette=indigo></a></li><li class="col-4 my-1"><a role=button id=palette-orange aria-label=Orange class="btn btn-sm w-100 palette text-bg-orange" data-palette=orange></a></li><li class="col-4 my-1"><a role=button id=palette-pink aria-label=Pink class="btn btn-sm w-100 palette text-bg-pink" data-palette=pink></a></li><li class="col-4 my-1"><a role=button id=palette-purple aria-label=Purple class="btn btn-sm w-100 palette text-bg-purple" data-palette=purple></a></li><li class="col-4 my-1"><a role=button id=palette-red aria-label=Red class="btn btn-sm w-100 palette text-bg-red" data-palette=red></a></li><li class="col-4 my-1"><a role=button id=palette-teal aria-label=Teal class="btn btn-sm w-100 palette text-bg-teal" data-palette=teal></a></li><li class="col-4 my-1"><a role=button id=palette-yellow aria-label=Yellow class="btn btn-sm w-100 palette text-bg-yellow" data-palette=yellow></a></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=modeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="mode-icon fas fa-fw fa-sun" id=modeIcon></i>
<span class=d-xxl-none>Mode</span></a><ul class="mode-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=modeDropdown><li class="mode-item active" data-color-mode=light data-icon=sun><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-sun"></i> Light</button></li><li class=mode-item data-color-mode=dark data-icon=moon><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-moon"></i> Dark</button></li><li class=mode-item data-color-mode=auto data-icon=adjust><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-adjust"></i> Auto</button></li></ul></li></ul></div></div><div class=d-flex><button class="navbar-toggler order-5 border-0" type=button data-bs-toggle=offcanvas data-bs-target=#navbarMenus aria-controls=navbarMenus aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-h"></i></button></div></div></nav></header><main class=container><div class="row content"><noscript><div class="alert alert-danger" role=alert>Your browser does not support JavaScript.</div></noscript><div class=col-xxl-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class="card-body pb-0"><ol class="hbs-breadcrumb breadcrumb flex-nowrap"><li class="breadcrumb-item text-surface"><a href=/>Home</a></li><li class="breadcrumb-item text-surface"><a href=/blog/>Blogs</a></li><li class="breadcrumb-item active">Getting Started With Pyflink on AWS - Part 1 Local Flink and Local Kafka</li></ol></div></nav><div class="post-panel-wrapper position-relative d-flex justify-content-center"><div class="d-flex flex-row justify-content-center rounded-5 border post-panel position-fixed px-3 py-1 surface shadow-1"><a class="action action-toc d-none d-xxl-block" href=#postTOC role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-toc d-block d-xxl-none" href=#post-toc-container role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-post-comments" href=#post-comments role=button aria-label=Comments title=Comments><i class="fas fa-fw fa-comments"></i>
</a><a id=sidebarToggler class="action action-sidebar-toggler d-none d-xxl-block" role=button title="Toggle sidebar"><i class="fas fa-fw fa-expand-alt" data-fa-transform=rotate-45></i></a></div></div><article class="row card component mb-4 post"><div class=card-header><h1 class="card-title post-title my-2">Getting Started With Pyflink on AWS - Part 1 Local Flink and Local Kafka</h1></div><div class=card-body><div class="post-meta mb-3"><span class="post-date me-1 mb-1" title="created on 2023-08-17 00:00:00 +0000 UTC, updated on 2024-04-14 22:44:15 +0000 UTC.">August 17, 2023</span><span class="post-reading-time me-1 mb-1">16 min read</span><a href=/categories/data-streaming/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-category">
<i class="fas fa-fw fa-folder me-1"></i>Data Streaming</a><a href=/series/getting-started-with-pyflink-on-aws/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-series">
<i class="fas fa-fw fa-columns me-1"></i>Getting Started With Pyflink on AWS</a><a href=/tags/amazon-managed-flink/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Amazon Managed Flink</a><a href=/tags/amazon-managed-service-for-apache-flink/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Amazon Managed Service for Apache Flink</a><a href=/tags/amazon-msk/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Amazon MSK</a><a href=/tags/apache-flink/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Flink</a><a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Kafka</a><a href=/tags/docker/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Docker</a><a href=/tags/docker-compose/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Docker Compose</a><a href=/tags/pyflink/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Pyflink</a><a href=/tags/python/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Python</a></div><picture class="d-flex justify-content-center"><source srcset=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured_hu6470c0101df93a224de5159e363e8665_55960_0x270_resize_box_3.png type=image/png media="(max-width: 576px)" width=468 height=270><img class="post-featured-img h-auto w-auto mb-3" alt="Getting Started with Pyflink on AWS - Part 1 Local Flink and Local Kafka" src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured_hu6470c0101df93a224de5159e363e8665_55960_0x480_resize_box_3.png width=832 height=480 data-src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured.png></picture><p class="lead mb-3 text-body-emphasis">Apache Flink is widely used for building real-time stream processing applications. On AWS, Amazon Managed Service for Apache Flink is the easiest option to develop a Flink app as it provides the underlying infrastructure. Updating a guide from AWS, this series of posts discuss how to develop and deploy a Flink (Pyflink) application via KDA where the data source and sink are Kafka topics. In part 1, the app will be developed locally targeting a Kafka cluster created by Docker. Furthermore, it will be executed in a virtual environment as well as in a local Flink cluster for improved monitoring.</p><div id=postTOC class="mb-3 text-surface"><h2 class=mb-3>Contents<a class="anchor ms-1" href=#postTOC></a></h2><nav id=TableOfContents><ul><li><a href=#architecture>Architecture</a></li><li><a href=#infrastructure>Infrastructure</a><ul><li><a href=#preparation>Preparation</a></li><li><a href=#kafka-cluster>Kafka Cluster</a></li><li><a href=#flink-cluster>Flink Cluster</a></li><li><a href=#virtual-environment>Virtual Environment</a></li></ul></li><li><a href=#application>Application</a><ul><li><a href=#source-data>Source Data</a></li><li><a href=#process-data>Process Data</a><ul><li><a href=#run-locally>Run Locally</a></li><li><a href=#run-in-flink-cluster>Run in Flink Cluster</a></li></ul></li></ul></li><li><a href=#summary>Summary</a></li></ul></nav><hr class=text-secondary></div><div class="post-content mb-3" data-bs-spy=scroll data-bs-target=#TableOfContents tabindex=0><div id=post-content-body><p><a href=https://flink.apache.org/ target=_blank rel="noopener noreferrer">Apache Flink<i class="fas fa-external-link-square-alt ms-1"></i></a> is an open-source, unified stream-processing and batch-processing framework. Its core is a distributed streaming data-flow engine that you can use to run real-time stream processing on high-throughput data sources. Currently, it is widely used to build applications for fraud/anomaly detection, rule-based alerting, business process monitoring, and continuous ETL to name a few. On AWS, we can deploy a Flink application via <a href=https://aws.amazon.com/kinesis/data-analytics/ target=_blank rel="noopener noreferrer">Amazon Kinesis Data Analytics (KDA)<i class="fas fa-external-link-square-alt ms-1"></i></a>, <a href=https://aws.amazon.com/emr/ target=_blank rel="noopener noreferrer">Amazon EMR<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href=https://aws.amazon.com/eks/ target=_blank rel="noopener noreferrer">Amazon EKS<i class="fas fa-external-link-square-alt ms-1"></i></a>. Among those, KDA is the easiest option as it provides the underlying infrastructure for your Apache Flink applications.</p><p>For those who are new to Flink (Pyflink) and KDA, AWS provides a good resource that guides how to develop a Flink application locally and deploy via KDA. The guide uses Amazon Kinesis Data Stream as a data source and demonstrates how to sink records into multiple destinations - Kinesis Data Stream, Kinesis Firehose Delivery Stream and S3. It can be found in this <a href=https://github.com/aws-samples/pyflink-getting-started target=_blank rel="noopener noreferrer">GitHub project<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><p>In this series of posts, we will update one of the examples of the guide by changing the data source and sink into <a href=https://kafka.apache.org/ target=_blank rel="noopener noreferrer">Apache Kafka<i class="fas fa-external-link-square-alt ms-1"></i></a> topics. In part 1, we will discuss how to develop a Flink application that targets a local Kafka cluster. Furthermore, it will be executed in a virtual environment as well as in a local Flink cluster for improved monitoring. The Flink application will be amended to connect a Kafka cluster on Amazon MSK in part 2. The Kafka cluster will be authenticated by <a href=https://docs.aws.amazon.com/msk/latest/developerguide/iam-access-control.html target=_blank rel="noopener noreferrer">IAM access control<i class="fas fa-external-link-square-alt ms-1"></i></a>, and the Flink app needs to change its configuration accordingly by creating a custom Uber Jar file. In part 3, the application will be deployed via KDA using an application package that is saved in S3. The application package is a zip file that includes the application script, custom Uber Jar file, and 3rd-party Python packages. The deployment will be made by <a href=https://www.terraform.io/ target=_blank rel="noopener noreferrer">Terraform<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><ul><li><a href=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/#>Part 1 Local Flink and Local Kafka</a> (this post)</li><li><a href=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2>Part 2 Local Flink and MSK</a></li><li><a href=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3>Part 3 AWS Managed Flink and MSK</a></li></ul><p>[<strong>Update 2023-08-30</strong>] Amazon Kinesis Data Analytics is renamed into <a href=https://aws.amazon.com/about-aws/whats-new/2023/08/amazon-managed-service-apache-flink/ target=_blank rel="noopener noreferrer">Amazon Managed Service for Apache Flink<i class="fas fa-external-link-square-alt ms-1"></i></a>. In this post, Kinesis Data Analytics (KDA) and Amazon Managed Service for Apache Flink will be used interchangeably.</p><h2 id=architecture data-numberify>Architecture<a class="anchor ms-1" href=#architecture></a></h2><p>The Python source data generator (<em>producer.py</em>) sends random stock price records into a Kafka topic. The messages in the source topic are consumed by a Flink application, and it just writes those messages into a different sink topic. This is the simplest application of the AWS guide, and you may try <a href=https://github.com/aws-samples/pyflink-getting-started/tree/main/pyflink-examples target=_blank rel="noopener noreferrer">other examples<i class="fas fa-external-link-square-alt ms-1"></i></a> if interested.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured.png loading=lazy width=1123 height=648></picture></p><h2 id=infrastructure data-numberify>Infrastructure<a class="anchor ms-1" href=#infrastructure></a></h2><p>A Kafka cluster and management app (<em>Kpow</em>) are created using Docker while the Python apps including the Flink app run in a virtual environment in the first trial. After that the Flink app is submitted to a local Flink cluster for improved monitoring. The Flink cluster is also created using Docker. The source can be found in the <a href=https://github.com/jaehyeon-kim/flink-demos/tree/master/pyflink-getting-started-on-aws/local target=_blank rel="noopener noreferrer"><strong>GitHub repository</strong><i class="fas fa-external-link-square-alt ms-1"></i></a> of this post.</p><h3 id=preparation data-numberify>Preparation<a class="anchor ms-1" href=#preparation></a></h3><p>As discussed later, the Flink application needs the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/connectors/table/kafka/ target=_blank rel="noopener noreferrer">Apache Kafka SQL Connector<i class="fas fa-external-link-square-alt ms-1"></i></a> artifact (<em>flink-sql-connector-kafka-1.15.2.jar</em>) in order to connect a Kafka cluster. Also, the <em>kafka-python</em> package is downloaded to check if <code>--pyFiles</code> option works when submitting the app to a Flink cluster or deploying via KDA. They can be downloaded by executing the following script.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl><span class=c1># build.sh</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1>#!/usr/bin/env bash</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl><span class=nv>SCRIPT_DIR</span><span class=o>=</span><span class=s2>&#34;</span><span class=k>$(</span><span class=nb>cd</span> <span class=k>$(</span>dirname <span class=s2>&#34;</span><span class=nv>$0</span><span class=s2>&#34;</span><span class=k>)</span><span class=p>;</span> <span class=nb>pwd</span><span class=k>)</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=nv>SRC_PATH</span><span class=o>=</span><span class=nv>$SCRIPT_DIR</span>/package
</span></span><span class=line><span class=ln> 5</span><span class=cl>rm -rf <span class=nv>$SRC_PATH</span> <span class=o>&amp;&amp;</span> mkdir -p <span class=nv>$SRC_PATH</span>/lib
</span></span><span class=line><span class=ln> 6</span><span class=cl>
</span></span><span class=line><span class=ln> 7</span><span class=cl><span class=c1>## Download flink sql connector kafka</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl><span class=nb>echo</span> <span class=s2>&#34;download flink sql connector kafka...&#34;</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl><span class=nv>VERSION</span><span class=o>=</span>1.15.2
</span></span><span class=line><span class=ln>10</span><span class=cl><span class=nv>FILE_NAME</span><span class=o>=</span>flink-sql-connector-kafka-<span class=nv>$VERSION</span>
</span></span><span class=line><span class=ln>11</span><span class=cl><span class=nv>DOWNLOAD_URL</span><span class=o>=</span>https://repo.maven.apache.org/maven2/org/apache/flink/flink-sql-connector-kafka/<span class=nv>$VERSION</span>/flink-sql-connector-kafka-<span class=nv>$VERSION</span>.jar
</span></span><span class=line><span class=ln>12</span><span class=cl>curl -L -o <span class=nv>$SRC_PATH</span>/lib/<span class=nv>$FILE_NAME</span>.jar <span class=si>${</span><span class=nv>DOWNLOAD_URL</span><span class=si>}</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>
</span></span><span class=line><span class=ln>14</span><span class=cl><span class=c1>## Install pip packages</span>
</span></span><span class=line><span class=ln>15</span><span class=cl><span class=nb>echo</span> <span class=s2>&#34;install and zip pip packages...&#34;</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>pip install -r requirements.txt --target <span class=nv>$SRC_PATH</span>/site_packages
</span></span><span class=line><span class=ln>17</span><span class=cl>
</span></span><span class=line><span class=ln>18</span><span class=cl><span class=c1>## Package pyflink app</span>
</span></span><span class=line><span class=ln>19</span><span class=cl><span class=nb>echo</span> <span class=s2>&#34;package pyflink app&#34;</span>
</span></span><span class=line><span class=ln>20</span><span class=cl>zip -r kda-package.zip processor.py package/lib package/site_packages
</span></span></code></pre></div><p>Once downloaded, the Kafka SQL artifact and python package can be found in the <em>lib</em> and <em>site_packages</em> folders respectively as shown below.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/source-folders.png loading=lazy width=377 height=251></picture></p><h3 id=kafka-cluster data-numberify>Kafka Cluster<a class="anchor ms-1" href=#kafka-cluster></a></h3><p>A Kafka cluster with a single broker and zookeeper node is used in this post. The broker has two listeners and the port 9092 and 29092 are used for internal and external communication respectively. The default number of topic partitions is set to 2. Details about Kafka cluster setup can be found in <a href=/blog/2023-05-04-kafka-development-with-docker-part-1/>this post</a>.</p><p>The <a href=https://docs.kpow.io/ce/ target=_blank rel="noopener noreferrer">Kpow CE<i class="fas fa-external-link-square-alt ms-1"></i></a> is used for ease of monitoring Kafka topics and related resources. The bootstrap server address is added as an environment variable. See <a href=/blog/2023-05-18-kafka-development-with-docker-part-2/>this post</a> for details about Kafka management apps.</p><p>The Kafka cluster can be started by <code>docker-compose -f compose-kafka.yml up -d</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=ln> 1</span><span class=cl><span class=c># compose-kafka.yml</span><span class=w>
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=w></span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;3.5&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln> 3</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=w>  </span><span class=nt>zookeeper</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 6</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/zookeeper:3.5</span><span class=w>
</span></span></span><span class=line><span class=ln> 7</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=ln> 8</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 9</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;2181&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>10</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>11</span><span class=cl><span class=w>      </span>- <span class=l>kafkanet</span><span class=w>
</span></span></span><span class=line><span class=ln>12</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>13</span><span class=cl><span class=w>      </span>- <span class=l>ALLOW_ANONYMOUS_LOGIN=yes</span><span class=w>
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=w>      </span>- <span class=l>zookeeper_data:/bitnami/zookeeper</span><span class=w>
</span></span></span><span class=line><span class=ln>16</span><span class=cl><span class=w>  </span><span class=nt>kafka-0</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>17</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/kafka:2.8.1</span><span class=w>
</span></span></span><span class=line><span class=ln>18</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=ln>19</span><span class=cl><span class=w>    </span><span class=nt>expose</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>20</span><span class=cl><span class=w>      </span>- <span class=m>9092</span><span class=w>
</span></span></span><span class=line><span class=ln>21</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>22</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;29092:29092&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>23</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>24</span><span class=cl><span class=w>      </span>- <span class=l>kafkanet</span><span class=w>
</span></span></span><span class=line><span class=ln>25</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>26</span><span class=cl><span class=w>      </span>- <span class=l>ALLOW_PLAINTEXT_LISTENER=yes</span><span class=w>
</span></span></span><span class=line><span class=ln>27</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181</span><span class=w>
</span></span></span><span class=line><span class=ln>28</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_BROKER_ID=0</span><span class=w>
</span></span></span><span class=line><span class=ln>29</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=ln>30</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:29092</span><span class=w>
</span></span></span><span class=line><span class=ln>31</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka-0:9092,EXTERNAL://localhost:29092</span><span class=w>
</span></span></span><span class=line><span class=ln>32</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL</span><span class=w>
</span></span></span><span class=line><span class=ln>33</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_NUM_PARTITIONS=2</span><span class=w>
</span></span></span><span class=line><span class=ln>34</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>35</span><span class=cl><span class=w>      </span>- <span class=l>kafka_0_data:/bitnami/kafka</span><span class=w>
</span></span></span><span class=line><span class=ln>36</span><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>37</span><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=ln>38</span><span class=cl><span class=w>  </span><span class=nt>kpow</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>39</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>factorhouse/kpow-ce:91.2.1</span><span class=w>
</span></span></span><span class=line><span class=ln>40</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kpow</span><span class=w>
</span></span></span><span class=line><span class=ln>41</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>42</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;3000:3000&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>43</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>44</span><span class=cl><span class=w>      </span>- <span class=l>kafkanet</span><span class=w>
</span></span></span><span class=line><span class=ln>45</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>46</span><span class=cl><span class=w>      </span><span class=nt>BOOTSTRAP</span><span class=p>:</span><span class=w> </span><span class=l>kafka-0:9092</span><span class=w>
</span></span></span><span class=line><span class=ln>47</span><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>48</span><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=ln>49</span><span class=cl><span class=w>      </span>- <span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=ln>50</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln>51</span><span class=cl><span class=w></span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>52</span><span class=cl><span class=w>  </span><span class=nt>kafkanet</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>53</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-network</span><span class=w>
</span></span></span><span class=line><span class=ln>54</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln>55</span><span class=cl><span class=w></span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>56</span><span class=cl><span class=w>  </span><span class=nt>zookeeper_data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>57</span><span class=cl><span class=w>    </span><span class=nt>driver</span><span class=p>:</span><span class=w> </span><span class=l>local</span><span class=w>
</span></span></span><span class=line><span class=ln>58</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper_data</span><span class=w>
</span></span></span><span class=line><span class=ln>59</span><span class=cl><span class=w>  </span><span class=nt>kafka_0_data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>60</span><span class=cl><span class=w>    </span><span class=nt>driver</span><span class=p>:</span><span class=w> </span><span class=l>local</span><span class=w>
</span></span></span><span class=line><span class=ln>61</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>kafka_0_data</span><span class=w>
</span></span></span></code></pre></div><h3 id=flink-cluster data-numberify>Flink Cluster<a class="anchor ms-1" href=#flink-cluster></a></h3><p>In order to run a PyFlink application in a Flink cluster, we need to install Python and the <em>apache-flink</em> package additionally. We can create a custom Docker image based on the <a href=https://hub.docker.com/_/flink target=_blank rel="noopener noreferrer">official Flink<i class="fas fa-external-link-square-alt ms-1"></i></a> image. I chose the version 1.15.2 as it is the recommended Flink version by KDA. The custom image can be built by <code>docker build -t pyflink:1.15.2-scala_2.12 .</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-Docker data-lang=Docker><span class=line><span class=ln> 1</span><span class=cl><span class=k>FROM</span><span class=s> flink:1.15.2-scala_2.12</span><span class=err>
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=err>
</span></span></span><span class=line><span class=ln> 3</span><span class=cl><span class=err></span><span class=k>ARG</span> PYTHON_VERSION<span class=err>
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=err></span><span class=k>ENV</span> <span class=nv>PYTHON_VERSION</span><span class=o>=</span><span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=k>:-</span><span class=nv>3</span><span class=p>.8.10</span><span class=si>}</span><span class=err>
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=err></span><span class=k>ARG</span> FLINK_VERSION<span class=err>
</span></span></span><span class=line><span class=ln> 6</span><span class=cl><span class=err></span><span class=k>ENV</span> <span class=nv>FLINK_VERSION</span><span class=o>=</span><span class=si>${</span><span class=nv>FLINK_VERSION</span><span class=k>:-</span><span class=nv>1</span><span class=p>.15.2</span><span class=si>}</span><span class=err>
</span></span></span><span class=line><span class=ln> 7</span><span class=cl><span class=err>
</span></span></span><span class=line><span class=ln> 8</span><span class=cl><span class=err></span><span class=c># Currently only Python 3.6, 3.7 and 3.8 are supported officially.</span><span class=err>
</span></span></span><span class=line><span class=ln> 9</span><span class=cl><span class=err></span><span class=k>RUN</span> apt-get update -y <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>10</span><span class=cl><span class=se></span>  apt-get install -y build-essential libssl-dev zlib1g-dev libbz2-dev libffi-dev <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>11</span><span class=cl><span class=se></span>  wget https://www.python.org/ftp/python/<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span>/Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span>.tgz <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>12</span><span class=cl><span class=se></span>  tar -xvf Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span>.tgz <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>13</span><span class=cl><span class=se></span>  <span class=nb>cd</span> Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span> <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=se></span>  ./configure --without-tests --enable-shared <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=se></span>  make -j6 <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>16</span><span class=cl><span class=se></span>  make install <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>17</span><span class=cl><span class=se></span>  ldconfig /usr/local/lib <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>18</span><span class=cl><span class=se></span>  <span class=nb>cd</span> .. <span class=o>&amp;&amp;</span> rm -f Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span>.tgz <span class=o>&amp;&amp;</span> rm -rf Python-<span class=si>${</span><span class=nv>PYTHON_VERSION</span><span class=si>}</span> <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>19</span><span class=cl><span class=se></span>  ln -s /usr/local/bin/python3 /usr/local/bin/python <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>20</span><span class=cl><span class=se></span>  apt-get clean <span class=o>&amp;&amp;</span> <span class=se>\
</span></span></span><span class=line><span class=ln>21</span><span class=cl><span class=se></span>  rm -rf /var/lib/apt/lists/*<span class=err>
</span></span></span><span class=line><span class=ln>22</span><span class=cl><span class=err>
</span></span></span><span class=line><span class=ln>23</span><span class=cl><span class=err></span><span class=c># install PyFlink</span><span class=err>
</span></span></span><span class=line><span class=ln>24</span><span class=cl><span class=err></span><span class=k>RUN</span> pip3 install apache-flink<span class=o>==</span><span class=si>${</span><span class=nv>FLINK_VERSION</span><span class=si>}</span><span class=err>
</span></span></span></code></pre></div><p>A Flink cluster is made up of a single Job Manger and Task Manager, and the cluster runs in the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.17/docs/deployment/overview/ target=_blank rel="noopener noreferrer">Session Mode<i class="fas fa-external-link-square-alt ms-1"></i></a> where one or more Flink applications can be submitted/executed simultaneously. See <a href=https://nightlies.apache.org/flink/flink-docs-master/docs/deployment/resource-providers/standalone/docker/#flink-with-docker-compose target=_blank rel="noopener noreferrer">this page<i class="fas fa-external-link-square-alt ms-1"></i></a> for details about how to create a Flink cluster using <em>docker-compose</em>.</p><p>Two environment variables are configured to adjust the application behaviour. The <em>RUNTIME_ENV</em> is set to <em>DOCKER</em>, and it determines which <a href=https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/python/dependency_management/ target=_blank rel="noopener noreferrer">pipeline jar<i class="fas fa-external-link-square-alt ms-1"></i></a> and application property file to choose. Also, the <em>BOOTSTRAP_SERVERS</em> overrides the Kafka bootstrap server address value from the application property file. We will make use of it to configure the bootstrap server address dynamically for MSK in part 2. Finally, the current directory is volume-mapped into <em>/etc/flink</em> so that the application and related resources can be available in the Flink cluster.</p><p>The Flink cluster can be started by <code>docker-compose -f compose-flink.yml up -d</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=ln> 1</span><span class=cl><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;3.5&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln> 3</span><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=w>  </span><span class=nt>jobmanager</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>pyflink:1.15.2-scala_2.12</span><span class=w>
</span></span></span><span class=line><span class=ln> 6</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>jobmanager</span><span class=w>
</span></span></span><span class=line><span class=ln> 7</span><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>jobmanager</span><span class=w>
</span></span></span><span class=line><span class=ln> 8</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 9</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;8081:8081&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>10</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>11</span><span class=cl><span class=w>      </span>- <span class=l>kafkanet</span><span class=w>
</span></span></span><span class=line><span class=ln>12</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>13</span><span class=cl><span class=w>      </span>- <span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=sd>        FLINK_PROPERTIES=
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=sd>        jobmanager.rpc.address: jobmanager
</span></span></span><span class=line><span class=ln>16</span><span class=cl><span class=sd>        state.backend: filesystem
</span></span></span><span class=line><span class=ln>17</span><span class=cl><span class=sd>        state.checkpoints.dir: file:///tmp/flink-checkpoints
</span></span></span><span class=line><span class=ln>18</span><span class=cl><span class=sd>        heartbeat.interval: 1000
</span></span></span><span class=line><span class=ln>19</span><span class=cl><span class=sd>        heartbeat.timeout: 5000
</span></span></span><span class=line><span class=ln>20</span><span class=cl><span class=sd>        rest.flamegraph.enabled: true
</span></span></span><span class=line><span class=ln>21</span><span class=cl><span class=sd>        web.backpressure.refresh-interval: 10000</span><span class=w>        
</span></span></span><span class=line><span class=ln>22</span><span class=cl><span class=w>      </span>- <span class=l>RUNTIME_ENV=DOCKER</span><span class=w>
</span></span></span><span class=line><span class=ln>23</span><span class=cl><span class=w>      </span>- <span class=l>BOOTSTRAP_SERVERS=kafka-0:9092</span><span class=w>
</span></span></span><span class=line><span class=ln>24</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>25</span><span class=cl><span class=w>      </span>- <span class=l>$PWD:/etc/flink</span><span class=w>
</span></span></span><span class=line><span class=ln>26</span><span class=cl><span class=w>  </span><span class=nt>taskmanager</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>27</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>pyflink:1.15.2-scala_2.12</span><span class=w>
</span></span></span><span class=line><span class=ln>28</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>taskmanager</span><span class=w>
</span></span></span><span class=line><span class=ln>29</span><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>taskmanager</span><span class=w>
</span></span></span><span class=line><span class=ln>30</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>31</span><span class=cl><span class=w>      </span>- <span class=l>kafkanet</span><span class=w>
</span></span></span><span class=line><span class=ln>32</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>33</span><span class=cl><span class=w>      </span>- <span class=l>flink_data:/tmp/</span><span class=w>
</span></span></span><span class=line><span class=ln>34</span><span class=cl><span class=w>      </span>- <span class=l>$PWD:/etc/flink</span><span class=w>
</span></span></span><span class=line><span class=ln>35</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>36</span><span class=cl><span class=w>      </span>- <span class=p>|</span><span class=sd>
</span></span></span><span class=line><span class=ln>37</span><span class=cl><span class=sd>        FLINK_PROPERTIES=
</span></span></span><span class=line><span class=ln>38</span><span class=cl><span class=sd>        jobmanager.rpc.address: jobmanager
</span></span></span><span class=line><span class=ln>39</span><span class=cl><span class=sd>        taskmanager.numberOfTaskSlots: 3
</span></span></span><span class=line><span class=ln>40</span><span class=cl><span class=sd>        state.backend: filesystem
</span></span></span><span class=line><span class=ln>41</span><span class=cl><span class=sd>        state.checkpoints.dir: file:///tmp/flink-checkpoints
</span></span></span><span class=line><span class=ln>42</span><span class=cl><span class=sd>        heartbeat.interval: 1000
</span></span></span><span class=line><span class=ln>43</span><span class=cl><span class=sd>        heartbeat.timeout: 5000</span><span class=w>        
</span></span></span><span class=line><span class=ln>44</span><span class=cl><span class=w>      </span>- <span class=l>RUNTIME_ENV=DOCKER</span><span class=w>
</span></span></span><span class=line><span class=ln>45</span><span class=cl><span class=w>      </span>- <span class=l>BOOTSTRAP_SERVERS=kafka-0:9092</span><span class=w>
</span></span></span><span class=line><span class=ln>46</span><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>47</span><span class=cl><span class=w>      </span>- <span class=l>jobmanager</span><span class=w>
</span></span></span><span class=line><span class=ln>48</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln>49</span><span class=cl><span class=w></span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>50</span><span class=cl><span class=w>  </span><span class=nt>kafkanet</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>51</span><span class=cl><span class=w>    </span><span class=nt>external</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=ln>52</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-network</span><span class=w>
</span></span></span><span class=line><span class=ln>53</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln>54</span><span class=cl><span class=w></span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>55</span><span class=cl><span class=w>  </span><span class=nt>flink_data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>56</span><span class=cl><span class=w>    </span><span class=nt>driver</span><span class=p>:</span><span class=w> </span><span class=l>local</span><span class=w>
</span></span></span><span class=line><span class=ln>57</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>flink_data</span><span class=w>
</span></span></span></code></pre></div><h3 id=virtual-environment data-numberify>Virtual Environment<a class="anchor ms-1" href=#virtual-environment></a></h3><p>As mentioned earlier, all Python apps run in a virtual environment, and we have the following pip packages. We use the version 1.15.2 of the <a href=https://pypi.org/project/apache-flink/ target=_blank rel="noopener noreferrer">apache-flink<i class="fas fa-external-link-square-alt ms-1"></i></a> package because it is the recommended version by KDA. We also need the <a href=https://pypi.org/project/kafka-python/ target=_blank rel="noopener noreferrer">kafka-python<i class="fas fa-external-link-square-alt ms-1"></i></a> package for source data generation. The pip packages can be installed by <code>pip install -r requirements-dev.txt</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-txt data-lang=txt><span class=line><span class=ln>1</span><span class=cl># requirements.txt
</span></span><span class=line><span class=ln>2</span><span class=cl>kafka-python==2.0.2
</span></span><span class=line><span class=ln>3</span><span class=cl>
</span></span><span class=line><span class=ln>4</span><span class=cl># requirements-dev.txt
</span></span><span class=line><span class=ln>5</span><span class=cl>-r requirements.txt
</span></span><span class=line><span class=ln>6</span><span class=cl>apache-flink==1.15.2
</span></span><span class=line><span class=ln>7</span><span class=cl>black==19.10b0
</span></span><span class=line><span class=ln>8</span><span class=cl>pytest
</span></span><span class=line><span class=ln>9</span><span class=cl>pytest-cov
</span></span></code></pre></div><h2 id=application data-numberify>Application<a class="anchor ms-1" href=#application></a></h2><h3 id=source-data data-numberify>Source Data<a class="anchor ms-1" href=#source-data></a></h3><p>A single Python script is created to generate fake stock price records. The class for the stock record has the <em>asdict</em>, <em>auto</em> and <em>create</em> methods. The <em>create</em> method generates a list of records where each element is instantiated by the <em>auto</em> method. Those records are sent into the relevant Kafka topic after being converted into a dictionary by the <em>asdict</em> method.</p><p>A Kafka producer is created as an attribute of the <em>Producer</em> class. The source records are sent into the relevant topic by the <em>send</em> method. Note that both the key and value of the messages are serialized as json.</p><p>The data generator can be started simply by <code>python producer.py</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=ln> 1</span><span class=cl><span class=c1># producer.py</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl><span class=kn>import</span> <span class=nn>datetime</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl><span class=kn>import</span> <span class=nn>typing</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl><span class=kn>import</span> <span class=nn>random</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl><span class=kn>import</span> <span class=nn>logging</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl><span class=kn>import</span> <span class=nn>dataclasses</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>
</span></span><span class=line><span class=ln>11</span><span class=cl><span class=kn>from</span> <span class=nn>kafka</span> <span class=kn>import</span> <span class=n>KafkaProducer</span>
</span></span><span class=line><span class=ln>12</span><span class=cl>
</span></span><span class=line><span class=ln>13</span><span class=cl><span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span>
</span></span><span class=line><span class=ln>14</span><span class=cl>    <span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>,</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>    <span class=nb>format</span><span class=o>=</span><span class=s2>&#34;</span><span class=si>%(asctime)s</span><span class=s2>.</span><span class=si>%(msecs)03d</span><span class=s2>:</span><span class=si>%(levelname)s</span><span class=s2>:</span><span class=si>%(name)s</span><span class=s2>:</span><span class=si>%(message)s</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>    <span class=n>datefmt</span><span class=o>=</span><span class=s2>&#34;%Y-%m-</span><span class=si>%d</span><span class=s2> %H:%M:%S&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>17</span><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>
</span></span><span class=line><span class=ln>19</span><span class=cl><span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s2>&#34;%Y-%m-</span><span class=si>%d</span><span class=s2> %H:%M:%S.</span><span class=si>%f</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>20</span><span class=cl>
</span></span><span class=line><span class=ln>21</span><span class=cl>
</span></span><span class=line><span class=ln>22</span><span class=cl><span class=nd>@dataclasses.dataclass</span>
</span></span><span class=line><span class=ln>23</span><span class=cl><span class=k>class</span> <span class=nc>Stock</span><span class=p>:</span>
</span></span><span class=line><span class=ln>24</span><span class=cl>    <span class=n>event_time</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=ln>25</span><span class=cl>    <span class=n>ticker</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=ln>26</span><span class=cl>    <span class=n>price</span><span class=p>:</span> <span class=nb>float</span>
</span></span><span class=line><span class=ln>27</span><span class=cl>
</span></span><span class=line><span class=ln>28</span><span class=cl>    <span class=k>def</span> <span class=nf>asdict</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=ln>29</span><span class=cl>        <span class=k>return</span> <span class=n>dataclasses</span><span class=o>.</span><span class=n>asdict</span><span class=p>(</span><span class=bp>self</span><span class=p>)</span>
</span></span><span class=line><span class=ln>30</span><span class=cl>
</span></span><span class=line><span class=ln>31</span><span class=cl>    <span class=nd>@classmethod</span>
</span></span><span class=line><span class=ln>32</span><span class=cl>    <span class=k>def</span> <span class=nf>auto</span><span class=p>(</span><span class=bp>cls</span><span class=p>,</span> <span class=n>ticker</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln>33</span><span class=cl>        <span class=c1># event_time = datetime.datetime.now().isoformat(timespec=&#34;milliseconds&#34;)</span>
</span></span><span class=line><span class=ln>34</span><span class=cl>        <span class=n>event_time</span> <span class=o>=</span> <span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=o>.</span><span class=n>now</span><span class=p>()</span><span class=o>.</span><span class=n>strftime</span><span class=p>(</span><span class=s2>&#34;%Y-%m-</span><span class=si>%d</span><span class=s2> %H:%M:%S.</span><span class=si>%f</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>35</span><span class=cl>        <span class=n>price</span> <span class=o>=</span> <span class=nb>round</span><span class=p>(</span><span class=n>random</span><span class=o>.</span><span class=n>random</span><span class=p>()</span> <span class=o>*</span> <span class=mi>100</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=ln>36</span><span class=cl>        <span class=k>return</span> <span class=bp>cls</span><span class=p>(</span><span class=n>event_time</span><span class=p>,</span> <span class=n>ticker</span><span class=p>,</span> <span class=n>price</span><span class=p>)</span>
</span></span><span class=line><span class=ln>37</span><span class=cl>
</span></span><span class=line><span class=ln>38</span><span class=cl>    <span class=nd>@staticmethod</span>
</span></span><span class=line><span class=ln>39</span><span class=cl>    <span class=k>def</span> <span class=nf>create</span><span class=p>():</span>
</span></span><span class=line><span class=ln>40</span><span class=cl>        <span class=n>tickers</span> <span class=o>=</span> <span class=s1>&#39;[&#34;AAPL&#34;, &#34;ACN&#34;, &#34;ADBE&#34;, &#34;AMD&#34;, &#34;AVGO&#34;, &#34;CRM&#34;, &#34;CSCO&#34;, &#34;IBM&#34;, &#34;INTC&#34;, &#34;MA&#34;, &#34;MSFT&#34;, &#34;NVDA&#34;, &#34;ORCL&#34;, &#34;PYPL&#34;, &#34;QCOM&#34;, &#34;TXN&#34;, &#34;V&#34;]&#39;</span>
</span></span><span class=line><span class=ln>41</span><span class=cl>        <span class=k>return</span> <span class=p>[</span><span class=n>Stock</span><span class=o>.</span><span class=n>auto</span><span class=p>(</span><span class=n>ticker</span><span class=p>)</span> <span class=k>for</span> <span class=n>ticker</span> <span class=ow>in</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>tickers</span><span class=p>)]</span>
</span></span><span class=line><span class=ln>42</span><span class=cl>
</span></span><span class=line><span class=ln>43</span><span class=cl>
</span></span><span class=line><span class=ln>44</span><span class=cl><span class=k>class</span> <span class=nc>Producer</span><span class=p>:</span>
</span></span><span class=line><span class=ln>45</span><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>bootstrap_servers</span><span class=p>:</span> <span class=nb>list</span><span class=p>,</span> <span class=n>topic</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln>46</span><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>bootstrap_servers</span> <span class=o>=</span> <span class=n>bootstrap_servers</span>
</span></span><span class=line><span class=ln>47</span><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>topic</span> <span class=o>=</span> <span class=n>topic</span>
</span></span><span class=line><span class=ln>48</span><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>producer</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>create</span><span class=p>()</span>
</span></span><span class=line><span class=ln>49</span><span class=cl>
</span></span><span class=line><span class=ln>50</span><span class=cl>    <span class=k>def</span> <span class=nf>create</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=ln>51</span><span class=cl>        <span class=k>return</span> <span class=n>KafkaProducer</span><span class=p>(</span>
</span></span><span class=line><span class=ln>52</span><span class=cl>            <span class=n>bootstrap_servers</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>bootstrap_servers</span><span class=p>,</span>
</span></span><span class=line><span class=ln>53</span><span class=cl>            <span class=n>key_serializer</span><span class=o>=</span><span class=k>lambda</span> <span class=n>v</span><span class=p>:</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>v</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>serialize</span><span class=p>)</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln>54</span><span class=cl>            <span class=n>value_serializer</span><span class=o>=</span><span class=k>lambda</span> <span class=n>v</span><span class=p>:</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>v</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>serialize</span><span class=p>)</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln>55</span><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=ln>56</span><span class=cl>
</span></span><span class=line><span class=ln>57</span><span class=cl>    <span class=k>def</span> <span class=nf>send</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>stocks</span><span class=p>:</span> <span class=n>typing</span><span class=o>.</span><span class=n>List</span><span class=p>[</span><span class=n>Stock</span><span class=p>]):</span>
</span></span><span class=line><span class=ln>58</span><span class=cl>        <span class=k>for</span> <span class=n>stock</span> <span class=ow>in</span> <span class=n>stocks</span><span class=p>:</span>
</span></span><span class=line><span class=ln>59</span><span class=cl>            <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=ln>60</span><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>producer</span><span class=o>.</span><span class=n>send</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>topic</span><span class=p>,</span> <span class=n>key</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;ticker&#34;</span><span class=p>:</span> <span class=n>stock</span><span class=o>.</span><span class=n>ticker</span><span class=p>},</span> <span class=n>value</span><span class=o>=</span><span class=n>stock</span><span class=o>.</span><span class=n>asdict</span><span class=p>())</span>
</span></span><span class=line><span class=ln>61</span><span class=cl>            <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=ln>62</span><span class=cl>                <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s2>&#34;fails to send a message&#34;</span><span class=p>)</span> <span class=kn>from</span> <span class=nn>e</span>
</span></span><span class=line><span class=ln>63</span><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>producer</span><span class=o>.</span><span class=n>flush</span><span class=p>()</span>
</span></span><span class=line><span class=ln>64</span><span class=cl>
</span></span><span class=line><span class=ln>65</span><span class=cl>    <span class=k>def</span> <span class=nf>serialize</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>obj</span><span class=p>):</span>
</span></span><span class=line><span class=ln>66</span><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>obj</span><span class=p>,</span> <span class=n>datetime</span><span class=o>.</span><span class=n>datetime</span><span class=p>):</span>
</span></span><span class=line><span class=ln>67</span><span class=cl>            <span class=k>return</span> <span class=n>obj</span><span class=o>.</span><span class=n>isoformat</span><span class=p>()</span>
</span></span><span class=line><span class=ln>68</span><span class=cl>        <span class=k>if</span> <span class=nb>isinstance</span><span class=p>(</span><span class=n>obj</span><span class=p>,</span> <span class=n>datetime</span><span class=o>.</span><span class=n>date</span><span class=p>):</span>
</span></span><span class=line><span class=ln>69</span><span class=cl>            <span class=k>return</span> <span class=nb>str</span><span class=p>(</span><span class=n>obj</span><span class=p>)</span>
</span></span><span class=line><span class=ln>70</span><span class=cl>        <span class=k>return</span> <span class=n>obj</span>
</span></span><span class=line><span class=ln>71</span><span class=cl>
</span></span><span class=line><span class=ln>72</span><span class=cl>
</span></span><span class=line><span class=ln>73</span><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=ln>74</span><span class=cl>    <span class=n>producer</span> <span class=o>=</span> <span class=n>Producer</span><span class=p>(</span>
</span></span><span class=line><span class=ln>75</span><span class=cl>        <span class=n>bootstrap_servers</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;BOOTSTRAP_SERVERS&#34;</span><span class=p>,</span> <span class=s2>&#34;localhost:29092&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;,&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln>76</span><span class=cl>        <span class=n>topic</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;TOPIC_NAME&#34;</span><span class=p>,</span> <span class=s2>&#34;stocks-in&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln>77</span><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=ln>78</span><span class=cl>    <span class=n>max_run</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span><span class=s2>&#34;MAX_RUN&#34;</span><span class=p>,</span> <span class=s2>&#34;-1&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=ln>79</span><span class=cl>    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;max run - </span><span class=si>{</span><span class=n>max_run</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>80</span><span class=cl>    <span class=n>current_run</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=ln>81</span><span class=cl>    <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=ln>82</span><span class=cl>        <span class=n>current_run</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=ln>83</span><span class=cl>        <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;current run - </span><span class=si>{</span><span class=n>current_run</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>84</span><span class=cl>        <span class=k>if</span> <span class=n>current_run</span> <span class=o>-</span> <span class=n>max_run</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=ln>85</span><span class=cl>            <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;reached max run, finish&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>86</span><span class=cl>            <span class=n>producer</span><span class=o>.</span><span class=n>producer</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span><span class=line><span class=ln>87</span><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=ln>88</span><span class=cl>        <span class=n>producer</span><span class=o>.</span><span class=n>send</span><span class=p>(</span><span class=n>Stock</span><span class=o>.</span><span class=n>create</span><span class=p>())</span>
</span></span><span class=line><span class=ln>89</span><span class=cl>        <span class=n>secs</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>5</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=ln>90</span><span class=cl>        <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;messages sent... wait </span><span class=si>{</span><span class=n>secs</span><span class=si>}</span><span class=s2> seconds&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>91</span><span class=cl>        <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=n>secs</span><span class=p>)</span>
</span></span></code></pre></div><p>Once we start the app, we can check the topic for the source data is created and messages are ingested in <em>Kpow</em>.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/source-topic.png loading=lazy width=1167 height=794></picture></p><h3 id=process-data data-numberify>Process Data<a class="anchor ms-1" href=#process-data></a></h3><p>The Flink application is built using the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/python/table_api_tutorial/ target=_blank rel="noopener noreferrer">Table API<i class="fas fa-external-link-square-alt ms-1"></i></a>. We have two Kafka topics - one for the source and the other for the sink. Simply put, we can manipulate the records of the topics as tables of unbounded real-time streams with the Table API. In order to read/write records from/to a Kafka topic, we need to specify the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/connectors/table/kafka/ target=_blank rel="noopener noreferrer">Apache Kafka SQL Connector<i class="fas fa-external-link-square-alt ms-1"></i></a> artifact that we downloaded earlier as the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/dev/python/dependency_management/#jar-dependencies target=_blank rel="noopener noreferrer">pipeline jar<i class="fas fa-external-link-square-alt ms-1"></i></a>. Note we only need to configure the connector jar when we develop the app locally as the jar file will be specified by the <code>--jarfile</code> option when submitting it to a Flink cluster or deploying via KDA. We also need the application properties file (<em>application_properties.json</em>) in order to be comparable with KDA. The file contains the Flink runtime options in KDA as well as application specific properties. All the properties should be specified when deploying via KDA and, for local development, we keep them as a json file and only the application specific properties are used.</p><p>The tables for the source and output topics can be created using SQL with options that are related to the Kafka connector. Key options cover the connector name (<em>connector</em>), topic name (<em>topic</em>), bootstrap server address (<em>properties.bootstrap.servers</em>) and format (<em>format</em>). See the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/connectors/table/kafka/ target=_blank rel="noopener noreferrer">connector document<i class="fas fa-external-link-square-alt ms-1"></i></a> for more details about the connector configuration. When it comes to inserting the source records into the output table, we can use either SQL or built-in <em>add_insert</em> method.</p><p>In the <em>main</em> method, we create all the source and sink tables after mapping relevant application properties. Then the output records are inserted into the output Kafka topic. Note that the output records are printed in the terminal additionally when the app is running locally for ease of checking them.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-py data-lang=py><span class=line><span class=ln>  1</span><span class=cl><span class=c1># processor.py</span>
</span></span><span class=line><span class=ln>  2</span><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=ln>  3</span><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=ln>  4</span><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=ln>  5</span><span class=cl><span class=kn>import</span> <span class=nn>logging</span>
</span></span><span class=line><span class=ln>  6</span><span class=cl>
</span></span><span class=line><span class=ln>  7</span><span class=cl><span class=kn>import</span> <span class=nn>kafka</span>  <span class=c1># check if --pyFiles works</span>
</span></span><span class=line><span class=ln>  8</span><span class=cl><span class=kn>from</span> <span class=nn>pyflink.table</span> <span class=kn>import</span> <span class=n>EnvironmentSettings</span><span class=p>,</span> <span class=n>TableEnvironment</span>
</span></span><span class=line><span class=ln>  9</span><span class=cl>
</span></span><span class=line><span class=ln> 10</span><span class=cl><span class=n>logging</span><span class=o>.</span><span class=n>basicConfig</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 11</span><span class=cl>    <span class=n>level</span><span class=o>=</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 12</span><span class=cl>    <span class=nb>format</span><span class=o>=</span><span class=s2>&#34;</span><span class=si>%(asctime)s</span><span class=s2>.</span><span class=si>%(msecs)03d</span><span class=s2>:</span><span class=si>%(levelname)s</span><span class=s2>:</span><span class=si>%(name)s</span><span class=s2>:</span><span class=si>%(message)s</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 13</span><span class=cl>    <span class=n>datefmt</span><span class=o>=</span><span class=s2>&#34;%Y-%m-</span><span class=si>%d</span><span class=s2> %H:%M:%S&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 14</span><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=ln> 15</span><span class=cl>
</span></span><span class=line><span class=ln> 16</span><span class=cl><span class=n>RUNTIME_ENV</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;RUNTIME_ENV&#34;</span><span class=p>,</span> <span class=s2>&#34;KDA&#34;</span><span class=p>)</span>  <span class=c1># KDA, DOCKER, LOCAL</span>
</span></span><span class=line><span class=ln> 17</span><span class=cl><span class=n>BOOTSTRAP_SERVERS</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;BOOTSTRAP_SERVERS&#34;</span><span class=p>)</span>  <span class=c1># overwrite app config</span>
</span></span><span class=line><span class=ln> 18</span><span class=cl>
</span></span><span class=line><span class=ln> 19</span><span class=cl><span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;runtime environment - </span><span class=si>{</span><span class=n>RUNTIME_ENV</span><span class=si>}</span><span class=s2>...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 20</span><span class=cl>
</span></span><span class=line><span class=ln> 21</span><span class=cl><span class=n>env_settings</span> <span class=o>=</span> <span class=n>EnvironmentSettings</span><span class=o>.</span><span class=n>in_streaming_mode</span><span class=p>()</span>
</span></span><span class=line><span class=ln> 22</span><span class=cl><span class=n>table_env</span> <span class=o>=</span> <span class=n>TableEnvironment</span><span class=o>.</span><span class=n>create</span><span class=p>(</span><span class=n>env_settings</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 23</span><span class=cl>
</span></span><span class=line><span class=ln> 24</span><span class=cl><span class=n>APPLICATION_PROPERTIES_FILE_PATH</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=ln> 25</span><span class=cl>    <span class=s2>&#34;/etc/flink/application_properties.json&#34;</span>  <span class=c1># on kda or docker-compose</span>
</span></span><span class=line><span class=ln> 26</span><span class=cl>    <span class=k>if</span> <span class=n>RUNTIME_ENV</span> <span class=o>!=</span> <span class=s2>&#34;LOCAL&#34;</span>
</span></span><span class=line><span class=ln> 27</span><span class=cl>    <span class=k>else</span> <span class=s2>&#34;application_properties.json&#34;</span>
</span></span><span class=line><span class=ln> 28</span><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=ln> 29</span><span class=cl>
</span></span><span class=line><span class=ln> 30</span><span class=cl><span class=k>if</span> <span class=n>RUNTIME_ENV</span> <span class=o>!=</span> <span class=s2>&#34;KDA&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 31</span><span class=cl>    <span class=c1># on non-KDA, multiple jar files can be passed after being delimited by a semicolon</span>
</span></span><span class=line><span class=ln> 32</span><span class=cl>    <span class=n>CURRENT_DIR</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>realpath</span><span class=p>(</span><span class=vm>__file__</span><span class=p>))</span>
</span></span><span class=line><span class=ln> 33</span><span class=cl>    <span class=n>PIPELINE_JAR</span> <span class=o>=</span> <span class=s2>&#34;flink-sql-connector-kafka-1.15.2.jar&#34;</span>
</span></span><span class=line><span class=ln> 34</span><span class=cl>    <span class=n>table_env</span><span class=o>.</span><span class=n>get_config</span><span class=p>()</span><span class=o>.</span><span class=n>set</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 35</span><span class=cl>        <span class=s2>&#34;pipeline.jars&#34;</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;file://</span><span class=si>{</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>CURRENT_DIR</span><span class=p>,</span> <span class=s1>&#39;package&#39;</span><span class=p>,</span> <span class=s1>&#39;lib&#39;</span><span class=p>,</span> <span class=n>PIPELINE_JAR</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=ln> 36</span><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=ln> 37</span><span class=cl><span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;app properties file path - </span><span class=si>{</span><span class=n>APPLICATION_PROPERTIES_FILE_PATH</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 38</span><span class=cl>
</span></span><span class=line><span class=ln> 39</span><span class=cl>
</span></span><span class=line><span class=ln> 40</span><span class=cl><span class=k>def</span> <span class=nf>get_application_properties</span><span class=p>():</span>
</span></span><span class=line><span class=ln> 41</span><span class=cl>    <span class=k>if</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>isfile</span><span class=p>(</span><span class=n>APPLICATION_PROPERTIES_FILE_PATH</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 42</span><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>APPLICATION_PROPERTIES_FILE_PATH</span><span class=p>,</span> <span class=s2>&#34;r&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>file</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 43</span><span class=cl>            <span class=n>contents</span> <span class=o>=</span> <span class=n>file</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=ln> 44</span><span class=cl>            <span class=n>properties</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>contents</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 45</span><span class=cl>            <span class=k>return</span> <span class=n>properties</span>
</span></span><span class=line><span class=ln> 46</span><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 47</span><span class=cl>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;A file at &#39;</span><span class=si>{</span><span class=n>APPLICATION_PROPERTIES_FILE_PATH</span><span class=si>}</span><span class=s2>&#39; was not found&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 48</span><span class=cl>
</span></span><span class=line><span class=ln> 49</span><span class=cl>
</span></span><span class=line><span class=ln> 50</span><span class=cl><span class=k>def</span> <span class=nf>property_map</span><span class=p>(</span><span class=n>props</span><span class=p>:</span> <span class=nb>dict</span><span class=p>,</span> <span class=n>property_group_id</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 51</span><span class=cl>    <span class=k>for</span> <span class=n>prop</span> <span class=ow>in</span> <span class=n>props</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 52</span><span class=cl>        <span class=k>if</span> <span class=n>prop</span><span class=p>[</span><span class=s2>&#34;PropertyGroupId&#34;</span><span class=p>]</span> <span class=o>==</span> <span class=n>property_group_id</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 53</span><span class=cl>            <span class=k>return</span> <span class=n>prop</span><span class=p>[</span><span class=s2>&#34;PropertyMap&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln> 54</span><span class=cl>
</span></span><span class=line><span class=ln> 55</span><span class=cl>
</span></span><span class=line><span class=ln> 56</span><span class=cl><span class=k>def</span> <span class=nf>create_source_table</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 57</span><span class=cl>    <span class=n>table_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>topic_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>bootstrap_servers</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>startup_mode</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=ln> 58</span><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=ln> 59</span><span class=cl>    <span class=n>stmt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=ln> 60</span><span class=cl><span class=s2>    CREATE TABLE </span><span class=si>{</span><span class=n>table_name</span><span class=si>}</span><span class=s2> (
</span></span></span><span class=line><span class=ln> 61</span><span class=cl><span class=s2>        event_time TIMESTAMP(3),
</span></span></span><span class=line><span class=ln> 62</span><span class=cl><span class=s2>        ticker VARCHAR(6),
</span></span></span><span class=line><span class=ln> 63</span><span class=cl><span class=s2>        price DOUBLE
</span></span></span><span class=line><span class=ln> 64</span><span class=cl><span class=s2>    )
</span></span></span><span class=line><span class=ln> 65</span><span class=cl><span class=s2>    WITH (
</span></span></span><span class=line><span class=ln> 66</span><span class=cl><span class=s2>        &#39;connector&#39; = &#39;kafka&#39;,
</span></span></span><span class=line><span class=ln> 67</span><span class=cl><span class=s2>        &#39;topic&#39; = &#39;</span><span class=si>{</span><span class=n>topic_name</span><span class=si>}</span><span class=s2>&#39;,
</span></span></span><span class=line><span class=ln> 68</span><span class=cl><span class=s2>        &#39;properties.bootstrap.servers&#39; = &#39;</span><span class=si>{</span><span class=n>bootstrap_servers</span><span class=si>}</span><span class=s2>&#39;,
</span></span></span><span class=line><span class=ln> 69</span><span class=cl><span class=s2>        &#39;properties.group.id&#39; = &#39;source-group&#39;,
</span></span></span><span class=line><span class=ln> 70</span><span class=cl><span class=s2>        &#39;format&#39; = &#39;json&#39;,
</span></span></span><span class=line><span class=ln> 71</span><span class=cl><span class=s2>        &#39;scan.startup.mode&#39; = &#39;</span><span class=si>{</span><span class=n>startup_mode</span><span class=si>}</span><span class=s2>&#39;
</span></span></span><span class=line><span class=ln> 72</span><span class=cl><span class=s2>    )
</span></span></span><span class=line><span class=ln> 73</span><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=ln> 74</span><span class=cl>    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;source table statement...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 75</span><span class=cl>    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=n>stmt</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 76</span><span class=cl>    <span class=k>return</span> <span class=n>stmt</span>
</span></span><span class=line><span class=ln> 77</span><span class=cl>
</span></span><span class=line><span class=ln> 78</span><span class=cl>
</span></span><span class=line><span class=ln> 79</span><span class=cl><span class=k>def</span> <span class=nf>create_sink_table</span><span class=p>(</span><span class=n>table_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>topic_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>bootstrap_servers</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 80</span><span class=cl>    <span class=n>stmt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=ln> 81</span><span class=cl><span class=s2>    CREATE TABLE </span><span class=si>{</span><span class=n>table_name</span><span class=si>}</span><span class=s2> (
</span></span></span><span class=line><span class=ln> 82</span><span class=cl><span class=s2>        event_time TIMESTAMP(3),
</span></span></span><span class=line><span class=ln> 83</span><span class=cl><span class=s2>        ticker VARCHAR(6),
</span></span></span><span class=line><span class=ln> 84</span><span class=cl><span class=s2>        price DOUBLE
</span></span></span><span class=line><span class=ln> 85</span><span class=cl><span class=s2>    )
</span></span></span><span class=line><span class=ln> 86</span><span class=cl><span class=s2>    WITH (
</span></span></span><span class=line><span class=ln> 87</span><span class=cl><span class=s2>        &#39;connector&#39; = &#39;kafka&#39;,
</span></span></span><span class=line><span class=ln> 88</span><span class=cl><span class=s2>        &#39;topic&#39; = &#39;</span><span class=si>{</span><span class=n>topic_name</span><span class=si>}</span><span class=s2>&#39;,
</span></span></span><span class=line><span class=ln> 89</span><span class=cl><span class=s2>        &#39;properties.bootstrap.servers&#39; = &#39;</span><span class=si>{</span><span class=n>bootstrap_servers</span><span class=si>}</span><span class=s2>&#39;,        
</span></span></span><span class=line><span class=ln> 90</span><span class=cl><span class=s2>        &#39;format&#39; = &#39;json&#39;,
</span></span></span><span class=line><span class=ln> 91</span><span class=cl><span class=s2>        &#39;key.format&#39; = &#39;json&#39;,
</span></span></span><span class=line><span class=ln> 92</span><span class=cl><span class=s2>        &#39;key.fields&#39; = &#39;ticker&#39;,
</span></span></span><span class=line><span class=ln> 93</span><span class=cl><span class=s2>        &#39;properties.allow.auto.create.topics&#39; = &#39;true&#39;
</span></span></span><span class=line><span class=ln> 94</span><span class=cl><span class=s2>    )
</span></span></span><span class=line><span class=ln> 95</span><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=ln> 96</span><span class=cl>    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;sint table statement...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 97</span><span class=cl>    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=n>stmt</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 98</span><span class=cl>    <span class=k>return</span> <span class=n>stmt</span>
</span></span><span class=line><span class=ln> 99</span><span class=cl>
</span></span><span class=line><span class=ln>100</span><span class=cl>
</span></span><span class=line><span class=ln>101</span><span class=cl><span class=k>def</span> <span class=nf>create_print_table</span><span class=p>(</span><span class=n>table_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln>102</span><span class=cl>    <span class=k>return</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=ln>103</span><span class=cl><span class=s2>    CREATE TABLE </span><span class=si>{</span><span class=n>table_name</span><span class=si>}</span><span class=s2> (
</span></span></span><span class=line><span class=ln>104</span><span class=cl><span class=s2>        event_time TIMESTAMP(3),
</span></span></span><span class=line><span class=ln>105</span><span class=cl><span class=s2>        ticker VARCHAR(6),
</span></span></span><span class=line><span class=ln>106</span><span class=cl><span class=s2>        price DOUBLE
</span></span></span><span class=line><span class=ln>107</span><span class=cl><span class=s2>    )
</span></span></span><span class=line><span class=ln>108</span><span class=cl><span class=s2>    WITH (
</span></span></span><span class=line><span class=ln>109</span><span class=cl><span class=s2>        &#39;connector&#39; = &#39;print&#39;
</span></span></span><span class=line><span class=ln>110</span><span class=cl><span class=s2>    )
</span></span></span><span class=line><span class=ln>111</span><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=ln>112</span><span class=cl>
</span></span><span class=line><span class=ln>113</span><span class=cl>
</span></span><span class=line><span class=ln>114</span><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=ln>115</span><span class=cl>    <span class=c1>## map consumer/producer properties</span>
</span></span><span class=line><span class=ln>116</span><span class=cl>    <span class=n>props</span> <span class=o>=</span> <span class=n>get_application_properties</span><span class=p>()</span>
</span></span><span class=line><span class=ln>117</span><span class=cl>    <span class=c1># consumer</span>
</span></span><span class=line><span class=ln>118</span><span class=cl>    <span class=n>consumer_property_group_key</span> <span class=o>=</span> <span class=s2>&#34;consumer.config.0&#34;</span>
</span></span><span class=line><span class=ln>119</span><span class=cl>    <span class=n>consumer_properties</span> <span class=o>=</span> <span class=n>property_map</span><span class=p>(</span><span class=n>props</span><span class=p>,</span> <span class=n>consumer_property_group_key</span><span class=p>)</span>
</span></span><span class=line><span class=ln>120</span><span class=cl>    <span class=n>consumer_table_name</span> <span class=o>=</span> <span class=n>consumer_properties</span><span class=p>[</span><span class=s2>&#34;table.name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>121</span><span class=cl>    <span class=n>consumer_topic_name</span> <span class=o>=</span> <span class=n>consumer_properties</span><span class=p>[</span><span class=s2>&#34;topic.name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>122</span><span class=cl>    <span class=n>consumer_bootstrap_servers</span> <span class=o>=</span> <span class=n>BOOTSTRAP_SERVERS</span> <span class=ow>or</span> <span class=n>consumer_properties</span><span class=p>[</span><span class=s2>&#34;bootstrap.servers&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>123</span><span class=cl>    <span class=n>consumer_startup_mode</span> <span class=o>=</span> <span class=n>consumer_properties</span><span class=p>[</span><span class=s2>&#34;startup.mode&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>124</span><span class=cl>    <span class=c1># producer</span>
</span></span><span class=line><span class=ln>125</span><span class=cl>    <span class=n>producer_property_group_key</span> <span class=o>=</span> <span class=s2>&#34;producer.config.0&#34;</span>
</span></span><span class=line><span class=ln>126</span><span class=cl>    <span class=n>producer_properties</span> <span class=o>=</span> <span class=n>property_map</span><span class=p>(</span><span class=n>props</span><span class=p>,</span> <span class=n>producer_property_group_key</span><span class=p>)</span>
</span></span><span class=line><span class=ln>127</span><span class=cl>    <span class=n>producer_table_name</span> <span class=o>=</span> <span class=n>producer_properties</span><span class=p>[</span><span class=s2>&#34;table.name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>128</span><span class=cl>    <span class=n>producer_topic_name</span> <span class=o>=</span> <span class=n>producer_properties</span><span class=p>[</span><span class=s2>&#34;topic.name&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>129</span><span class=cl>    <span class=n>producer_bootstrap_servers</span> <span class=o>=</span> <span class=n>BOOTSTRAP_SERVERS</span> <span class=ow>or</span> <span class=n>producer_properties</span><span class=p>[</span><span class=s2>&#34;bootstrap.servers&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=ln>130</span><span class=cl>    <span class=c1># print</span>
</span></span><span class=line><span class=ln>131</span><span class=cl>    <span class=n>print_table_name</span> <span class=o>=</span> <span class=s2>&#34;sink_print&#34;</span>
</span></span><span class=line><span class=ln>132</span><span class=cl>    <span class=c1>## create a souce table</span>
</span></span><span class=line><span class=ln>133</span><span class=cl>    <span class=n>table_env</span><span class=o>.</span><span class=n>execute_sql</span><span class=p>(</span>
</span></span><span class=line><span class=ln>134</span><span class=cl>        <span class=n>create_source_table</span><span class=p>(</span>
</span></span><span class=line><span class=ln>135</span><span class=cl>            <span class=n>consumer_table_name</span><span class=p>,</span>
</span></span><span class=line><span class=ln>136</span><span class=cl>            <span class=n>consumer_topic_name</span><span class=p>,</span>
</span></span><span class=line><span class=ln>137</span><span class=cl>            <span class=n>consumer_bootstrap_servers</span><span class=p>,</span>
</span></span><span class=line><span class=ln>138</span><span class=cl>            <span class=n>consumer_startup_mode</span><span class=p>,</span>
</span></span><span class=line><span class=ln>139</span><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=ln>140</span><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=ln>141</span><span class=cl>    <span class=c1>## create sink tables</span>
</span></span><span class=line><span class=ln>142</span><span class=cl>    <span class=n>table_env</span><span class=o>.</span><span class=n>execute_sql</span><span class=p>(</span>
</span></span><span class=line><span class=ln>143</span><span class=cl>        <span class=n>create_sink_table</span><span class=p>(</span><span class=n>producer_table_name</span><span class=p>,</span> <span class=n>producer_topic_name</span><span class=p>,</span> <span class=n>producer_bootstrap_servers</span><span class=p>)</span>
</span></span><span class=line><span class=ln>144</span><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=ln>145</span><span class=cl>    <span class=n>table_env</span><span class=o>.</span><span class=n>execute_sql</span><span class=p>(</span><span class=n>create_print_table</span><span class=p>(</span><span class=s2>&#34;sink_print&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=ln>146</span><span class=cl>    <span class=c1>## insert into sink tables</span>
</span></span><span class=line><span class=ln>147</span><span class=cl>    <span class=k>if</span> <span class=n>RUNTIME_ENV</span> <span class=o>==</span> <span class=s2>&#34;LOCAL&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=ln>148</span><span class=cl>        <span class=n>source_table</span> <span class=o>=</span> <span class=n>table_env</span><span class=o>.</span><span class=n>from_path</span><span class=p>(</span><span class=n>consumer_table_name</span><span class=p>)</span>
</span></span><span class=line><span class=ln>149</span><span class=cl>        <span class=n>statement_set</span> <span class=o>=</span> <span class=n>table_env</span><span class=o>.</span><span class=n>create_statement_set</span><span class=p>()</span>
</span></span><span class=line><span class=ln>150</span><span class=cl>        <span class=n>statement_set</span><span class=o>.</span><span class=n>add_insert</span><span class=p>(</span><span class=n>producer_table_name</span><span class=p>,</span> <span class=n>source_table</span><span class=p>)</span>
</span></span><span class=line><span class=ln>151</span><span class=cl>        <span class=n>statement_set</span><span class=o>.</span><span class=n>add_insert</span><span class=p>(</span><span class=n>print_table_name</span><span class=p>,</span> <span class=n>source_table</span><span class=p>)</span>
</span></span><span class=line><span class=ln>152</span><span class=cl>        <span class=n>statement_set</span><span class=o>.</span><span class=n>execute</span><span class=p>()</span><span class=o>.</span><span class=n>wait</span><span class=p>()</span>
</span></span><span class=line><span class=ln>153</span><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=ln>154</span><span class=cl>        <span class=n>table_result</span> <span class=o>=</span> <span class=n>table_env</span><span class=o>.</span><span class=n>execute_sql</span><span class=p>(</span>
</span></span><span class=line><span class=ln>155</span><span class=cl>            <span class=sa>f</span><span class=s2>&#34;INSERT INTO </span><span class=si>{</span><span class=n>producer_table_name</span><span class=si>}</span><span class=s2> SELECT * FROM </span><span class=si>{</span><span class=n>consumer_table_name</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=ln>156</span><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=ln>157</span><span class=cl>        <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=n>table_result</span><span class=o>.</span><span class=n>get_job_client</span><span class=p>()</span><span class=o>.</span><span class=n>get_job_status</span><span class=p>())</span>
</span></span><span class=line><span class=ln>158</span><span class=cl>
</span></span><span class=line><span class=ln>159</span><span class=cl>
</span></span><span class=line><span class=ln>160</span><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=ln>161</span><span class=cl>    <span class=n>main</span><span class=p>()</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=ln> 1</span><span class=cl><span class=c1>// application_properties.json
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1></span><span class=p>[</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl>    <span class=nt>&#34;PropertyGroupId&#34;</span><span class=p>:</span> <span class=s2>&#34;kinesis.analytics.flink.run.options&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>    <span class=nt>&#34;PropertyMap&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl>      <span class=nt>&#34;python&#34;</span><span class=p>:</span> <span class=s2>&#34;processor.py&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>      <span class=nt>&#34;jarfile&#34;</span><span class=p>:</span> <span class=s2>&#34;package/lib/flink-sql-connector-kinesis-1.15.2.jar&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>      <span class=nt>&#34;pyFiles&#34;</span><span class=p>:</span> <span class=s2>&#34;package/site_packages/&#34;</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=ln>12</span><span class=cl>    <span class=nt>&#34;PropertyGroupId&#34;</span><span class=p>:</span> <span class=s2>&#34;consumer.config.0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>    <span class=nt>&#34;PropertyMap&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=ln>14</span><span class=cl>      <span class=nt>&#34;table.name&#34;</span><span class=p>:</span> <span class=s2>&#34;source_table&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>      <span class=nt>&#34;topic.name&#34;</span><span class=p>:</span> <span class=s2>&#34;stocks-in&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>      <span class=nt>&#34;bootstrap.servers&#34;</span><span class=p>:</span> <span class=s2>&#34;localhost:29092&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>17</span><span class=cl>      <span class=nt>&#34;startup.mode&#34;</span><span class=p>:</span> <span class=s2>&#34;earliest-offset&#34;</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=ln>19</span><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=ln>20</span><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=ln>21</span><span class=cl>    <span class=nt>&#34;PropertyGroupId&#34;</span><span class=p>:</span> <span class=s2>&#34;producer.config.0&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>22</span><span class=cl>    <span class=nt>&#34;PropertyMap&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=ln>23</span><span class=cl>      <span class=nt>&#34;table.name&#34;</span><span class=p>:</span> <span class=s2>&#34;sink_table&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>24</span><span class=cl>      <span class=nt>&#34;topic.name&#34;</span><span class=p>:</span> <span class=s2>&#34;stocks-out&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>25</span><span class=cl>      <span class=nt>&#34;bootstrap.servers&#34;</span><span class=p>:</span> <span class=s2>&#34;localhost:29092&#34;</span>
</span></span><span class=line><span class=ln>26</span><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=ln>27</span><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=ln>28</span><span class=cl><span class=p>]</span>
</span></span></code></pre></div><h4 id=run-locally data-numberify>Run Locally<a class="anchor ms-1" href=#run-locally></a></h4><p>We can run the app locally as following - <code>RUNTIME_ENV=LOCAL python processor.py</code>. The terminal on the right-hand side shows the output records of the Flink app while the left-hand side records logs of the producer app. We can see that the print output from the Flink app gets updated when new source records are sent into the source topic by the producer app.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/terminal-result.png loading=lazy width=1417 height=508></picture></p><p>We can also see details of all the topics in <em>Kpow</em> as shown below. The total number of messages matches between the source and output topics but not within partitions.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/all-topics.png loading=lazy width=1167 height=914></picture></p><h4 id=run-in-flink-cluster data-numberify>Run in Flink Cluster<a class="anchor ms-1" href=#run-in-flink-cluster></a></h4><p>The execution in a terminal is limited for monitoring, and we can inspect and understand what is happening inside Flink using the Flink Web UI. For this, we need to submit the app to the Flink cluster we created earlier. Typically, a Pyflink app can be submitted using the <a href=https://nightlies.apache.org/flink/flink-docs-release-1.15/docs/deployment/cli/ target=_blank rel="noopener noreferrer">CLI interface<i class="fas fa-external-link-square-alt ms-1"></i></a> by specifying the main application (<em>&ndash;python</em>), Kafka connector artifact file (<em>&ndash;jarfile</em>), and 3rd-party Python packages (<em>&ndash;pyFiles</em>) if necessary. Once submitted, it shows the status with the job ID.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl>$ docker <span class=nb>exec</span> jobmanager /opt/flink/bin/flink run <span class=se>\
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=se></span>  --python /etc/flink/processor.py <span class=se>\
</span></span></span><span class=line><span class=ln> 3</span><span class=cl><span class=se></span>  --jarfile /etc/flink/package/lib/flink-sql-connector-kafka-1.15.2.jar <span class=se>\
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=se></span>  --pyFiles /etc/flink/package/site_packages/ <span class=se>\
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=se></span>  -d
</span></span><span class=line><span class=ln> 6</span><span class=cl>2023-08-08 02:07:13.220:INFO:root:runtime environment - DOCKER...
</span></span><span class=line><span class=ln> 7</span><span class=cl>2023-08-08 02:07:14.341:INFO:root:app properties file path - /etc/flink/application_properties.json
</span></span><span class=line><span class=ln> 8</span><span class=cl>2023-08-08 02:07:14.341:INFO:root:source table statement...
</span></span><span class=line><span class=ln> 9</span><span class=cl>2023-08-08 02:07:14.341:INFO:root:
</span></span><span class=line><span class=ln>10</span><span class=cl>    CREATE TABLE source_table <span class=o>(</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>        event_time TIMESTAMP<span class=o>(</span>3<span class=o>)</span>,
</span></span><span class=line><span class=ln>12</span><span class=cl>        ticker VARCHAR<span class=o>(</span>6<span class=o>)</span>,
</span></span><span class=line><span class=ln>13</span><span class=cl>        price DOUBLE
</span></span><span class=line><span class=ln>14</span><span class=cl>    <span class=o>)</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>    WITH <span class=o>(</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>        <span class=s1>&#39;connector&#39;</span> <span class=o>=</span> <span class=s1>&#39;kafka&#39;</span>,
</span></span><span class=line><span class=ln>17</span><span class=cl>        <span class=s1>&#39;topic&#39;</span> <span class=o>=</span> <span class=s1>&#39;stocks-in&#39;</span>,
</span></span><span class=line><span class=ln>18</span><span class=cl>        <span class=s1>&#39;properties.bootstrap.servers&#39;</span> <span class=o>=</span> <span class=s1>&#39;kafka-0:9092&#39;</span>,
</span></span><span class=line><span class=ln>19</span><span class=cl>        <span class=s1>&#39;properties.group.id&#39;</span> <span class=o>=</span> <span class=s1>&#39;source-group&#39;</span>,
</span></span><span class=line><span class=ln>20</span><span class=cl>        <span class=s1>&#39;format&#39;</span> <span class=o>=</span> <span class=s1>&#39;json&#39;</span>,
</span></span><span class=line><span class=ln>21</span><span class=cl>        <span class=s1>&#39;scan.startup.mode&#39;</span> <span class=o>=</span> <span class=s1>&#39;earliest-offset&#39;</span>
</span></span><span class=line><span class=ln>22</span><span class=cl>    <span class=o>)</span>
</span></span><span class=line><span class=ln>23</span><span class=cl>    
</span></span><span class=line><span class=ln>24</span><span class=cl>2023-08-08 02:07:14.439:INFO:root:sint table statement...
</span></span><span class=line><span class=ln>25</span><span class=cl>2023-08-08 02:07:14.439:INFO:root:
</span></span><span class=line><span class=ln>26</span><span class=cl>    CREATE TABLE sink_table <span class=o>(</span>
</span></span><span class=line><span class=ln>27</span><span class=cl>        event_time TIMESTAMP<span class=o>(</span>3<span class=o>)</span>,
</span></span><span class=line><span class=ln>28</span><span class=cl>        ticker VARCHAR<span class=o>(</span>6<span class=o>)</span>,
</span></span><span class=line><span class=ln>29</span><span class=cl>        price DOUBLE
</span></span><span class=line><span class=ln>30</span><span class=cl>    <span class=o>)</span>
</span></span><span class=line><span class=ln>31</span><span class=cl>    WITH <span class=o>(</span>
</span></span><span class=line><span class=ln>32</span><span class=cl>        <span class=s1>&#39;connector&#39;</span> <span class=o>=</span> <span class=s1>&#39;kafka&#39;</span>,
</span></span><span class=line><span class=ln>33</span><span class=cl>        <span class=s1>&#39;topic&#39;</span> <span class=o>=</span> <span class=s1>&#39;stocks-out&#39;</span>,
</span></span><span class=line><span class=ln>34</span><span class=cl>        <span class=s1>&#39;properties.bootstrap.servers&#39;</span> <span class=o>=</span> <span class=s1>&#39;kafka-0:9092&#39;</span>,        
</span></span><span class=line><span class=ln>35</span><span class=cl>        <span class=s1>&#39;format&#39;</span> <span class=o>=</span> <span class=s1>&#39;json&#39;</span>,
</span></span><span class=line><span class=ln>36</span><span class=cl>        <span class=s1>&#39;key.format&#39;</span> <span class=o>=</span> <span class=s1>&#39;json&#39;</span>,
</span></span><span class=line><span class=ln>37</span><span class=cl>        <span class=s1>&#39;key.fields&#39;</span> <span class=o>=</span> <span class=s1>&#39;ticker&#39;</span>,
</span></span><span class=line><span class=ln>38</span><span class=cl>        <span class=s1>&#39;properties.allow.auto.create.topics&#39;</span> <span class=o>=</span> <span class=s1>&#39;true&#39;</span>
</span></span><span class=line><span class=ln>39</span><span class=cl>    <span class=o>)</span>
</span></span><span class=line><span class=ln>40</span><span class=cl>    
</span></span><span class=line><span class=ln>41</span><span class=cl>WARNING: An illegal reflective access operation has occurred
</span></span><span class=line><span class=ln>42</span><span class=cl>WARNING: Illegal reflective access by org.apache.flink.api.java.ClosureCleaner <span class=o>(</span>file:/opt/flink/lib/flink-dist-1.15.4.jar<span class=o>)</span> to field java.lang.String.value
</span></span><span class=line><span class=ln>43</span><span class=cl>WARNING: Please consider reporting this to the maintainers of org.apache.flink.api.java.ClosureCleaner
</span></span><span class=line><span class=ln>44</span><span class=cl>WARNING: Use --illegal-access<span class=o>=</span>warn to <span class=nb>enable</span> warnings of further illegal reflective access operations
</span></span><span class=line><span class=ln>45</span><span class=cl>WARNING: All illegal access operations will be denied in a future release
</span></span><span class=line><span class=ln>46</span><span class=cl>Job has been submitted with JobID 02d83c46d646aa498a986c0a9335e276
</span></span><span class=line><span class=ln>47</span><span class=cl>2023-08-08 02:07:23.010:INFO:root:java.util.concurrent.CompletableFuture@34e729a3<span class=o>[</span>Not completed<span class=o>]</span>
</span></span></code></pre></div><p>We can check the submitted job by listing all jobs as shown below.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ docker <span class=nb>exec</span> jobmanager /opt/flink/bin/flink list
</span></span><span class=line><span class=ln>2</span><span class=cl>Waiting <span class=k>for</span> response...
</span></span><span class=line><span class=ln>3</span><span class=cl>------------------ Running/Restarting Jobs -------------------
</span></span><span class=line><span class=ln>4</span><span class=cl>08.08.2023 02:07:18 : 02d83c46d646aa498a986c0a9335e276 : insert-into_default_catalog.default_database.sink_table <span class=o>(</span>RUNNING<span class=o>)</span>
</span></span><span class=line><span class=ln>5</span><span class=cl>--------------------------------------------------------------
</span></span><span class=line><span class=ln>6</span><span class=cl>No scheduled jobs.
</span></span></code></pre></div><p>The Flink Web UI can be accessed on port 8081. In the Overview section, it shows the available task slots, running jobs and completed jobs.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/cluster-dashboard-01.png loading=lazy width=1359 height=842></picture></p><p>We can inspect an individual job in the Jobs menu. It shows key details about a job execution in <em>Overview</em>, <em>Exceptions</em>, <em>TimeLine</em>, <em>Checkpoints</em> and <em>Configuration</em> tabs.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/cluster-dashboard-02.png loading=lazy width=1360 height=888></picture></p><p>We can cancel a job on the web UI or using the CLI. Below shows how to cancel the job we submitted earlier using the CLI.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ docker <span class=nb>exec</span> jobmanager /opt/flink/bin/flink cancel 02d83c46d646aa498a986c0a9335e276
</span></span><span class=line><span class=ln>2</span><span class=cl>Cancelling job 02d83c46d646aa498a986c0a9335e276.
</span></span><span class=line><span class=ln>3</span><span class=cl>Cancelled job 02d83c46d646aa498a986c0a9335e276.
</span></span></code></pre></div><h2 id=summary data-numberify>Summary<a class="anchor ms-1" href=#summary></a></h2><p>Apache Flink is widely used for building real-time stream processing applications. On AWS, Kinesis Data Analytics (KDA) is the easiest option to develop a Flink app as it provides the underlying infrastructure. Updating a guide from AWS, this series of posts discuss how to develop and deploy a Flink (Pyflink) application via KDA where the data source and sink are Kafka topics. In part 1, the app was developed locally targeting a Kafka cluster created by Docker. Furthermore, it was executed in a virtual environment as well as in a local Flink cluster for improved monitoring.</p></div></div></div><div class=card-footer><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-down post-prev-icon me-1" data-fa-transform=rotate-90></i>
<a href=/blog/2023-08-10-fraud-detection-part-1/>Kafka, Flink and DynamoDB for Real Time Fraud Detection - Part 1 Local Development</a></div><div class="post-nav post-next"><a href=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2/>Getting Started With Pyflink on AWS - Part 2 Local Flink and MSK</a>
<i class="fas fa-fw fa-chevron-down post-next-icon ms-1" data-fa-transform=rotate-270></i></div></div></div></article><section class="related-posts row card component"><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Related Posts</h2></div><div class="card-body slide px-1"><div class="slide-inner row gx-0"><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-08-10-fraud-detection-part-1/featured_hu0e6881a0b5c39bbfe5c0b72138bca889_72929_500x0_resize_box_3.png media="(max-width: 576px)" height=213 width=500><img class=img-fluid height=77 width=180 alt=featured.png src=/blog/2023-08-10-fraud-detection-part-1/featured_hu0e6881a0b5c39bbfe5c0b72138bca889_72929_180x0_resize_box_3.png data-src=/blog/2023-08-10-fraud-detection-part-1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-08-10-fraud-detection-part-1/>Kafka, Flink and DynamoDB for Real Time Fraud Detection - Part 1 Local Development</a><div class="post-meta mb-0">August 10, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_500x0_resize_box_3.png media="(max-width: 576px)" height=305 width=500><img class=img-fluid height=110 width=180 alt=featured.png src=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_180x0_resize_box_3.png data-src=/blog/2023-04-12-integrate-glue-schema-registry/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-04-12-integrate-glue-schema-registry/>Integrate Glue Schema Registry With Your Python Kafka App</a><div class="post-meta mb-0">April 12, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-07-20-kafka-development-with-docker-part-11/featured_hu02926410fee69d2a9d233fecc3582cc8_458848_500x0_resize_box_3.png media="(max-width: 576px)" height=500 width=500><img class=img-fluid height=180 width=180 alt=featured.png src=/blog/2023-07-20-kafka-development-with-docker-part-11/featured_hu02926410fee69d2a9d233fecc3582cc8_458848_180x0_resize_box_3.png data-src=/blog/2023-07-20-kafka-development-with-docker-part-11/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-07-20-kafka-development-with-docker-part-11/>Kafka Development With Docker - Part 11 Kafka Authorization</a><div class="post-meta mb-0">July 20, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-07-13-kafka-development-with-docker-part-10/featured_hu35df27459c2871526cb88101a926a14d_471947_500x0_resize_box_3.png media="(max-width: 576px)" height=500 width=500><img class=img-fluid height=180 width=180 alt=featured.png src=/blog/2023-07-13-kafka-development-with-docker-part-10/featured_hu35df27459c2871526cb88101a926a14d_471947_180x0_resize_box_3.png data-src=/blog/2023-07-13-kafka-development-with-docker-part-10/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-07-13-kafka-development-with-docker-part-10/>Kafka Development With Docker - Part 10 SASL Authentication</a><div class="post-meta mb-0">July 13, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-07-06-kafka-development-with-docker-part-9/featured_hu46b705891e566c5f4e1fa5fb958154c6_471471_500x0_resize_box_3.png media="(max-width: 576px)" height=500 width=500><img class=img-fluid height=180 width=180 alt=featured.png src=/blog/2023-07-06-kafka-development-with-docker-part-9/featured_hu46b705891e566c5f4e1fa5fb958154c6_471471_180x0_resize_box_3.png data-src=/blog/2023-07-06-kafka-development-with-docker-part-9/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-07-06-kafka-development-with-docker-part-9/>Kafka Development With Docker - Part 9 SSL Authentication</a><div class="post-meta mb-0">July 6, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-06-29-kafka-development-with-docker-part-8/featured_hu5ba48e27b04577c6841598e1e7862406_469311_500x0_resize_box_3.png media="(max-width: 576px)" height=500 width=500><img class=img-fluid height=180 width=180 alt=featured.png src=/blog/2023-06-29-kafka-development-with-docker-part-8/featured_hu5ba48e27b04577c6841598e1e7862406_469311_180x0_resize_box_3.png data-src=/blog/2023-06-29-kafka-development-with-docker-part-8/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-06-29-kafka-development-with-docker-part-8/>Kafka Development With Docker - Part 8 SSL Encryption</a><div class="post-meta mb-0">June 29, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-06-22-kafka-development-with-docker-part-7/featured_hu13c1b1b7b1d0fd49e8378a753b0e3b10_57175_500x0_resize_box_3.png media="(max-width: 576px)" height=215 width=500><img class=img-fluid height=78 width=180 alt=featured.png src=/blog/2023-06-22-kafka-development-with-docker-part-7/featured_hu13c1b1b7b1d0fd49e8378a753b0e3b10_57175_180x0_resize_box_3.png data-src=/blog/2023-06-22-kafka-development-with-docker-part-7/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-06-22-kafka-development-with-docker-part-7/>Kafka Development With Docker - Part 7 Producer and Consumer With Glue Schema Registry</a><div class="post-meta mb-0">June 22, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-06-01-kafka-development-with-docker-part-4/featured_hu577191e1103a5dba84b139cbfa921627_75255_500x0_resize_box_3.png media="(max-width: 576px)" height=301 width=500><img class=img-fluid height=108 width=180 alt=featured.png src=/blog/2023-06-01-kafka-development-with-docker-part-4/featured_hu577191e1103a5dba84b139cbfa921627_75255_180x0_resize_box_3.png data-src=/blog/2023-06-01-kafka-development-with-docker-part-4/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-06-01-kafka-development-with-docker-part-4/>Kafka Development With Docker - Part 4 Producer and Consumer</a><div class="post-meta mb-0">June 1, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-01-10-kafka-consumer-seek-offsets/featured_hua222fe3eeaae92dfa98b24cdf7061694_47217_500x0_resize_box_3.png media="(max-width: 576px)" height=368 width=500><img class=img-fluid height=132 width=180 alt=featured.png src=/blog/2023-01-10-kafka-consumer-seek-offsets/featured_hua222fe3eeaae92dfa98b24cdf7061694_47217_180x0_resize_box_3.png data-src=/blog/2023-01-10-kafka-consumer-seek-offsets/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-01-10-kafka-consumer-seek-offsets/>How to Configure Kafka Consumers to Seek Offsets by Timestamp</a><div class="post-meta mb-0">January 10, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2022-04-03-schema-registry-part2/featured_hu55ef0aeef397b55768e961367d004bbc_59689_500x0_resize_box_3.png media="(max-width: 576px)" height=252 width=500><img class=img-fluid height=91 width=180 alt=featured.png src=/blog/2022-04-03-schema-registry-part2/featured_hu55ef0aeef397b55768e961367d004bbc_59689_180x0_resize_box_3.png data-src=/blog/2022-04-03-schema-registry-part2/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2022-04-03-schema-registry-part2/>Use External Schema Registry With MSK Connect – Part 2 MSK Deployment</a><div class="post-meta mb-0">April 3, 2022</div></div></div></div><button class=slide-control-left>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i>
<span class=visually-hidden>Left</span>
</button>
<button class=slide-control-right>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-270></i>
<span class=visually-hidden>Right</span></button></div></section><div class="card component row post-comments" id=post-comments><div class=card-header><h2 class="card-title my-2 fs-4 text-surface">Comments</h2></div><div class=card-body><div class=giscus></div></div></div></div></div><aside class="col-xxl-4 sidebar d-flex"><div class="container d-flex flex-column"><div class="accordion profile"><div class="accordion-item card row text-center component"><div class="accordion-header card-header border-0" id=profile-header><a class="accordion-button d-lg-none mb-2 shadow-none p-0 bg-transparent text-surface" role=button data-bs-toggle=collapse href=#profile aria-expanded=true aria-controls=profile>Profile</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=profile aria-labelledby=profile-header><div class="col-12 d-flex align-items-center justify-content-center"><picture><img class="profile-avatar rounded-circle" alt="Jaehyeon Kim" src="https://jaehyeon.me/images/profile.png?v=44ac505745a2253002ad04fbe748fad8" loading=lazy data-viewer-invisible width=200 height=200></picture></div><div class="col-12 profile-meta"><div class="profile-name fw-fold fs-lg">Jaehyeon Kim</div><div class=profile-bio>⚙️ Data Engineer 📝 Blogger 👯 OSS Maintainer</div></div><nav class="social-links nav justify-content-center mt-1 justify-content-around"><a class="nav-link social-link" href=mailto:dottami@gmail.com title=Email><i class="fas fa-fw fa-2x fa-envelope" style=color:#0963ac></i>
</a><a class="nav-link social-link" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fa-2x fab fa-github"></i>
</a><a class="nav-link social-link" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fa-2x fab fa-linkedin-in" style=color:#0a66c2></i>
</a><a class="nav-link social-link" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fa-2x fab fa-paypal"></i></a></nav></div></div></div><div class="accordion taxonomies-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#taxonomies-toggle aria-expanded=true aria-controls=taxonomies-toggle>Taxonomies</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=taxonomies-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=taxonomyCategoriesTab data-bs-toggle=tab data-bs-target=#taxonomyCategories type=button role=tab aria-controls=taxonomyCategories aria-selected=true>
Categories</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyTagsTab data-bs-toggle=tab data-bs-target=#taxonomyTags type=button role=tab aria-controls=taxonomyTags aria-selected=true>
Tags</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomySeriesTab data-bs-toggle=tab data-bs-target=#taxonomySeries type=button role=tab aria-controls=taxonomySeries aria-selected=true>
Series</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyArchivesTab data-bs-toggle=tab data-bs-target=#taxonomyArchives type=button role=tab aria-controls=taxonomyArchives aria-selected=true>
Archives</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=taxonomyCategories role=tabpanel aria-labelledby=taxonomyCategoriesTab tabindex=0><a href=/categories/data-streaming/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Streaming">Data Streaming
<span class="badge badge-sm text-secondary bg-white ms-1">28</span>
</a><a href=/categories/data-engineering/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Engineering">Data Engineering
<span class="badge badge-sm text-secondary bg-white ms-1">26</span>
</a><a href=/categories/development/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Development>Development
<span class="badge badge-sm text-secondary bg-white ms-1">19</span>
</a><a href=/categories/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/categories/apache-beam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Beam">Apache Beam
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/categories/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/categories/machine-learning/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Machine Learning">Machine Learning
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/categories/general/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=General>General
<span class="badge badge-sm text-secondary bg-white ms-1">5</span></a></div><div class=tab-pane id=taxonomyTags role=tabpanel aria-labelledby=taxonomyTagsTab tabindex=0><a href=/tags/docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Docker>Docker
<span class="badge badge-sm text-secondary bg-white ms-1">62</span>
</a><a href=/tags/python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Python>Python
<span class="badge badge-sm text-secondary bg-white ms-1">61</span>
</a><a href=/tags/docker-compose/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Docker Compose">Docker Compose
<span class="badge badge-sm text-secondary bg-white ms-1">52</span>
</a><a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">46</span>
</a><a href=/tags/aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=AWS>AWS
<span class="badge badge-sm text-secondary bg-white ms-1">43</span>
</a><a href=/tags/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">36</span>
</a><a href=/tags/apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Flink">Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">27</span>
</a><a href=/tags/amazon-msk/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK">Amazon MSK
<span class="badge badge-sm text-secondary bg-white ms-1">21</span>
</a><a href=/tags/apache-spark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Spark">Apache Spark
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/tags/kafka-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Kafka Connect">Kafka Connect
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/tags/apache-beam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Beam">Apache Beam
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/tags/aws-lambda/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Lambda">AWS Lambda
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/tags/terraform/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Terraform>Terraform
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/tags/data-build-tool-dbt/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Data Build Tool (DBT)">Data Build Tool (DBT)
<span class="badge badge-sm text-secondary bg-white ms-1">13</span>
</a><a href=/tags/amazon-emr/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EMR">Amazon EMR
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/pyflink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PyFlink>PyFlink
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Kubernetes>Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">10</span>
</a><a href=/tags/amazon-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK Connect">Amazon MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">9</span>
</a><a href=/tags/amazon-athena/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Athena">Amazon Athena
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/minikube/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Minikube>Minikube
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/pyspark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PySpark>PySpark
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/amazon-dynamodb/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon DynamoDB">Amazon DynamoDB
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/apache-airflow/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Airflow">Apache Airflow
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/grpc/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=GRPC>GRPC
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/rserve/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Rserve>Rserve
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/visual-studio-code/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Visual Studio Code">Visual Studio Code
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/amazon-api-gateway/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon API Gateway">Amazon API Gateway
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-managed-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Managed Flink">Amazon Managed Flink
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-managed-service-for-apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Managed Service for Apache Flink">Amazon Managed Service for Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-quicksight/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon QuickSight">Amazon QuickSight
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/aws-glue/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Glue">AWS Glue
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/bigquery/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=BigQuery>BigQuery
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/gcp/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=GCP>GCP
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/opensearch/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=OpenSearch>OpenSearch
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/security/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Security>Security
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/shiny/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Shiny>Shiny
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-eks/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EKS">Amazon EKS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/amazon-opensearch-service/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon OpenSearch Service">Amazon OpenSearch Service
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/amazon-s3/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon S3">Amazon S3
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/apache-camel/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Camel">Apache Camel
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=https://jaehyeon.me/tags class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=ALL>ALL
<span class="badge badge-sm text-secondary bg-white ms-1">104</span></a></div><div class=tab-pane id=taxonomySeries role=tabpanel aria-labelledby=taxonomySeriesTab tabindex=0><a href=/series/kafka-development-with-docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development With Docker">Kafka Development With Docker
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/series/apache-beam-python-examples/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Apache Beam Python Examples">Apache Beam Python Examples
<span class="badge badge-sm text-secondary bg-white ms-1">8</span>
</a><a href=/series/real-time-streaming-with-kafka-and-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Real Time Streaming With Kafka and Flink">Real Time Streaming With Kafka and Flink
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/series/dbt-pizza-shop-demo/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT Pizza Shop Demo">DBT Pizza Shop Demo
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/series/tree-based-methods-in-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Tree Based Methods in R">Tree Based Methods in R
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/series/apache-beam-local-development-with-python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Apache Beam Local Development With Python">Apache Beam Local Development With Python
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/dbt-for-effective-data-transformation-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT for Effective Data Transformation on AWS">DBT for Effective Data Transformation on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/kafka-connect-for-aws-services-integration/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Connect for AWS Services Integration">Kafka Connect for AWS Services Integration
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/serverless-data-product/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Serverless Data Product">Serverless Data Product
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/series/data-lake-demo-using-change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Data Lake Demo Using Change Data Capture">Data Lake Demo Using Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/getting-started-with-pyflink-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Getting Started With Pyflink on AWS">Getting Started With Pyflink on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/kafka-development-on-kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development on Kubernetes">Kafka Development on Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/parallel-processing-on-single-machine/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Parallel Processing on Single Machine">Parallel Processing on Single Machine
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/api-development-with-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="API Development With R">API Development With R
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/dbt-guide-for-production/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT Guide for Production">DBT Guide for Production
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/deploy-python-stream-processing-app-on-kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Deploy Python Stream Processing App on Kubernetes">Deploy Python Stream Processing App on Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/integrate-schema-registry-with-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Integrate Schema Registry With MSK Connect">Integrate Schema Registry With MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/kafka-flink-and-dynamodb-for-real-time-fraud-detection/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka, Flink and DynamoDB for Real Time Fraud Detection">Kafka, Flink and DynamoDB for Real Time Fraud Detection
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/simplify-streaming-ingestion-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Simplify Streaming Ingestion on AWS">Simplify Streaming Ingestion on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a></div><div class=tab-pane id=taxonomyArchives role=tabpanel aria-labelledby=taxonomyArchivesTab tabindex=0><a href=/archives/2024/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2024>2024 <span class="badge badge-sm text-secondary bg-white ms-1">27</span>
</a><a href=/archives/2023/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2023>2023 <span class="badge badge-sm text-secondary bg-white ms-1">39</span>
</a><a href=/archives/2022/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2022>2022 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2021/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2021>2021 <span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/archives/2020/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2020>2020 <span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/archives/2019/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2019>2019 <span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/archives/2018/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2018>2018 <span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/archives/2017/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2017>2017 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2016/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2016>2016 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2015/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2015>2015 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2014/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2014>2014 <span class="badge badge-sm text-secondary bg-white ms-1">5</span></a></div></div></div></div></div><div class="accordion posts-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#posts-toggle aria-expanded=true aria-controls=posts-toggle>Posts</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=posts-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=featured-posts-tab data-bs-toggle=tab data-bs-target=#featured-posts type=button role=tab aria-controls=featured-posts aria-selected=true>
Featured Posts</button></li><li class=nav-item role=presentation><button class=nav-link id=recent-posts-tab data-bs-toggle=tab data-bs-target=#recent-posts type=button role=tab aria-controls=recent-posts aria-selected=true>
Recent Posts</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=featured-posts role=tabpanel aria-labelledby=featured-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-11-07-cdc-local-dev/featured_hu1be5b7cd9299c136c309544dd6dd598d_83605_500x0_resize_box_3.png media="(max-width: 576px)" height=369 width=500><img class=img-fluid height=133 width=180 alt=featured.png src=/blog/2024-11-07-cdc-local-dev/featured_hu1be5b7cd9299c136c309544dd6dd598d_83605_180x0_resize_box_3.png data-src=/blog/2024-11-07-cdc-local-dev/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-11-07-cdc-local-dev/>Change Data Capture (CDC) Local Development With PostgreSQL, Debezium Server and Pub/Sub Emulator</a><div class="post-meta mt-2"><span class=post-date>November 7, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-09-13-dbt-guide/featured_hu02c411e2b810e83058a2abf514c3ab2e_71185_500x0_resize_box_3.png media="(max-width: 576px)" height=253 width=500><img class=img-fluid height=91 width=180 alt=featured.png src=/blog/2024-09-13-dbt-guide/featured_hu02c411e2b810e83058a2abf514c3ab2e_71185_180x0_resize_box_3.png data-src=/blog/2024-09-13-dbt-guide/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-09-13-dbt-guide/>Guide to Running DBT in Production</a><div class="post-meta mt-2"><span class=post-date>September 13, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-09-05-dbt-cicd-demo/featured_huad11874eeea265d1d4cc984ffd50128c_60835_500x0_resize_box_3.png media="(max-width: 576px)" height=367 width=500><img class=img-fluid height=132 width=180 alt=featured.png src=/blog/2024-09-05-dbt-cicd-demo/featured_huad11874eeea265d1d4cc984ffd50128c_60835_180x0_resize_box_3.png data-src=/blog/2024-09-05-dbt-cicd-demo/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-09-05-dbt-cicd-demo/>DBT CI/CD Demo With BigQuery and GitHub Actions</a><div class="post-meta mt-2"><span class=post-date>September 5, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-08-22-cache-using-shared-object/featured_hu9078f8221b3da3b9c4a7fded6a2842e2_49574_500x0_resize_box_3.png media="(max-width: 576px)" height=211 width=500><img class=img-fluid height=76 width=180 alt=featured.png src=/blog/2024-08-22-cache-using-shared-object/featured_hu9078f8221b3da3b9c4a7fded6a2842e2_49574_180x0_resize_box_3.png data-src=/blog/2024-08-22-cache-using-shared-object/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-08-22-cache-using-shared-object/>Cache Data on Apache Beam Pipelines Using a Shared Object</a><div class="post-meta mt-2"><span class=post-date>August 22, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-07-04-beam-examples-1/featured_hud3ce9831fcc98de0424cfc6e53706491_96881_500x0_resize_box_3.png media="(max-width: 576px)" height=318 width=500><img class=img-fluid height=115 width=180 alt=featured.png src=/blog/2024-07-04-beam-examples-1/featured_hud3ce9831fcc98de0424cfc6e53706491_96881_180x0_resize_box_3.png data-src=/blog/2024-07-04-beam-examples-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-07-04-beam-examples-1/>Apache Beam Python Examples - Part 1 Calculate K Most Frequent Words and Max Word Length</a><div class="post-meta mt-2"><span class=post-date>July 4, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-05-30-beam-deploy-1/featured_hu716373a174df6c1bd689346398ab2e3c_64457_500x0_resize_box_3.png media="(max-width: 576px)" height=365 width=500><img class=img-fluid height=131 width=180 alt=featured.png src=/blog/2024-05-30-beam-deploy-1/featured_hu716373a174df6c1bd689346398ab2e3c_64457_180x0_resize_box_3.png data-src=/blog/2024-05-30-beam-deploy-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-05-30-beam-deploy-1/>Deploy Python Stream Processing App on Kubernetes - Part 1 PyFlink Application</a><div class="post-meta mt-2"><span class=post-date>May 30, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_500x0_resize_box_3.png media="(max-width: 576px)" height=338 width=500><img class=img-fluid height=122 width=180 alt=featured.png src=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_180x0_resize_box_3.png data-src=/blog/2024-03-28-beam-local-dev-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-28-beam-local-dev-1/>Apache Beam Local Development With Python - Part 1 Pipeline, Notebook, SQL and DataFrame</a><div class="post-meta mt-2"><span class=post-date>March 28, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_500x0_resize_box_3.png media="(max-width: 576px)" height=238 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_180x0_resize_box_3.png data-src=/blog/2024-01-18-dbt-pizza-shop-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-18-dbt-pizza-shop-1/>Data Build Tool (Dbt) Pizza Shop Demo - Part 1 Modelling on PostgreSQL</a><div class="post-meta mt-2"><span class=post-date>January 18, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_180x0_resize_box_3.png data-src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-12-21-kafka-development-on-k8s-part-1/>Kafka Development on Kubernetes - Part 1 Cluster Setup</a><div class="post-meta mt-2"><span class=post-date>December 21, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-12-07-flink-spark-local-dev/featured_hu7a73c8ca7d8b8a4ddf49d1a9b8fe40bd_133053_500x0_resize_box_3.png media="(max-width: 576px)" height=373 width=500><img class=img-fluid height=134 width=180 alt=featured.png src=/blog/2023-12-07-flink-spark-local-dev/featured_hu7a73c8ca7d8b8a4ddf49d1a9b8fe40bd_133053_180x0_resize_box_3.png data-src=/blog/2023-12-07-flink-spark-local-dev/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-12-07-flink-spark-local-dev/>Setup Local Development Environment for Apache Flink and Spark Using EMR Container Images</a><div class="post-meta mt-2"><span class=post-date>December 7, 2023</span></div></div></div></li></ul></div><div class=tab-pane id=recent-posts role=tabpanel aria-labelledby=recent-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-11-21-beam-examples-8/featured_hua1bed0ac2a8d7df60d85401d258c29bb_402888_500x0_resize_box_3.png media="(max-width: 576px)" height=304 width=500><img class=img-fluid height=109 width=180 alt=featured.png src=/blog/2024-11-21-beam-examples-8/featured_hua1bed0ac2a8d7df60d85401d258c29bb_402888_180x0_resize_box_3.png data-src=/blog/2024-11-21-beam-examples-8/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-11-21-beam-examples-8/>Apache Beam Python Examples - Part 8 Enhance Sport Activity Tracker With Runner Motivation</a><div class="post-meta mt-2"><span class=post-date>November 21, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-11-07-cdc-local-dev/featured_hu1be5b7cd9299c136c309544dd6dd598d_83605_500x0_resize_box_3.png media="(max-width: 576px)" height=369 width=500><img class=img-fluid height=133 width=180 alt=featured.png src=/blog/2024-11-07-cdc-local-dev/featured_hu1be5b7cd9299c136c309544dd6dd598d_83605_180x0_resize_box_3.png data-src=/blog/2024-11-07-cdc-local-dev/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-11-07-cdc-local-dev/>Change Data Capture (CDC) Local Development With PostgreSQL, Debezium Server and Pub/Sub Emulator</a><div class="post-meta mt-2"><span class=post-date>November 7, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-10-24-beam-examples-7/featured_hu336cff41161b0f32f430902350f8d12d_214574_500x0_resize_box_3.png media="(max-width: 576px)" height=320 width=500><img class=img-fluid height=115 width=180 alt=featured.png src=/blog/2024-10-24-beam-examples-7/featured_hu336cff41161b0f32f430902350f8d12d_214574_180x0_resize_box_3.png data-src=/blog/2024-10-24-beam-examples-7/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-10-24-beam-examples-7/>Apache Beam Python Examples - Part 7 Separate Droppable Data Into Side Output</a><div class="post-meta mt-2"><span class=post-date>October 24, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-10-02-beam-examples-6/featured_hu5f29b15cfad1fc457b0f3b5efe55ac30_99452_500x0_resize_box_3.png media="(max-width: 576px)" height=314 width=500><img class=img-fluid height=113 width=180 alt=featured.png src=/blog/2024-10-02-beam-examples-6/featured_hu5f29b15cfad1fc457b0f3b5efe55ac30_99452_180x0_resize_box_3.png data-src=/blog/2024-10-02-beam-examples-6/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-10-02-beam-examples-6/>Apache Beam Python Examples - Part 6 Call RPC Service in Batch With Defined Batch Size Using Stateful DoFn</a><div class="post-meta mt-2"><span class=post-date>October 2, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-09-18-beam-examples-5/featured_hu4163a2e5ad4cff386dbfbcbd0650f4f7_95285_500x0_resize_box_3.png media="(max-width: 576px)" height=310 width=500><img class=img-fluid height=112 width=180 alt=featured.png src=/blog/2024-09-18-beam-examples-5/featured_hu4163a2e5ad4cff386dbfbcbd0650f4f7_95285_180x0_resize_box_3.png data-src=/blog/2024-09-18-beam-examples-5/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-09-18-beam-examples-5/>Apache Beam Python Examples - Part 5 Call RPC Service in Batch Using Stateless DoFn</a><div class="post-meta mt-2"><span class=post-date>September 18, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-09-13-dbt-guide/featured_hu02c411e2b810e83058a2abf514c3ab2e_71185_500x0_resize_box_3.png media="(max-width: 576px)" height=253 width=500><img class=img-fluid height=91 width=180 alt=featured.png src=/blog/2024-09-13-dbt-guide/featured_hu02c411e2b810e83058a2abf514c3ab2e_71185_180x0_resize_box_3.png data-src=/blog/2024-09-13-dbt-guide/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-09-13-dbt-guide/>Guide to Running DBT in Production</a><div class="post-meta mt-2"><span class=post-date>September 13, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-09-05-dbt-cicd-demo/featured_huad11874eeea265d1d4cc984ffd50128c_60835_500x0_resize_box_3.png media="(max-width: 576px)" height=367 width=500><img class=img-fluid height=132 width=180 alt=featured.png src=/blog/2024-09-05-dbt-cicd-demo/featured_huad11874eeea265d1d4cc984ffd50128c_60835_180x0_resize_box_3.png data-src=/blog/2024-09-05-dbt-cicd-demo/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-09-05-dbt-cicd-demo/>DBT CI/CD Demo With BigQuery and GitHub Actions</a><div class="post-meta mt-2"><span class=post-date>September 5, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-08-22-cache-using-shared-object/featured_hu9078f8221b3da3b9c4a7fded6a2842e2_49574_500x0_resize_box_3.png media="(max-width: 576px)" height=211 width=500><img class=img-fluid height=76 width=180 alt=featured.png src=/blog/2024-08-22-cache-using-shared-object/featured_hu9078f8221b3da3b9c4a7fded6a2842e2_49574_180x0_resize_box_3.png data-src=/blog/2024-08-22-cache-using-shared-object/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-08-22-cache-using-shared-object/>Cache Data on Apache Beam Pipelines Using a Shared Object</a><div class="post-meta mt-2"><span class=post-date>August 22, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-08-15-beam-examples-4/featured_hue1bece16c6fea6890db11c6e669d0bb8_93408_500x0_resize_box_3.png media="(max-width: 576px)" height=319 width=500><img class=img-fluid height=115 width=180 alt=featured.png src=/blog/2024-08-15-beam-examples-4/featured_hue1bece16c6fea6890db11c6e669d0bb8_93408_180x0_resize_box_3.png data-src=/blog/2024-08-15-beam-examples-4/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-08-15-beam-examples-4/>Apache Beam Python Examples - Part 4 Call RPC Service for Data Augmentation</a><div class="post-meta mt-2"><span class=post-date>August 15, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-08-01-beam-examples-3/featured_hu19fc1c688bfb47a722801b16f94e4722_94507_500x0_resize_box_3.png media="(max-width: 576px)" height=313 width=500><img class=img-fluid height=113 width=180 alt=featured.png src=/blog/2024-08-01-beam-examples-3/featured_hu19fc1c688bfb47a722801b16f94e4722_94507_180x0_resize_box_3.png data-src=/blog/2024-08-01-beam-examples-3/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-08-01-beam-examples-3/>Apache Beam Python Examples - Part 3 Build Sport Activity Tracker With/Without SQL</a><div class="post-meta mt-2"><span class=post-date>August 1, 2024</span></div></div></div></li></ul></div></div></div></div></div></div></aside></div></main><footer class="footer mt-auto py-3 text-center container"><div class="offcanvas offcanvas-bottom h-auto" tabindex=-1 id=offcanvasActionsPanel aria-labelledby=offcanvasActionsPanelLabel><div class=offcanvas-header><div class="offcanvas-title h5" id=offcanvasActionsPanelLabel><i class="fas fa-fw fa-th-large me-1"></i>
Actions</div><button type=button class="btn-close ms-auto" data-bs-dismiss=offcanvas data-bs-target=offcanvasActionsPanel aria-label=Close></button></div><div class="offcanvas-body mt-2"><div class="actions d-flex overflow-auto align-items-center"><a role=button class="action action-go-back d-flex flex-column align-items-center me-3" href="javascript: window.history.back();"><span class="action-icon mb-2"><i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i></span> Go back
</a><a role=button class="action action-reload-page d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-redo-alt"></i></span> Reload
</a><a role=button class="action action-copy-url d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-link"></i></span> Copy URL</a></div></div></div><div class="row text-center"><div class="col-12 mt-2"><p class=mb-2>Jaehyeon Kim</p><p class="text-secondary mb-2"><small>⚙️ Data Engineer 📝 Blogger 👯 OSS Maintainer</small></p><div class="copyright mb-2 text-secondary"><small>Copyright © 2023-2024 Jaehyeon Kim. All Rights Reserved.</small></div><nav class="social-links nav justify-content-center mb-2 mt-3"><a class="nav-link social-link p-0 me-1 mb-2" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-2x fa-rss" style=color:#ea6221></i></a></nav></div><div class="col-12 col-lg-8 offset-0 offset-lg-1"></div></div></footer><script data-precache src=/assets/main/bundle.min.4185504578555b5b3c0a49a82726fac16c8dbe5ab2bf92d2dd2b9665d4a6a140.js integrity="sha256-QYVQRXhVW1s8CkmoJyb6wWyNvlqyv5LS3SuWZdSmoUA=" crossorigin=anonymous async></script><script data-precache src=/assets/icons/bundle.min.4f30d5267a9f2f9d45ed93969d45ec626100a969a8b91f71f753315a261e9034.js integrity="sha256-TzDVJnqfL51F7ZOWnUXsYmEAqWmouR9x91MxWiYekDQ=" crossorigin=anonymous defer></script><script data-precache src=/assets/viewer/bundle.min.06371891cfe6d10d36cba465c61c4d7cb17591a3be2fd9af4a38444d2074e709.js integrity="sha256-BjcYkc/m0Q02y6RlxhxNfLF1kaO+L9mvSjhETSB05wk=" crossorigin=anonymous defer></script><script data-precache defer src=/assets/katex/bundle.min.ecfaac987a9ad8e8c435500e3a2dc277d9c1bdedc12ea02390b093db3788c0d4.js integrity="sha256-7PqsmHqa2OjENVAOOi3Cd9nBve3BLqAjkLCT2zeIwNQ=" crossorigin=anonymous></script><script data-precache defer src=/assets/mermaid/bundle.min.76a078d0eb0c863cdcae6518fbf7259910f0d612b7c7b9d0ee8511a6d1a6c332.js integrity="sha256-dqB40OsMhjzcrmUY+/clmRDw1hK3x7nQ7oURptGmwzI=" crossorigin=anonymous></script><script src=/js/sw-register.js defer></script><script src=https://giscus.app/client.js data-repo=jaehyeon-kim/jaehyeon-kim.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkyNjgwMjU0NQ==" data-category data-category-id=DIC_kwDOAZj5cc4CV2fp data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous defer></script></body></html>