<!doctype html><html class=position-relative itemscope itemtype=https://schema.org/WebPage lang=en data-bs-theme=light data-palette=blue-gray><head><script src=/assets/init/bundle.min.587a916570f2c0ae58ced3b781f968a8b21e4c11e91f7488754b145d19a645cc.js integrity="sha256-WHqRZXDywK5YztO3gfloqLIeTBHpH3SIdUsUXRmmRcw=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Data Lake Demo using Change Data Capture (CDC) on AWS – Part 2 Implement CDC - Jaehyeon Kim</title>
<link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_16x16_resize_q75_h2_box_2.webp sizes=16x16 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_32x32_resize_q75_h2_box_2.webp sizes=32x32 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_150x150_resize_q75_h2_box_2.webp sizes=150x150 type=image/webp><link rel=apple-touch-icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_180x180_resize_q75_h2_box_2.webp sizes=180x180 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_192x192_resize_q75_h2_box_2.webp sizes=192x192 type=image/webp><link rel=mask-icon href=/safari-pinned-tab.svg color=#6f42c1><meta name=keywords content="AWS,Data Streaming,Analytics,Architecture,Microservices"><meta name=description content="Change data capture (CDC) on Amazon MSK and ingesting data using Apache Hudi on Amazon EMR can be used to build an efficient data lake solution. In this post, we'll build CDC with Amazon MSK and MSK Connect."><meta name=robots content="index, follow"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jaehyeon.me/blog/2021-12-12-datalake-demo-part2/featured.png"><meta name=twitter:title content="Data Lake Demo using Change Data Capture (CDC) on AWS – Part 2 Implement CDC"><meta name=twitter:description content="Change data capture (CDC) on Amazon MSK and ingesting data using Apache Hudi on Amazon EMR can be used to build an efficient data lake solution. In this post, we'll build CDC with Amazon MSK and MSK Connect."><meta property="og:title" content="Data Lake Demo using Change Data Capture (CDC) on AWS – Part 2 Implement CDC"><meta property="og:description" content="Change data capture (CDC) on Amazon MSK and ingesting data using Apache Hudi on Amazon EMR can be used to build an efficient data lake solution. In this post, we'll build CDC with Amazon MSK and MSK Connect."><meta property="og:type" content="article"><meta property="og:url" content="https://jaehyeon.me/blog/2021-12-12-datalake-demo-part2/"><meta property="og:image" content="https://jaehyeon.me/blog/2021-12-12-datalake-demo-part2/featured.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2021-12-12T00:00:00+00:00"><meta property="article:modified_time" content="2023-05-04T09:22:05+10:00"><meta property="og:see_also" content="https://jaehyeon.me/blog/2021-12-19-datalake-demo-part3/"><meta property="og:see_also" content="https://jaehyeon.me/blog/2021-12-05-datalake-demo-part1/"><meta itemprop=name content="Data Lake Demo using Change Data Capture (CDC) on AWS – Part 2 Implement CDC"><meta itemprop=description content="Change data capture (CDC) on Amazon MSK and ingesting data using Apache Hudi on Amazon EMR can be used to build an efficient data lake solution. In this post, we'll build CDC with Amazon MSK and MSK Connect."><meta itemprop=datePublished content="2021-12-12T00:00:00+00:00"><meta itemprop=dateModified content="2023-05-04T09:22:05+10:00"><meta itemprop=wordCount content="3430"><meta itemprop=image content="https://jaehyeon.me/blog/2021-12-12-datalake-demo-part2/featured.png"><meta itemprop=keywords content="AWS,Amazon EMR,Amazon MSK,Amazon MSK Connect,Apache Spark,Apache Hudi,Apache Kafka,Kafka Connect,Change Data Capture,Data Lake,Docker,Terraform,"><link rel=manifest href=/manifest.json><script async src="https://www.googletagmanager.com/gtag/js?id=G-076N8WCGWZ"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-076N8WCGWZ",{anonymize_ip:!1})}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2764466088407958"></script><link data-precache rel=stylesheet href="/assets/main/bundle.min.9fadd6633f8b348fed656abfea9f5293870452742e508e6bf968ea7b14639bee.css" integrity="sha256-n63WYz+LNI/tZWq/6p9Sk4cEUnQuUI5r+WjqexRjm+4=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/katex/bundle.min.b236565f31a50508b5851cfb13938fa5a8d9f4fd00884efe2ad27a11b82968bf.css integrity="sha256-sjZWXzGlBQi1hRz7E5OPpajZ9P0AiE7+KtJ6EbgpaL8=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/viewer/bundle.min.c8cc49b70e98e42caf70845e0d50f8e86821121688c2e5a5f6fc464d40154853.css integrity="sha256-yMxJtw6Y5CyvcIReDVD46GghEhaIwuWl9vxGTUAVSFM=" crossorigin=anonymous></head><body><header class="mb-4 sticky-top"><nav class="top-app-bar shadow navbar navbar-expand-xxl"><div class=container><a class="navbar-brand d-flex align-items-center flex-grow-1 flex-xxl-grow-0 justify-content-xxl-start ms-2 ms-xxl-0 mx-auto me-xxl-2" href=https://jaehyeon.me/>Jaehyeon Kim</a><div class="offcanvas-xxl offcanvas-end flex-grow-1" data-bs-scroll=true tabindex=-1 id=navbarMenus aria-labelledby=navbarMenusLabel><div class="offcanvas-header px-4 pb-0"><div class="offcanvas-title h5" id=navbarMenusLabel>Jaehyeon Kim</div><button type=button class="btn-close btn-close-white" data-bs-dismiss=offcanvas data-bs-target=#navbarMenus aria-label=Close></button></div><div class="offcanvas-body p-4 pt-0 p-xxl-0"><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center me-auto"><li class="nav-item col-12 col-xxl-auto dropdown px-0"><a href=# class="nav-link dropdown-toggle" id=navbarDropdownBlog role=button data-bs-toggle=dropdown aria-expanded=false><span class="menu-icon me-1"><i class="fas fa-fw fa-blog text-warning"></i></span>Blog</a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=navbarDropdownBlog data-bs-popper=none><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/archives/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-file-archive text-primary"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-0">Archives</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/series/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Series</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/categories/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Categories</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/tags/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Tags</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li></ul></li></ul><hr class=d-xxl-none><form class="search-bar ms-auto" action=/search/ novalidate><div class="input-group input-group-sm align-items-center"><span class="btn btn-search disabled position-absolute left-0 border-0 px-1"><i class="fas fa-fw fa-search fa-lg"></i>
</span><input class="my-1 form-control border-white rounded-5 search-input bg-body" name=q type=search placeholder=Search aria-label=Search required>
<span class="search-shortcut position-absolute end-0 top-0 me-2"><kbd class="bg-primary rounded shadow">/</kbd></span></div></form><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center ms-md-auto"><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><nav class="social-links nav justify-content-center flex-row"><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fab fa-github"></i>
<span class="ms-1 d-xxl-none">Github</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fab fa-linkedin-in"></i>
<span class="ms-1 d-xxl-none">Linkedin</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fab fa-paypal"></i>
<span class="ms-1 d-xxl-none">Paypal</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-rss"></i>
<span class="ms-1 d-xxl-none">RSS</span></a></nav></li><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><div class="vr d-none d-xxl-flex h-100 mx-xxl-2 text-white"></div><hr class="d-xxl-none my-2"></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=fontSizeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-font"></i>
<span class=d-xxl-none>Font Size</span></a><ul class="font-size-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=fontSizeDropdown><li><button class="font-size-item dropdown-item" data-size=xs>
Extra Small</button></li><li><button class="font-size-item dropdown-item" data-size=sm>
Small</button></li><li><button class="font-size-item dropdown-item active" data-size=md>
Medium</button></li><li><button class="font-size-item dropdown-item" data-size=lg>
Large</button></li><li><button class="font-size-item dropdown-item" data-size=xl>
Extra Large</button></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=paletteDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-palette"></i>
<span class=d-xxl-none>Palette</span></a><ul class="palette-dropdown-menu dropdown-menu dropdown-menu-end px-2 row g-2" aria-labelledby=paletteDropdown><li class="col-4 my-1"><a role=button id=palette-blue aria-label=Blue class="btn btn-sm w-100 palette text-bg-blue" data-palette=blue></a></li><li class="col-4 my-1"><a role=button id=palette-blue-gray aria-label="Blue Gray" class="btn btn-sm w-100 palette text-bg-blue-gray" data-palette=blue-gray></a></li><li class="col-4 my-1"><a role=button id=palette-brown aria-label=Brown class="btn btn-sm w-100 palette text-bg-brown" data-palette=brown></a></li><li class="col-4 my-1"><a role=button id=palette-cyan aria-label=Cyan class="btn btn-sm w-100 palette text-bg-cyan" data-palette=cyan></a></li><li class="col-4 my-1"><a role=button id=palette-green aria-label=Green class="btn btn-sm w-100 palette text-bg-green" data-palette=green></a></li><li class="col-4 my-1"><a role=button id=palette-indigo aria-label=Indigo class="btn btn-sm w-100 palette text-bg-indigo" data-palette=indigo></a></li><li class="col-4 my-1"><a role=button id=palette-orange aria-label=Orange class="btn btn-sm w-100 palette text-bg-orange" data-palette=orange></a></li><li class="col-4 my-1"><a role=button id=palette-pink aria-label=Pink class="btn btn-sm w-100 palette text-bg-pink" data-palette=pink></a></li><li class="col-4 my-1"><a role=button id=palette-purple aria-label=Purple class="btn btn-sm w-100 palette text-bg-purple" data-palette=purple></a></li><li class="col-4 my-1"><a role=button id=palette-red aria-label=Red class="btn btn-sm w-100 palette text-bg-red" data-palette=red></a></li><li class="col-4 my-1"><a role=button id=palette-teal aria-label=Teal class="btn btn-sm w-100 palette text-bg-teal" data-palette=teal></a></li><li class="col-4 my-1"><a role=button id=palette-yellow aria-label=Yellow class="btn btn-sm w-100 palette text-bg-yellow" data-palette=yellow></a></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=modeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="mode-icon fas fa-fw fa-sun" id=modeIcon></i>
<span class=d-xxl-none>Mode</span></a><ul class="mode-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=modeDropdown><li class="mode-item active" data-color-mode=light data-icon=sun><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-sun"></i> Light</button></li><li class=mode-item data-color-mode=dark data-icon=moon><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-moon"></i> Dark</button></li><li class=mode-item data-color-mode=auto data-icon=adjust><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-adjust"></i> Auto</button></li></ul></li></ul></div></div><div class=d-flex><button class="navbar-toggler order-5 border-0" type=button data-bs-toggle=offcanvas data-bs-target=#navbarMenus aria-controls=navbarMenus aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-h"></i></button></div></div></nav></header><main class=container><div class="row content"><noscript><div class="alert alert-danger" role=alert>Your browser does not support JavaScript.</div></noscript><div class=col-xxl-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class="card-body pb-0"><ol class="hbs-breadcrumb breadcrumb flex-nowrap"><li class="breadcrumb-item text-surface"><a href=/>Home</a></li><li class="breadcrumb-item text-surface"><a href=/blog/>Blogs</a></li><li class="breadcrumb-item active">Data Lake Demo Using Change Data Capture (CDC) on AWS – Part 2 Implement CDC</li></ol></div></nav><div class="post-panel-wrapper position-relative d-flex justify-content-center"><div class="d-flex flex-row justify-content-center rounded-5 border post-panel position-fixed px-3 py-1 surface shadow-1"><a class="action action-toc d-none d-xxl-block" href=#postTOC role=button title="Table of contents"><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-toc d-block d-xxl-none" href=#post-toc-container role=button title="Table of contents"><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-post-comments" href=#post-comments role=button aria-label=Comments title=Comments><i class="fas fa-fw fa-comments"></i>
</a><a id=sidebarToggler class="action action-sidebar-toggler d-none d-xxl-block" role=button title="Sidebar toggler"><i class="fas fa-fw fa-expand-alt" data-fa-transform=rotate-45></i></a></div></div><article class="row card component mb-4 post"><div class=card-header><h1 class="card-title post-title my-2">Data Lake Demo Using Change Data Capture (CDC) on AWS – Part 2 Implement CDC</h1></div><div class=card-body><div class="post-meta mb-3"><span class="post-date me-1 mb-1" title="created on 2021-12-12 00:00:00 +0000 UTC, updated on 2023-05-03 23:22:05 +0000 UTC.">December 12, 2021</span><span class="post-reading-time me-1 mb-1">17 min read</span><a href=/categories/change-data-capture-cdc/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-category">
<i class="fas fa-fw fa-folder me-1"></i>Change Data Capture (CDC)</a><a href=/series/data-lake-demo-using-change-data-capture/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-series">
<i class="fas fa-fw fa-columns me-1"></i>Data Lake Demo Using Change Data Capture</a><a href=/tags/amazon-emr/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Amazon EMR</a><a href=/tags/amazon-msk/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Amazon MSK</a><a href=/tags/amazon-msk-connect/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Amazon MSK Connect</a><a href=/tags/apache-hudi/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Hudi</a><a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Kafka</a><a href=/tags/apache-spark/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Spark</a><a href=/tags/aws/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">AWS</a><a href=/tags/change-data-capture/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Change Data Capture</a><a href=/tags/data-lake/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Data Lake</a><a href=/tags/docker/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Docker</a><a href=/tags/kafka-connect/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Kafka Connect</a><a href=/tags/terraform/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Terraform</a></div><picture class="d-flex justify-content-center"><source srcset=/blog/2021-12-12-datalake-demo-part2/featured_hua25eccd3824300d3b1ed87f56797248c_164526_0x270_resize_box_3.png type=image/png media="(max-width: 576px)" width=588 height=270><img class="post-featured-img h-auto w-auto mb-3" alt="Data Lake Demo using Change Data Capture (CDC) on AWS – Part 2 Implement CDC" src=/blog/2021-12-12-datalake-demo-part2/featured_hua25eccd3824300d3b1ed87f56797248c_164526_0x480_resize_box_3.png width=1046 height=480 data-src=/blog/2021-12-12-datalake-demo-part2/featured.png></picture><div id=postTOC class="mb-3 text-surface"><h2 class=mb-3>Contents<a class="anchor ms-1" href=#postTOC></a></h2><nav id=TableOfContents><ul><li><a href=#architecture>Architecture</a></li><li><a href=#infrastructure>Infrastructure</a><ul><li><a href=#vpc>VPC</a><ul><li><a href=#nat-instances>NAT Instances</a></li><li><a href=#vpn-bastion-host>VPN Bastion Host</a></li></ul></li><li><a href=#aurora-postgresql>Aurora PostgreSQL</a><ul><li><a href=#source-database>Source Database</a></li></ul></li><li><a href=#msk-cluster>MSK Cluster</a><ul><li><a href=#msk-connect-role>MSK Connect Role</a></li></ul></li></ul></li><li><a href=#cdc-development>CDC Development</a><ul><li><a href=#custom-plugins>Custom Plugins</a></li><li><a href=#msk-connectors>MSK Connectors</a><ul><li><a href=#source-connector>Source Connector</a></li><li><a href=#sink-connector>Sink Connector</a></li></ul></li><li><a href=#updateinsert-examples>Update/Insert Examples</a><ul><li><a href=#kafka-ui>Kafka UI</a></li><li><a href=#update-event>Update Event</a></li><li><a href=#insert-event>Insert Event</a></li></ul></li></ul></li><li><a href=#conclusion>Conclusion</a></li></ul></nav><hr class=text-secondary></div><div class="post-content mb-3" data-bs-spy=scroll data-bs-target=#TableOfContents tabindex=0><div id=post-content-body><p><strong><a href=https://cevo.com.au/post/data-lake-demo-using-cdc-part-2/ target=_blank rel="noopener noreferrer">This article<i class="fas fa-external-link-square-alt ms-1"></i></a> was originally posted on Tech Insights of <a href=https://cevo.com.au/ target=_blank rel="noopener noreferrer">Cevo Australia<i class="fas fa-external-link-square-alt ms-1"></i></a>.</strong></p><p>In the <a href=/blog/2021-12-05-datalake-demo-part1>previous post</a>, we discussed a data lake solution where data ingestion is performed using <a href=https://www.redhat.com/en/topics/integration/what-is-change-data-capture#what-is-cdc target=_blank rel="noopener noreferrer">change data capture (CDC)<i class="fas fa-external-link-square-alt ms-1"></i></a> and the output files are <em>upserted</em> to an <a href=https://hudi.apache.org/ target=_blank rel="noopener noreferrer">Apache Hudi<i class="fas fa-external-link-square-alt ms-1"></i></a> table. Being registered to <a href=https://docs.aws.amazon.com/glue/latest/dg/populate-data-catalog.html target=_blank rel="noopener noreferrer">Glue Data Catalog<i class="fas fa-external-link-square-alt ms-1"></i></a>, it can be used for ad-hoc queries and report/dashboard creation. The <a href=https://docs.yugabyte.com/latest/sample-data/northwind/ target=_blank rel="noopener noreferrer">Northwind database<i class="fas fa-external-link-square-alt ms-1"></i></a> is used as the source database and, following the <a href=https://microservices.io/patterns/data/transactional-outbox.html target=_blank rel="noopener noreferrer">transactional outbox pattern<i class="fas fa-external-link-square-alt ms-1"></i></a>, order-related changes are _upserted _to an outbox table by triggers. The data ingestion is developed using Kafka connectors in the <a href=https://docs.confluent.io/platform/current/quickstart/ce-docker-quickstart.html target=_blank rel="noopener noreferrer">local Confluent platform<i class="fas fa-external-link-square-alt ms-1"></i></a> where the <a href=https://debezium.io/documentation/reference/stable/connectors/postgresql.html target=_blank rel="noopener noreferrer">Debezium for PostgreSQL<i class="fas fa-external-link-square-alt ms-1"></i></a> is used as the source connector and the <a href=https://lenses.io/blog/2020/11/new-kafka-to-S3-connector/ target=_blank rel="noopener noreferrer">Lenses S3 sink connector<i class="fas fa-external-link-square-alt ms-1"></i></a> is used as the sink connector. We confirmed the order creation and update events are captured as expected, and it is ready for production deployment. In this post, we&rsquo;ll build the CDC part of the solution on AWS using <a href=https://aws.amazon.com/msk/ target=_blank rel="noopener noreferrer">Amazon MSK<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href=https://aws.amazon.com/msk/features/msk-connect/ target=_blank rel="noopener noreferrer">MSK Connect<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><ul><li><a href=/blog/2021-12-05-datalake-demo-part1>Part 1 Local Development</a></li><li><a href=/blog/2021-12-12-datalake-demo-part2/#>Part 2 Implement CDC</a> (this post)</li><li><a href=/blog/2021-12-19-datalake-demo-part3>Part 3 Implement Data Lake</a></li></ul><h2 id=architecture data-numberify>Architecture<a class="anchor ms-1" href=#architecture></a></h2><p>As described in a <a href=https://www.redhat.com/en/topics/integration/what-is-change-data-capture target=_blank rel="noopener noreferrer">Red Hat IT topics article<i class="fas fa-external-link-square-alt ms-1"></i></a>, <em>change data capture (CDC) is a proven data integration pattern to track when and what changes occur in data then alert other systems and services that must respond to those changes. Change data capture helps maintain consistency and functionality across all systems that rely on data</em>.</p><p>The primary use of CDC is to enable applications to respond almost immediately whenever data in databases change. Specifically its use cases cover microservices integration, data replication with up-to-date data, building time-sensitive analytics dashboards, auditing and compliance, cache invalidation, full-text search and so on. There are a number of approaches for CDC - polling, dual writes and log-based CDC. Among those, <a href=https://debezium.io/blog/2018/07/19/advantages-of-log-based-change-data-capture/ target=_blank rel="noopener noreferrer">log-based CDC has advantages<i class="fas fa-external-link-square-alt ms-1"></i></a> to other approaches.</p><p>Both <a href=https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Task.CDC.html target=_blank rel="noopener noreferrer">Amazon DMS<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href=https://debezium.io/ target=_blank rel="noopener noreferrer">Debezium<i class="fas fa-external-link-square-alt ms-1"></i></a> implement log-based CDC. While the former is a managed service, the latter can be deployed to a Kafka cluster as a (source) connector. It uses <a href=https://www.redhat.com/en/topics/integration/what-is-apache-kafka target=_blank rel="noopener noreferrer">Apache Kafka<i class="fas fa-external-link-square-alt ms-1"></i></a> as a messaging service to deliver database change notifications to the applicable systems and applications. Note that Kafka Connect is a tool for streaming data between Apache Kafka and other data systems by connectors in a scalable and reliable way. In AWS, we can use <a href=https://aws.amazon.com/msk/ target=_blank rel="noopener noreferrer">Amazon MSK<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href=https://aws.amazon.com/msk/features/msk-connect/ target=_blank rel="noopener noreferrer">MSK Connect<i class="fas fa-external-link-square-alt ms-1"></i></a> for building a Debezium based CDC solution.</p><p>Data replication to data lakes using CDC can be much more effective if <a href=https://lakefs.io/hudi-iceberg-and-delta-lake-data-lake-table-formats-compared/ target=_blank rel="noopener noreferrer">data is stored to a format<i class="fas fa-external-link-square-alt ms-1"></i></a> that supports atomic transactions and consistent updates. Popular choices are <a href=https://hudi.apache.org/ target=_blank rel="noopener noreferrer">Apache Hudi<i class="fas fa-external-link-square-alt ms-1"></i></a>, <a href=https://iceberg.apache.org/ target=_blank rel="noopener noreferrer">Apache Iceberg<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href=https://delta.io/ target=_blank rel="noopener noreferrer">Delta Lake<i class="fas fa-external-link-square-alt ms-1"></i></a>. Among those, Apache Hudi can be a good option as it is <a href=https://docs.aws.amazon.com/emr/latest/ReleaseGuide/emr-hudi.html target=_blank rel="noopener noreferrer">well-integrated with AWS services<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><p>Below shows the architecture of the data lake solution that we will be building in this series of posts.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/00-01-architecture.png loading=lazy width=1301 height=535></picture></p><ol><li>Employing the <a href=https://microservices.io/patterns/data/transactional-outbox.html target=_blank rel="noopener noreferrer">transactional outbox pattern<i class="fas fa-external-link-square-alt ms-1"></i></a>, the source database publishes change event records to the CDC event table. The event records are generated by triggers that listen to insert and update events on source tables. See the Source Database section of the <a href=/blog/2021-12-05-datalake-demo-part1>previous post</a> for details.</li><li>CDC is implemented in a streaming environment and <a href=https://aws.amazon.com/msk/ target=_blank rel="noopener noreferrer">Amazon MSK<i class="fas fa-external-link-square-alt ms-1"></i></a> is used to build the streaming infrastructure. In order to process the real-time CDC event records, a source and sink connectors are set up in <a href=https://aws.amazon.com/msk/features/msk-connect/ target=_blank rel="noopener noreferrer">Amazon MSK Connect<i class="fas fa-external-link-square-alt ms-1"></i></a>. The <a href=https://debezium.io/documentation/reference/stable/connectors/postgresql.html target=_blank rel="noopener noreferrer">Debezium connector for PostgreSQL<i class="fas fa-external-link-square-alt ms-1"></i></a> is used as the source connector and the <a href=https://lenses.io/blog/2020/11/new-kafka-to-S3-connector/ target=_blank rel="noopener noreferrer">Lenses S3 connector<i class="fas fa-external-link-square-alt ms-1"></i></a> is used as the sink connector. The sink connector pushes messages to a S3 bucket.</li><li><a href=https://hudi.apache.org/docs/writing_data/#deltastreamer target=_blank rel="noopener noreferrer">Hudi DeltaStreamer<i class="fas fa-external-link-square-alt ms-1"></i></a> is run on <a href=https://aws.amazon.com/emr/ target=_blank rel="noopener noreferrer">Amazon EMR<i class="fas fa-external-link-square-alt ms-1"></i></a>. As a spark application, it reads files from the S3 bucket and upserts Hudi records to another S3 bucket. The Hudi table is created in the AWS Glue Data Catalog.</li><li>The Hudi table is queried in <a href=https://aws.amazon.com/athena/ target=_blank rel="noopener noreferrer">Amazon Athena<i class="fas fa-external-link-square-alt ms-1"></i></a> while the table is registered in the AWS Glue Data Catalog.</li><li>Dashboards are created in <a href=https://aws.amazon.com/quicksight/ target=_blank rel="noopener noreferrer">Amazon Quicksight<i class="fas fa-external-link-square-alt ms-1"></i></a> where the dataset is created using Amazon Athena.</li></ol><p>In this post, we&rsquo;ll build the CDC part of the solution on AWS using Amazon MSK and MSK Connect.</p><h2 id=infrastructure data-numberify>Infrastructure<a class="anchor ms-1" href=#infrastructure></a></h2><h3 id=vpc data-numberify>VPC<a class="anchor ms-1" href=#vpc></a></h3><p>We&rsquo;ll build the data lake solution in a dedicated VPC. The VPC is created in the Sydney region, and it has private and public subnets in 2 availability zones. Note the source database, MSK cluster/connectors and EMR cluster will be deployed to the private subnets. The <a href=https://s3-eu-west-1.amazonaws.com/widdix-aws-cf-templates-releases-eu-west-1/stable/vpc/vpc-2azs.yaml target=_blank rel="noopener noreferrer">CloudFormation template<i class="fas fa-external-link-square-alt ms-1"></i></a> can be found in the <a href=https://templates.cloudonaut.io/en/stable/ target=_blank rel="noopener noreferrer">Free Templates for AWS CloudFormation<i class="fas fa-external-link-square-alt ms-1"></i></a>- see the <a href=https://templates.cloudonaut.io/en/stable/vpc/ target=_blank rel="noopener noreferrer">VPC section<i class="fas fa-external-link-square-alt ms-1"></i></a> for details.</p><h4 id=nat-instances data-numberify>NAT Instances<a class="anchor ms-1" href=#nat-instances></a></h4><p>NAT instances are created in each of the availability zone to forward outbound traffic to the internet. The <a href=https://s3-eu-west-1.amazonaws.com/widdix-aws-cf-templates-releases-eu-west-1/stable/vpc/vpc-nat-instance.yaml target=_blank rel="noopener noreferrer">CloudFormation template<i class="fas fa-external-link-square-alt ms-1"></i></a> can be found in the VPC section of the site as well.</p><h4 id=vpn-bastion-host data-numberify>VPN Bastion Host<a class="anchor ms-1" href=#vpn-bastion-host></a></h4><p>We can use a VPN bastion host to access resources in the private subnets. The free template site provides both SSH and VPN bastion host templates and I find the latter is more convenient. It can be used to access other resources via different ports as well as be used as an SSH bastion host. The <a href=https://s3-eu-west-1.amazonaws.com/widdix-aws-cf-templates-releases-eu-west-1/stable/vpc/vpc-vpn-bastion.yaml target=_blank rel="noopener noreferrer">CloudFormation template<i class="fas fa-external-link-square-alt ms-1"></i></a> creates an EC2 instance in one of the public subnets and installs a <a href=https://www.softether.org/ target=_blank rel="noopener noreferrer">SoftEther VPN<i class="fas fa-external-link-square-alt ms-1"></i></a> server. The template requires you to add the <a href=https://en.wikipedia.org/wiki/Pre-shared_key target=_blank rel="noopener noreferrer">pre-shared key<i class="fas fa-external-link-square-alt ms-1"></i></a> and the VPN admin password, which can be used to manage the server and create connection settings for the VPN server. After creating the CloudFormation stack, we need to download the server manager from the <a href="https://www.softether-download.com/en.aspx?product=softether" target=_blank rel="noopener noreferrer">download page<i class="fas fa-external-link-square-alt ms-1"></i></a> and to install the admin tools.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/vpn-00.png loading=lazy width=587 height=430></picture></p><p>After that, we can create connection settings for the VPN server by providing the necessary details as marked in red boxes below. We should add the public IP address of the EC2 instance and the VPN admin password.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/vpn-01.png loading=lazy width=764 height=730></picture></p><p>The template also has VPN username and password parameters and those are used to create a user account in the VPN bastion server. Using the credentials we can set up a VPN connection using the SoftEther VPN client program - it can be downloaded on the same download page. We should add the public IP address of the EC2 instance to the host name and select DEFAULT as the virtual hub name.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/vpn-02.png loading=lazy width=792 height=723></picture></p><p>After that, we can connect to the VPN bastion host and access resources in the private subnets.</p><h3 id=aurora-postgresql data-numberify>Aurora PostgreSQL<a class="anchor ms-1" href=#aurora-postgresql></a></h3><p>We create the source database with Aurora PostgreSQL. The <a href=https://s3-eu-west-1.amazonaws.com/widdix-aws-cf-templates-releases-eu-west-1/stable/state/rds-postgres.yaml target=_blank rel="noopener noreferrer">CloudFormation template<i class="fas fa-external-link-square-alt ms-1"></i></a> from the <a href=https://templates.cloudonaut.io/en/stable/state/ target=_blank rel="noopener noreferrer">free template site<i class="fas fa-external-link-square-alt ms-1"></i></a> creates database instances in multiple availability zones. We can simplify it by creating only a single instance. Also, as we&rsquo;re going to use the <code>pgoutput</code> plugin for the Debezium source connector, we need to set <code>rds:logical_replication</code> value to &ldquo;1&rdquo; in the database cluster parameter group. Note to add the CloudFormation stack name of the VPN bastion host to the <em>ParentSSHBastionStack</em> parameter value so that the database can be accessed by the VPN bastion host. Also note that the template doesn&rsquo;t include an inbound rule from the MSK cluster that&rsquo;ll be created below. For now, we need to add the inbound rule manually. The updated template can be found in the project <a href=https://github.com/jaehyeon-kim/data-lake-demo/blob/main/infra/state/rds-aurora.yaml target=_blank rel="noopener noreferrer"><strong>GitHub repository</strong><i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><h4 id=source-database data-numberify>Source Database<a class="anchor ms-1" href=#source-database></a></h4><p>As with the local development, we can create the source database by executing the <a href=https://github.com/jaehyeon-kim/data-lake-demo/tree/main/data/sql target=_blank rel="noopener noreferrer">db creation SQL scripts<i class="fas fa-external-link-square-alt ms-1"></i></a>. A function is created in Python. After creating the <em>datalake</em> schema and setting the search path of the database (<em>devdb</em>) to it, it executes the SQL scripts.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=ln> 1</span><span class=cl><span class=c1># ./data/load/src.py</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=k>def</span> <span class=nf>create_northwind_db</span><span class=p>():</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=s2>    Create Northwind database by executing SQL scripts
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl>    <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>        <span class=k>global</span> <span class=n>conn</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>        <span class=k>with</span> <span class=n>conn</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>            <span class=k>with</span> <span class=n>conn</span><span class=o>.</span><span class=n>cursor</span><span class=p>()</span> <span class=k>as</span> <span class=n>curs</span><span class=p>:</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>                <span class=n>curs</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=s2>&#34;CREATE SCHEMA datalake;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>                <span class=n>curs</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=s2>&#34;SET search_path TO datalake;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>12</span><span class=cl>                <span class=n>curs</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=s2>&#34;ALTER database devdb SET search_path TO datalake;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>                <span class=n>curs</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>set_script_path</span><span class=p>(</span><span class=s2>&#34;01_northwind_ddl.sql&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s2>&#34;r&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>())</span>
</span></span><span class=line><span class=ln>14</span><span class=cl>                <span class=n>curs</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>set_script_path</span><span class=p>(</span><span class=s2>&#34;02_northwind_data.sql&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s2>&#34;r&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>())</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>                <span class=n>curs</span><span class=o>.</span><span class=n>execute</span><span class=p>(</span><span class=n>set_script_path</span><span class=p>(</span><span class=s2>&#34;03_cdc_events.sql&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s2>&#34;r&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>())</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>                <span class=n>conn</span><span class=o>.</span><span class=n>commit</span><span class=p>()</span>
</span></span><span class=line><span class=ln>17</span><span class=cl>                <span class=n>typer</span><span class=o>.</span><span class=n>echo</span><span class=p>(</span><span class=s2>&#34;Northwind SQL scripts executed&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>    <span class=k>except</span> <span class=p>(</span><span class=n>psycopg2</span><span class=o>.</span><span class=n>OperationalError</span><span class=p>,</span> <span class=n>psycopg2</span><span class=o>.</span><span class=n>DatabaseError</span><span class=p>,</span> <span class=ne>FileNotFoundError</span><span class=p>)</span> <span class=k>as</span> <span class=n>err</span><span class=p>:</span>
</span></span><span class=line><span class=ln>19</span><span class=cl>        <span class=n>typer</span><span class=o>.</span><span class=n>echo</span><span class=p>(</span><span class=n>create_northwind_db</span><span class=o>.</span><span class=vm>__name__</span><span class=p>,</span> <span class=n>err</span><span class=p>)</span>
</span></span><span class=line><span class=ln>20</span><span class=cl>        <span class=n>close_conn</span><span class=p>()</span>
</span></span><span class=line><span class=ln>21</span><span class=cl>        <span class=n>exit</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><p>In order to facilitate the db creation, a simple command line application is created using the <a href=https://typer.tiangolo.com/ target=_blank rel="noopener noreferrer">Typer library<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=ln> 1</span><span class=cl><span class=c1># ./data/load/main.py</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=kn>import</span> <span class=nn>typer</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl><span class=kn>from</span> <span class=nn>src</span> <span class=kn>import</span> <span class=n>set_connection</span><span class=p>,</span> <span class=n>create_northwind_db</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl>
</span></span><span class=line><span class=ln> 5</span><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl>    <span class=n>host</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>typer</span><span class=o>.</span><span class=n>Option</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=s2>&#34;--host&#34;</span><span class=p>,</span> <span class=s2>&#34;-h&#34;</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s2>&#34;Database host&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>    <span class=n>port</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=n>typer</span><span class=o>.</span><span class=n>Option</span><span class=p>(</span><span class=mi>5432</span><span class=p>,</span> <span class=s2>&#34;--port&#34;</span><span class=p>,</span> <span class=s2>&#34;-p&#34;</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s2>&#34;Database port&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>    <span class=n>dbname</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>typer</span><span class=o>.</span><span class=n>Option</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=s2>&#34;--dbname&#34;</span><span class=p>,</span> <span class=s2>&#34;-d&#34;</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s2>&#34;Database name&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>    <span class=n>user</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>typer</span><span class=o>.</span><span class=n>Option</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=s2>&#34;--user&#34;</span><span class=p>,</span> <span class=s2>&#34;-u&#34;</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s2>&#34;Database user name&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>    <span class=n>password</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>typer</span><span class=o>.</span><span class=n>Option</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>hide_input</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s2>&#34;Database user password&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln>11</span><span class=cl><span class=p>):</span>
</span></span><span class=line><span class=ln>12</span><span class=cl>    <span class=n>to_create</span> <span class=o>=</span> <span class=n>typer</span><span class=o>.</span><span class=n>confirm</span><span class=p>(</span><span class=s2>&#34;To create database?&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>    <span class=k>if</span> <span class=n>to_create</span><span class=p>:</span>
</span></span><span class=line><span class=ln>14</span><span class=cl>        <span class=n>params</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;host&#34;</span><span class=p>:</span> <span class=n>host</span><span class=p>,</span> <span class=s2>&#34;port&#34;</span><span class=p>:</span> <span class=n>port</span><span class=p>,</span> <span class=s2>&#34;dbname&#34;</span><span class=p>:</span> <span class=n>dbname</span><span class=p>,</span> <span class=s2>&#34;user&#34;</span><span class=p>:</span> <span class=n>user</span><span class=p>,</span> <span class=s2>&#34;password&#34;</span><span class=p>:</span> <span class=n>password</span><span class=p>}</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>        <span class=n>set_connection</span><span class=p>(</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>        <span class=n>create_northwind_db</span><span class=p>()</span>
</span></span><span class=line><span class=ln>17</span><span class=cl>
</span></span><span class=line><span class=ln>18</span><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=ln>19</span><span class=cl>    <span class=n>typer</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>main</span><span class=p>)</span>
</span></span></code></pre></div><p>It has a set of options to specify - database host, post, database name and username. The database password is set to be prompted, and an additional confirmation is required. If all options are provided, the app runs and creates the source database.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl><span class=o>(</span>venv<span class=o>)</span> jaehyeon@cevo:~/data-lake-demo$ python data/load/main.py --help
</span></span><span class=line><span class=ln> 2</span><span class=cl>Usage: main.py <span class=o>[</span>OPTIONS<span class=o>]</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>
</span></span><span class=line><span class=ln> 4</span><span class=cl>Options:
</span></span><span class=line><span class=ln> 5</span><span class=cl>  -h, --host TEXT       Database host  <span class=o>[</span>required<span class=o>]</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl>  -p, --port INTEGER    Database port  <span class=o>[</span>default: 5432<span class=o>]</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>  -d, --dbname TEXT     Database name  <span class=o>[</span>required<span class=o>]</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>  -u, --user TEXT       Database user name  <span class=o>[</span>required<span class=o>]</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>  --password TEXT       Database user password  <span class=o>[</span>required<span class=o>]</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>  --install-completion  Install completion <span class=k>for</span> the current shell.
</span></span><span class=line><span class=ln>11</span><span class=cl>  --show-completion     Show completion <span class=k>for</span> the current shell, to copy it or
</span></span><span class=line><span class=ln>12</span><span class=cl>                        customize the installation.
</span></span><span class=line><span class=ln>13</span><span class=cl>  --help                Show this message and exit.
</span></span><span class=line><span class=ln>14</span><span class=cl>
</span></span><span class=line><span class=ln>15</span><span class=cl><span class=o>(</span>venv<span class=o>)</span> jaehyeon@cevo:~/data-lake-demo$ python data/load/main.py -h &lt;db-host-name-or-ip&gt; -d &lt;dbname&gt; -u &lt;username&gt;
</span></span><span class=line><span class=ln>16</span><span class=cl>Password:
</span></span><span class=line><span class=ln>17</span><span class=cl>To create database? <span class=o>[</span>y/N<span class=o>]</span>: y
</span></span><span class=line><span class=ln>18</span><span class=cl>Database connection created
</span></span><span class=line><span class=ln>19</span><span class=cl>Northwind SQL scripts executed
</span></span></code></pre></div><p>As illustrated thoroughly in the <a href=/blog/2021-12-05-datalake-demo-part1>previous post</a>, it inserts 829 order event records to the <em>cdc_events</em> table.</p><h3 id=msk-cluster data-numberify>MSK Cluster<a class="anchor ms-1" href=#msk-cluster></a></h3><p>We&rsquo;ll create an MSK cluster with 2 brokers (<em><a href=https://kafka.apache.org/documentation/#intro_nutshell target=_blank rel="noopener noreferrer">servers<i class="fas fa-external-link-square-alt ms-1"></i></a></em>). The instance type of brokers is set to <code>kafka.m5.large</code>. Note that the smallest instance type of <code>kafka.t3.small</code> may look better for development, but we&rsquo;ll have a <a href=https://github.com/aws/aws-msk-iam-auth/issues/28 target=_blank rel="noopener noreferrer">failed authentication error<i class="fas fa-external-link-square-alt ms-1"></i></a> when IAM Authentication is used for access control and connectors are created on MSK Connect. It is because the T3 instance type is limited to <a href=https://docs.aws.amazon.com/msk/latest/developerguide/limits.html target=_blank rel="noopener noreferrer">1 TCP connection per broker per second<i class="fas fa-external-link-square-alt ms-1"></i></a> and if the frequency is higher than the limit, that error is thrown. Note, while it&rsquo;s possible to avoid it by updating <code>reconnect.backoff.ms</code> to 1000, it is <a href=https://docs.aws.amazon.com/msk/latest/developerguide/msk-connect-workers.html target=_blank rel="noopener noreferrer">not allowed on MSK Connect<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><p>When it comes to inbound rules of the cluster security group, we need to configure that all inbound traffic is allowed from its own security group. This is because connectors on MSK Connect are deployed with the same security group of the MSK cluster, and they should have access to it. Also, we need to allow port 9098 from the security group of the VPN bastion host - 9098 is the port for establishing the initial connection to the cluster when IAM Authentication is used.</p><p>Finally, a cluster configuration is created manually as it&rsquo;s not supported by CloudFormation and its ARN and revision number are added as parameters. The configuration is shown below.</p><pre tabindex=0><code class=language-conf data-lang=conf>auto.create.topics.enable = true
delete.topic.enable = true
</code></pre><p>The CloudFormation template can be found in the project <a href=https://github.com/jaehyeon-kim/data-lake-demo/blob/main/infra/main/msk.yaml target=_blank rel="noopener noreferrer"><strong>GitHub repository</strong><i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><h4 id=msk-connect-role data-numberify>MSK Connect Role<a class="anchor ms-1" href=#msk-connect-role></a></h4><p>As we use IAM Authentication for access control, the connectors need to have permission on the cluster, topic and group. Also, the sink connector should have access to put output files to the S3 bucket. For simplicity, a single connector role is created for both source and sink connectors in the same template.</p><h2 id=cdc-development data-numberify>CDC Development<a class="anchor ms-1" href=#cdc-development></a></h2><p>In order to create a connector on MSK Connect, we need to create a custom plugin and the connector itself. A custom plugin is a set of JAR files containing the implementation of one or more connectors, transforms, or converters and installed on the workers of the connect cluster where the connector is running. Both the resources are not supported by CloudFormation and can be created on AWS Console or using AWS SDK.</p><h3 id=custom-plugins data-numberify>Custom Plugins<a class="anchor ms-1" href=#custom-plugins></a></h3><p>We need plugins for the Debezium source and S3 sink connectors. Plugin objects can be saved to S3 in either JAR or ZIP file format. We can download them from the relevant release/download pages of <a href=https://debezium.io/releases/1.7/ target=_blank rel="noopener noreferrer">Debezium<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href=https://github.com/lensesio/stream-reactor/releases/tag/3.0.0 target=_blank rel="noopener noreferrer">Lenses Stream Reactor<i class="fas fa-external-link-square-alt ms-1"></i></a>. Note to put contents at the root level of the zip archives. Once they are saved to S3, we can create them simply by specifying their S3 URIs.</p><h3 id=msk-connectors data-numberify>MSK Connectors<a class="anchor ms-1" href=#msk-connectors></a></h3><h4 id=source-connector data-numberify>Source Connector<a class="anchor ms-1" href=#source-connector></a></h4><p>_<a href=https://debezium.io/documentation/reference/stable/connectors/postgresql.html target=_blank rel="noopener noreferrer">Debezium&rsquo;s PostgreSQL connector<i class="fas fa-external-link-square-alt ms-1"></i></a> captures row-level changes in the schemas of a PostgreSQL database. PostgreSQL versions 9.6, 10, 11, 12 and 13 are supported. The first time it connects to a PostgreSQL server or cluster, the connector takes a consistent snapshot of all schemas. After that snapshot is complete, the connector continuously captures row-level changes that insert, update, and delete database content and that were committed to a PostgreSQL database. The connector generates data change event records and streams them to Kafka topics. For each table, the default behavior is that the connector streams all generated events to a separate Kafka topic for that table. Applications and services consume data change event records from that topic.</p><p>The connector has a number of connector properties including name, connector class, database connection details, key/value converter and so on - the full list of properties can be found in <a href=https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-connector-properties target=_blank rel="noopener noreferrer">this page<i class="fas fa-external-link-square-alt ms-1"></i></a>. The properties that need explanation are listed below.</p><ul><li><code>plugin.name</code> - Using the <a href=https://www.postgresql.org/docs/current/logicaldecoding-explanation.html target=_blank rel="noopener noreferrer">logical decoding<i class="fas fa-external-link-square-alt ms-1"></i></a> feature, an output plug-in enables clients to consume changes to the transaction log in a user-friendly manner. Debezium supports <code>decoderbufs</code>, <code>wal2json</code> and <code>pgoutput</code> plug-ins. Both <code>wal2json</code> and <code>pgoutput</code> are available in Amazon RDS for PostgreSQL and Amazon Aurora PostgreSQL. <code>decoderbufs</code> requires a separate installation, and it is excluded from the option. Among the 2 supported plug-ins, <code>pgoutput</code> is selected because it is the standard logical decoding output plug-in in PostgreSQL 10+ and <a href=https://debezium.io/blog/2020/02/25/lessons-learned-running-debezium-with-postgresql-on-rds/ target=_blank rel="noopener noreferrer">has better performance for large transactions<i class="fas fa-external-link-square-alt ms-1"></i></a>.</li><li><code>publication.name</code> - With the <code>pgoutput</code> plug-in, the Debezium connector creates a publication (if not exists) and sets <code>publication.autocreate.mode</code> to <em>all_tables</em>. It can cause an issue to update a record to a table that doesn&rsquo;t have the primary key or replica identity. We can set the value to <em>filtered</em> where the connector adjusts the applicable tables by other property values. Alternatively we can create a publication on our own and add the name to <em>publication.name</em> property. I find creating a publication explicitly is easier to maintain. Note a publication alone is not sufficient to handle the issue. All affected tables by the publication should have the primary key or replica identity. In our example, the _orders _and _order_details _tables should meet the condition. In short, creating an explicit publication can prevent the event generation process from interrupting other processes by limiting the scope of CDC event generation.</li><li><code>key.converter/value.converter</code> - Although <a href=https://debezium.io/documentation/reference/stable/configuration/avro.html target=_blank rel="noopener noreferrer">Avro serialization<i class="fas fa-external-link-square-alt ms-1"></i></a> is recommended, JSON is a format that can be generated without schema registry and can be read by DeltaStreamer.</li><li><code>transforms</code> - A Debezium event data has a complex structure that provides a wealth of information. It can be quite difficult to process such a structure using DeltaStreamer. Debezium&rsquo;s event flattening <a href=https://debezium.io/documentation/reference/stable/transformations/event-flattening.html target=_blank rel="noopener noreferrer">single message transformation (SMT)<i class="fas fa-external-link-square-alt ms-1"></i></a> is configured to flatten the output payload.</li></ul><p>Note once the connector is deployed, the CDC event records will be published to <code>msk.datalake.cdc_events</code> topic.</p><pre tabindex=0><code class=language-conf data-lang=conf># ./connector/msk/source-debezium.properties
connector.class=io.debezium.connector.postgresql.PostgresConnector
tasks.max=1
plugin.name=pgoutput
publication.name=cdc_publication
database.hostname=&lt;database-hostname-or-ip-address&gt;
database.port=5432
database.user=&lt;database-user&gt;
database.password=&lt;database-user-password&gt;
database.dbname=devdb
database.server.name=msk
schema.include=datalake
table.include.list=datalake.cdc_events
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
transforms=unwrap
transforms.unwrap.type=io.debezium.transforms.ExtractNewRecordState
transforms.unwrap.drop.tombstones=false
transforms.unwrap.delete.handling.mode=rewrite
transforms.unwrap.add.fields=op,db,table,schema,lsn,source.ts_ms
</code></pre><p>The connector can be created in multiple steps. The first step is to select the relevant custom plugin from the custom plugins list.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/connector-01.png loading=lazy width=1121 height=762></picture></p><p>In the second step, we can configure connector properties. Applicable properties are</p><ul><li>Connector name and description</li><li>Apache Kafka cluster (MSK or self-managed) with an authentication method</li><li>Connector configuration</li><li>Connector capacity - Autoscaled or Provisioned</li><li>Worker configuration</li><li>IAM role of the connector - it is created in the CloudFormation template</li></ul><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/connector-02-01.png loading=lazy width=1107 height=474></picture></p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/connector-02-02.png loading=lazy width=1110 height=639></picture></p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/connector-02-03.png loading=lazy width=1123 height=582></picture></p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/connector-02-04.png loading=lazy width=1110 height=688></picture></p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/connector-02-05.png loading=lazy width=1109 height=872></picture></p><p>In the third step, we configure cluster security. As we selected IAM Authentication, only TLS encryption is available.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/connector-03.png loading=lazy width=1123 height=683></picture></p><p>Finally, we can configure logging. A log group is created in the CloudFormation, and we can add its ARN.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/connector-04.png loading=lazy width=1124 height=603></picture></p><p>After reviewing, we can create the connector.</p><h4 id=sink-connector data-numberify>Sink Connector<a class="anchor ms-1" href=#sink-connector></a></h4><p><a href=https://lenses.io/blog/2020/11/new-kafka-to-S3-connector/ target=_blank rel="noopener noreferrer">Lenses S3 Connector<i class="fas fa-external-link-square-alt ms-1"></i></a> is a Kafka Connect sink connector for writing records from Kafka to AWS S3 Buckets. It extends the standard connect config adding a parameter for a SQL command (Lenses Kafka Connect Query Language or &ldquo;KCQL&rdquo;). This defines how to map data from the source (in this case Kafka) to the target (S3). Importantly, it also includes how data should be partitioned into S3, the bucket names and the serialization format (support includes JSON, Avro, Parquet, Text, CSV and binary).</p><p>I find the Lenses S3 connector is more straightforward to configure than the Confluent S3 sink connector for its <a href=https://docs.lenses.io/4.1/integrations/connectors/stream-reactor/sinks/s3sinkconnector/ target=_blank rel="noopener noreferrer">SQL-like syntax<i class="fas fa-external-link-square-alt ms-1"></i></a>. The KCQL configuration indicates that object files are set to be</p><ul><li>moved from a Kafka topic (<code>msk.datalake.cdc_events</code>) to an S3 bucket (<code>data-lake-demo-cevo</code>) with object prefix of _<code>cdc-events-local</code>,</li><li>partitioned by <em>customer_id</em> and <em>order_id</em> e.g. <code>customer_id=&lt;customer-id>/order_id=&lt;order-id></code>,</li><li>stored as the JSON format and,</li><li>flushed every 60 seconds or when there are 50 records.</li></ul><pre tabindex=0><code class=language-conf data-lang=conf># ./connector/msk/sink-s3-lenses.properties
connector.class=io.lenses.streamreactor.connect.aws.s3.sink.S3SinkConnector
tasks.max=1
connect.s3.kcql=INSERT INTO data-lake-demo-cevo:cdc-events SELECT * FROM msk.datalake.cdc_events PARTITIONBY customer_id,order_id STOREAS `json` WITH_FLUSH_INTERVAL = 60 WITH_FLUSH_COUNT = 50
aws.region=ap-southeast-2
aws.custom.endpoint=https://s3.ap-southeast-2.amazonaws.com/
topics=msk.datalake.cdc_events
key.converter.schemas.enable=false
schema.enable=false
errors.log.enable=true
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
</code></pre><p>We can create the sink connector on AWS Console using the same steps to the source connector.</p><h3 id=updateinsert-examples data-numberify>Update/Insert Examples<a class="anchor ms-1" href=#updateinsert-examples></a></h3><h4 id=kafka-ui data-numberify>Kafka UI<a class="anchor ms-1" href=#kafka-ui></a></h4><p>When we used the Confluent platform for local development in the previous post, we checked topics and messages on the control tower UI. For MSK, we can use <a href=https://github.com/provectus/kafka-ui target=_blank rel="noopener noreferrer">Kafka UI<i class="fas fa-external-link-square-alt ms-1"></i></a>. Below shows a docker-compose file for it. Note that the MSK cluster is secured by IAM Authentication so that _AWS_MSK_IAM _is specified as the SASL mechanism. Under the hood, it uses <a href=https://github.com/aws/aws-msk-iam-auth target=_blank rel="noopener noreferrer">Amazon MSK Library for AWS IAM<i class="fas fa-external-link-square-alt ms-1"></i></a> for authentication and AWS credentials are provided via volume mapping. Also don&rsquo;t forget to connect the VPN bastion host using the SoftEther VPN client program.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=ln> 1</span><span class=cl><span class=c># ./kafka-ui/docker-compose.yml</span><span class=w>
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=w></span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;2&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln> 3</span><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=w>  </span><span class=nt>kafka-ui</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>provectuslabs/kafka-ui</span><span class=w>
</span></span></span><span class=line><span class=ln> 6</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-ui</span><span class=w>
</span></span></span><span class=line><span class=ln> 7</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 8</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;8080:8080&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln> 9</span><span class=cl><span class=w>    </span><span class=c># restart: always</span><span class=w>
</span></span></span><span class=line><span class=ln>10</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>11</span><span class=cl><span class=w>      </span>- <span class=l>$HOME/.aws:/root/.aws</span><span class=w>
</span></span></span><span class=line><span class=ln>12</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>13</span><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_NAME</span><span class=p>:</span><span class=w> </span><span class=l>msk</span><span class=w>
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS</span><span class=p>:</span><span class=w> </span><span class=l>$BS_SERVERS</span><span class=w>
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;SASL_SSL&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>16</span><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;AWS_MSK_IAM&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>17</span><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SASL_CLIENT_CALLBACK_HANDLER_CLASS</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;software.amazon.msk.auth.iam.IAMClientCallbackHandler&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>18</span><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;software.amazon.msk.auth.iam.IAMLoginModule required;&#34;</span><span class=w>
</span></span></span></code></pre></div><p>Once started, the UI can be accessed via <code>http://localhost:8080</code>. We see that the CDC topic is found in the topics list. There are 829 messages in the topic, and it matches the number of records in the <code>cdc_events</code> table at creation.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/kafka-ui-01.png loading=lazy width=1390 height=414></picture></p><p>When we click the topic name, it shows further details of it. When clicking the messages tab, we can see individual messages within the topic. The UI also has some other options, and it can be convenient to manage topics and messages.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/kafka-ui-02.png loading=lazy width=1388 height=532></picture></p><p>The message records can be expanded, and we can check a message&rsquo;s key, content and headers. Also, we can either copy the value to clipboard or save as a file.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/kafka-ui-03.png loading=lazy width=1385 height=752></picture></p><h4 id=update-event data-numberify>Update Event<a class="anchor ms-1" href=#update-event></a></h4><p>The order 11077 initially didn&rsquo;t have the _shipped_date _value. When the value is updated later, a new output file will be generated with the updated value.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=ln>1</span><span class=cl><span class=k>BEGIN</span><span class=w> </span><span class=k>TRANSACTION</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=ln>2</span><span class=cl><span class=w>    </span><span class=k>UPDATE</span><span class=w> </span><span class=n>orders</span><span class=w>
</span></span></span><span class=line><span class=ln>3</span><span class=cl><span class=w>    </span><span class=k>SET</span><span class=w> </span><span class=n>shipped_date</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=s1>&#39;1998-06-15&#39;</span><span class=p>::</span><span class=nb>date</span><span class=w>
</span></span></span><span class=line><span class=ln>4</span><span class=cl><span class=w>    </span><span class=k>WHERE</span><span class=w> </span><span class=n>order_id</span><span class=w> </span><span class=o>=</span><span class=w> </span><span class=mi>11077</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=ln>5</span><span class=cl><span class=w></span><span class=k>COMMIT</span><span class=w> </span><span class=k>TRANSACTION</span><span class=p>;</span><span class=w> 
</span></span></span><span class=line><span class=ln>6</span><span class=cl><span class=w></span><span class=k>END</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p>In S3, we see 2 JSON objects are included in the output file for the order entry and the shipped_date value is updated as expected. Note that the <a href=https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-temporal-types target=_blank rel="noopener noreferrer">Debezium connector converts the DATE type to the INT32 type<i class="fas fa-external-link-square-alt ms-1"></i></a>, which represents the number of days since the epoch.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/output-file-update.png loading=lazy width=1126 height=552></picture></p><h4 id=insert-event data-numberify>Insert Event<a class="anchor ms-1" href=#insert-event></a></h4><p>When a new order is created, it&rsquo;ll insert a record to the _orders _table as well as one or more order items to the _order_details _table. Therefore, we expect multiple event records will be created when a new order is created. We can check it by inserting an order and related order details items.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sql data-lang=sql><span class=line><span class=ln>1</span><span class=cl><span class=k>BEGIN</span><span class=w> </span><span class=k>TRANSACTION</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=ln>2</span><span class=cl><span class=w>    </span><span class=k>INSERT</span><span class=w> </span><span class=k>INTO</span><span class=w> </span><span class=n>orders</span><span class=w> </span><span class=k>VALUES</span><span class=w> </span><span class=p>(</span><span class=mi>11075</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;RICSU&#39;</span><span class=p>,</span><span class=w> </span><span class=mi>8</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;1998-05-06&#39;</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;1998-06-03&#39;</span><span class=p>,</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>,</span><span class=w> </span><span class=mi>6</span><span class=p>.</span><span class=mi>19000006</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;Richter Supermarkt&#39;</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;Starenweg 5&#39;</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;Genève&#39;</span><span class=p>,</span><span class=w> </span><span class=k>NULL</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;1204&#39;</span><span class=p>,</span><span class=w> </span><span class=s1>&#39;Switzerland&#39;</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=ln>3</span><span class=cl><span class=w>    </span><span class=k>INSERT</span><span class=w> </span><span class=k>INTO</span><span class=w> </span><span class=n>order_details</span><span class=w> </span><span class=k>VALUES</span><span class=w> </span><span class=p>(</span><span class=mi>11075</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>,</span><span class=w> </span><span class=mi>19</span><span class=p>,</span><span class=w> </span><span class=mi>10</span><span class=p>,</span><span class=w> </span><span class=mi>0</span><span class=p>.</span><span class=mi>150000006</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=ln>4</span><span class=cl><span class=w>    </span><span class=k>INSERT</span><span class=w> </span><span class=k>INTO</span><span class=w> </span><span class=n>order_details</span><span class=w> </span><span class=k>VALUES</span><span class=w> </span><span class=p>(</span><span class=mi>11075</span><span class=p>,</span><span class=w> </span><span class=mi>46</span><span class=p>,</span><span class=w> </span><span class=mi>12</span><span class=p>,</span><span class=w> </span><span class=mi>30</span><span class=p>,</span><span class=w> </span><span class=mi>0</span><span class=p>.</span><span class=mi>150000006</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=ln>5</span><span class=cl><span class=w>    </span><span class=k>INSERT</span><span class=w> </span><span class=k>INTO</span><span class=w> </span><span class=n>order_details</span><span class=w> </span><span class=k>VALUES</span><span class=w> </span><span class=p>(</span><span class=mi>11075</span><span class=p>,</span><span class=w> </span><span class=mi>76</span><span class=p>,</span><span class=w> </span><span class=mi>18</span><span class=p>,</span><span class=w> </span><span class=mi>2</span><span class=p>,</span><span class=w> </span><span class=mi>0</span><span class=p>.</span><span class=mi>150000006</span><span class=p>);</span><span class=w>
</span></span></span><span class=line><span class=ln>6</span><span class=cl><span class=w></span><span class=k>COMMIT</span><span class=w> </span><span class=k>TRANSACTION</span><span class=p>;</span><span class=w> 
</span></span></span><span class=line><span class=ln>7</span><span class=cl><span class=w></span><span class=k>END</span><span class=p>;</span><span class=w>
</span></span></span></code></pre></div><p>We can see the output file includes 4 JSON objects where the first object has NULL _order_items _and _products _value. We can also see that those values are expanded gradually in subsequent event records</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2021-12-12-datalake-demo-part2/output-file-insert.png loading=lazy width=1127 height=580></picture></p><h2 id=conclusion data-numberify>Conclusion<a class="anchor ms-1" href=#conclusion></a></h2><p>We created a VPC that has private and public subnets in 2 availability zones in order to build and deploy the data lake solution on AWS. NAT instances are created to forward outbound traffic to the internet and a VPN bastion host is set up to facilitate deployment. An Aurora PostgreSQL cluster is deployed to host the source database and a Python command line app is used to create the database. To develop data ingestion using CDC, an MSK cluster is deployed and the Debezium source and Lenses S3 sink connectors are created on MSK Connect. We also confirmed the order creation and update events are captured as expected with the scenarios used by local development. Using CDC event output files in S3, we are able to build an Apache Hudi table on EMR and use it for ad-hoc queries and report/dashboard generation. It&rsquo;ll be covered in the next post.</p></div></div></div><div class=card-footer><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-down post-prev-icon me-1" data-fa-transform=rotate-90></i>
<a href=/blog/2021-12-05-datalake-demo-part1/>Data Lake Demo Using Change Data Capture (CDC) on AWS – Part 1 Local Development</a></div><div class="post-nav post-next"><a href=/blog/2021-12-19-datalake-demo-part3/>Data Lake Demo Using Change Data Capture (CDC) on AWS – Part 3 Implement Data Lake</a>
<i class="fas fa-fw fa-chevron-down post-next-icon ms-1" data-fa-transform=rotate-270></i></div></div></div></article><section class="related-posts row card component"><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Related Posts</h2></div><div class="card-body slide px-1"><div class="slide-inner row gx-0"><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2021-12-05-datalake-demo-part1/featured_hua25eccd3824300d3b1ed87f56797248c_164526_500x0_resize_box_3.png media="(max-width: 576px)" height=229 width=500><img class=img-fluid height=83 width=180 alt=featured.png src=/blog/2021-12-05-datalake-demo-part1/featured_hua25eccd3824300d3b1ed87f56797248c_164526_180x0_resize_box_3.png data-src=/blog/2021-12-05-datalake-demo-part1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2021-12-05-datalake-demo-part1/>Data Lake Demo Using Change Data Capture (CDC) on AWS – Part 1 Local Development</a><div class="post-meta mb-0">December 5, 2021</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2021-11-14-glue-3-local-development/featured_hu689859cb443a98b1c98384fedaa00395_30923_500x0_resize_box_3.png media="(max-width: 576px)" height=296 width=500><img class=img-fluid height=107 width=180 alt=featured.png src=/blog/2021-11-14-glue-3-local-development/featured_hu689859cb443a98b1c98384fedaa00395_30923_180x0_resize_box_3.png data-src=/blog/2021-11-14-glue-3-local-development/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2021-11-14-glue-3-local-development/>Local Development of AWS Glue 3.0 and Later</a><div class="post-meta mb-0">November 14, 2021</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2021-08-20-glue-local-development/featured_hu248b4052e45f408d4fe80445a9d59f15_19535_500x0_resize_box_3.png media="(max-width: 576px)" height=141 width=500><img class=img-fluid height=51 width=180 alt=featured.png src=/blog/2021-08-20-glue-local-development/featured_hu248b4052e45f408d4fe80445a9d59f15_19535_180x0_resize_box_3.png data-src=/blog/2021-08-20-glue-local-development/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2021-08-20-glue-local-development/>AWS Glue Local Development With Docker and Visual Studio Code</a><div class="post-meta mb-0">August 20, 2021</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2020-04-13-airflow-lambda-operator/featured_hu1fb366ed8468cd95c289e8b53adf2b4c_44994_500x0_resize_box_3.png media="(max-width: 576px)" height=144 width=500><img class=img-fluid height=52 width=180 alt=featured.png src=/blog/2020-04-13-airflow-lambda-operator/featured_hu1fb366ed8468cd95c289e8b53adf2b4c_44994_180x0_resize_box_3.png data-src=/blog/2020-04-13-airflow-lambda-operator/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2020-04-13-airflow-lambda-operator/>Thoughts on Apache Airflow AWS Lambda Operator</a><div class="post-meta mb-0">April 13, 2020</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2019-07-20-aws-localstack/featured_hu76363859e2b475a85e538ad8f869426e_164886_500x0_resize_box_3.png media="(max-width: 576px)" height=300 width=500><img class=img-fluid height=108 width=180 alt=featured.png src=/blog/2019-07-20-aws-localstack/featured_hu76363859e2b475a85e538ad8f869426e_164886_180x0_resize_box_3.png data-src=/blog/2019-07-20-aws-localstack/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2019-07-20-aws-localstack/>AWS Local Development With LocalStack</a><div class="post-meta mb-0">July 20, 2019</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2019-11-29-traefik-example/featured_huf02131f0aec4656166a63d0e0c90fae1_139790_500x0_resize_box_3.png media="(max-width: 576px)" height=260 width=500><img class=img-fluid height=93 width=180 alt=featured.png src=/blog/2019-11-29-traefik-example/featured_huf02131f0aec4656166a63d0e0c90fae1_139790_180x0_resize_box_3.png data-src=/blog/2019-11-29-traefik-example/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2019-11-29-traefik-example/>Dynamic Routing and Centralized Auth With Traefik, Python and R Example</a><div class="post-meta mb-0">November 29, 2019</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2019-11-15-task-queue/featured_hu7f23bb50744730950217f66f197f569b_51615_500x0_resize_box_3.png media="(max-width: 576px)" height=272 width=500><img class=img-fluid height=98 width=180 alt=featured.png src=/blog/2019-11-15-task-queue/featured_hu7f23bb50744730950217f66f197f569b_51615_180x0_resize_box_3.png data-src=/blog/2019-11-15-task-queue/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2019-11-15-task-queue/>Distributed Task Queue With Python and R Example</a><div class="post-meta mb-0">November 15, 2019</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2019-11-01-linux-on-windows/featured_huc10c59749850e2c6e75df8112745c889_187978_500x0_resize_box_3.png media="(max-width: 576px)" height=271 width=500><img class=img-fluid height=98 width=180 alt=featured.png src=/blog/2019-11-01-linux-on-windows/featured_huc10c59749850e2c6e75df8112745c889_187978_180x0_resize_box_3.png data-src=/blog/2019-11-01-linux-on-windows/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2019-11-01-linux-on-windows/>Linux Dev Environment on Windows</a><div class="post-meta mb-0">November 1, 2019</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2019-07-19-cronicle-multi-server-setup/featured_huf31defd43c31d7741cd0651b807bf58f_64396_500x0_resize_box_3.png media="(max-width: 576px)" height=305 width=500><img class=img-fluid height=110 width=180 alt=featured.png src=/blog/2019-07-19-cronicle-multi-server-setup/featured_huf31defd43c31d7741cd0651b807bf58f_64396_180x0_resize_box_3.png data-src=/blog/2019-07-19-cronicle-multi-server-setup/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2019-07-19-cronicle-multi-server-setup/>Cronicle Multi Server Setup</a><div class="post-meta mb-0">July 19, 2019</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2017-04-17-serverless-data-product-4/featured_huf7a77a5394e53f84146299d65bd38b83_225463_500x0_resize_box_3.png media="(max-width: 576px)" height=282 width=500><img class=img-fluid height=101 width=180 alt=featured.png src=/blog/2017-04-17-serverless-data-product-4/featured_huf7a77a5394e53f84146299d65bd38b83_225463_180x0_resize_box_3.png data-src=/blog/2017-04-17-serverless-data-product-4/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2017-04-17-serverless-data-product-4/>Serverless Data Product POC Backend Part IV - Serving R ML Model via S3</a><div class="post-meta mb-0">April 17, 2017</div></div></div></div><button class=slide-control-left>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i>
<span class=visually-hidden>Left</span>
</button>
<button class=slide-control-right>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-270></i>
<span class=visually-hidden>Right</span></button></div></section><div class="card component row post-comments" id=post-comments><div class=card-header><h2 class="card-title my-2 fs-4 text-surface">Comments</h2></div><div class=card-body><div class=giscus></div></div></div></div></div><aside class="col-xxl-4 sidebar d-flex"><div class="container d-flex flex-column"><div class="accordion profile"><div class="accordion-item card row text-center component"><div class="accordion-header card-header border-0" id=profile-header><a class="accordion-button d-lg-none mb-2 shadow-none p-0 bg-transparent text-surface" role=button data-bs-toggle=collapse href=#profile aria-expanded=true aria-controls=profile>Profile</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=profile aria-labelledby=profile-header><div class="col-12 d-flex align-items-center justify-content-center"><picture><img class="profile-avatar rounded-circle" alt="Jaehyeon Kim" src=https://jaehyeon.me/images/profile.png loading=lazy data-viewer-invisible width=200 height=200></picture></div><div class="col-12 profile-meta"><div class="profile-name fw-fold fs-lg">Jaehyeon Kim</div><div class=profile-bio>Consultant at Cevo 🇦🇺 ☁ AWS Community Builder 💡 Blogger ⚡ Stateful Stream Processing Enthusiast</div></div><nav class="social-links nav justify-content-center mt-1 justify-content-around"><a class="nav-link social-link" href=mailto:dottami@gmail.com title=Email><i class="fas fa-fw fa-2x fa-envelope" style=color:#0963ac></i>
</a><a class="nav-link social-link" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fa-2x fab fa-github"></i>
</a><a class="nav-link social-link" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fa-2x fab fa-linkedin-in" style=color:#0a66c2></i>
</a><a class="nav-link social-link" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fa-2x fab fa-paypal"></i></a></nav></div></div></div><div class="accordion taxonomies-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#taxonomies-toggle aria-expanded=true aria-controls=taxonomies-toggle>Taxonomies</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=taxonomies-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=taxonomyCategoriesTab data-bs-toggle=tab data-bs-target=#taxonomyCategories type=button role=tab aria-controls=taxonomyCategories aria-selected=true>
Categories</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyTagsTab data-bs-toggle=tab data-bs-target=#taxonomyTags type=button role=tab aria-controls=taxonomyTags aria-selected=true>
Tags</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomySeriesTab data-bs-toggle=tab data-bs-target=#taxonomySeries type=button role=tab aria-controls=taxonomySeries aria-selected=true>
Series</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyArchivesTab data-bs-toggle=tab data-bs-target=#taxonomyArchives type=button role=tab aria-controls=taxonomyArchives aria-selected=true>
Archives</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=taxonomyCategories role=tabpanel aria-labelledby=taxonomyCategoriesTab tabindex=0><a href=/categories/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">20</span>
</a><a href=/categories/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/categories/data-product/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Product">Data Product
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/categories/data-engineering/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Engineering">Data Engineering
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/categories/machine-learning/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Machine Learning">Machine Learning
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/categories/data-build-tool-dbt/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Build Tool (DBT)">Data Build Tool (DBT)
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/categories/data-streaming/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Streaming">Data Streaming
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/categories/development/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Development>Development
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/categories/general/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=General>General
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/categories/apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Flink">Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/categories/change-data-capture-cdc/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Change Data Capture (CDC)">Change Data Capture (CDC)
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/categories/engineering/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Engineering>Engineering
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/categories/apache-airflow/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Airflow">Apache Airflow
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/categories/stateful-stream-processing/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Stateful Stream Processing">Stateful Stream Processing
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyTags role=tabpanel aria-labelledby=taxonomyTagsTab tabindex=0><a href=/tags/docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Docker>Docker
<span class="badge badge-sm text-secondary bg-white ms-1">36</span>
</a><a href=/tags/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">36</span>
</a><a href=/tags/aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=AWS>AWS
<span class="badge badge-sm text-secondary bg-white ms-1">34</span>
</a><a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">33</span>
</a><a href=/tags/docker-compose/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Docker Compose">Docker Compose
<span class="badge badge-sm text-secondary bg-white ms-1">31</span>
</a><a href=/tags/python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Python>Python
<span class="badge badge-sm text-secondary bg-white ms-1">31</span>
</a><a href=/tags/apache-spark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Spark">Apache Spark
<span class="badge badge-sm text-secondary bg-white ms-1">16</span>
</a><a href=/tags/amazon-msk/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK">Amazon MSK
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/tags/kafka-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Kafka Connect">Kafka Connect
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/tags/terraform/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Terraform>Terraform
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/tags/aws-lambda/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Lambda">AWS Lambda
<span class="badge badge-sm text-secondary bg-white ms-1">12</span>
</a><a href=/tags/amazon-emr/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EMR">Amazon EMR
<span class="badge badge-sm text-secondary bg-white ms-1">10</span>
</a><a href=/tags/apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Flink">Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/tags/pyflink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Pyflink>Pyflink
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/amazon-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK Connect">Amazon MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/data-build-tool-dbt/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Data Build Tool (DBT)">Data Build Tool (DBT)
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Kubernetes>Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/pyspark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PySpark>PySpark
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/rserve/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Rserve>Rserve
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/visual-studio-code/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Visual Studio Code">Visual Studio Code
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/amazon-api-gateway/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon API Gateway">Amazon API Gateway
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-dynamodb/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon DynamoDB">Amazon DynamoDB
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-managed-service-for-apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Managed Service for Apache Flink">Amazon Managed Service for Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-quicksight/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon QuickSight">Amazon QuickSight
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/security/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Security>Security
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/shiny/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Shiny>Shiny
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-eks/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EKS">Amazon EKS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/apache-hudi/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Hudi">Apache Hudi
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/aws-glue/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Glue">AWS Glue
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/aws-sam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS SAM">AWS SAM
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Change Data Capture">Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/data-lake/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Data Lake">Data Lake
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/fastapi/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=FastAPI>FastAPI
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/glue-schema-registry/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Glue Schema Registry">Glue Schema Registry
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="MSK Connect">MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/sparkr/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=SparkR>SparkR
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/amazon-athena/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Athena">Amazon Athena
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/tags/amazon-eventbridge/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EventBridge">Amazon EventBridge
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/tags/amazon-redshift/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Redshift">Amazon Redshift
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/tags/apache-airflow/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Airflow">Apache Airflow
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=https://jaehyeon.me/tags class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=ALL>ALL
<span class="badge badge-sm text-secondary bg-white ms-1">89</span></a></div><div class=tab-pane id=taxonomySeries role=tabpanel aria-labelledby=taxonomySeriesTab tabindex=0><a href=/series/kafka-development-with-docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development with Docker">Kafka Development with Docker
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/series/tree-based-methods-in-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Tree based methods in R">Tree based methods in R
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/series/dbt-for-effective-data-transformation-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT for Effective Data Transformation on AWS">DBT for Effective Data Transformation on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/kafka-connect-for-aws-services-integration/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Connect for AWS Services Integration">Kafka Connect for AWS Services Integration
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/serverless-data-product/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Serverless Data Product">Serverless Data Product
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/series/data-lake-demo-using-change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Data Lake Demo Using Change Data Capture">Data Lake Demo Using Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/getting-started-with-pyflink-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Getting Started with Pyflink on AWS">Getting Started with Pyflink on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/parallel-processing-on-single-machine/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Parallel processing on single machine">Parallel processing on single machine
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/api-development-with-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="API development with R">API development with R
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/integrate-schema-registry-with-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Integrate Schema Registry with MSK Connect">Integrate Schema Registry with MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/kafka-flink-and-dynamodb-for-real-time-fraud-detection/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka, Flink and DynamoDB for Real Time Fraud Detection">Kafka, Flink and DynamoDB for Real Time Fraud Detection
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/simplify-streaming-ingestion-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Simplify Streaming Ingestion on AWS">Simplify Streaming Ingestion on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a></div><div class=tab-pane id=taxonomyArchives role=tabpanel aria-labelledby=taxonomyArchivesTab tabindex=0><a href=/archives/2023/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2023>2023 <span class="badge badge-sm text-secondary bg-white ms-1">30</span>
</a><a href=/archives/2022/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2022>2022 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2021/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2021>2021 <span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/archives/2020/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2020>2020 <span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/archives/2019/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2019>2019 <span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/archives/2018/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2018>2018 <span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/archives/2017/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2017>2017 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2016/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2016>2016 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2015/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2015>2015 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2014/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2014>2014 <span class="badge badge-sm text-secondary bg-white ms-1">5</span></a></div></div></div></div></div><div class="accordion posts-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#posts-toggle aria-expanded=true aria-controls=posts-toggle>Posts</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=posts-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=featured-posts-tab data-bs-toggle=tab data-bs-target=#featured-posts type=button role=tab aria-controls=featured-posts aria-selected=true>
Featured Posts</button></li><li class=nav-item role=presentation><button class=nav-link id=recent-posts-tab data-bs-toggle=tab data-bs-target=#recent-posts type=button role=tab aria-controls=recent-posts aria-selected=true>
Recent Posts</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=featured-posts role=tabpanel aria-labelledby=featured-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_500x0_resize_box_3.png media="(max-width: 576px)" height=241 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_180x0_resize_box_3.png data-src=/blog/2023-10-19-build-pyflink-apps/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-10-19-build-pyflink-apps/>Building Apache Flink Applications in Python</a><div class="post-meta mt-2"><span class=post-date>October 19, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured_hu6470c0101df93a224de5159e363e8665_55960_500x0_resize_box_3.png media="(max-width: 576px)" height=289 width=500><img class=img-fluid height=104 width=180 alt=featured.png src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured_hu6470c0101df93a224de5159e363e8665_55960_180x0_resize_box_3.png data-src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/>Getting Started With Pyflink on AWS - Part 1 Local Flink and Local Kafka</a><div class="post-meta mt-2"><span class=post-date>August 17, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-08-10-fraud-detection-part-1/featured_hu0e6881a0b5c39bbfe5c0b72138bca889_72929_500x0_resize_box_3.png media="(max-width: 576px)" height=213 width=500><img class=img-fluid height=77 width=180 alt=featured.png src=/blog/2023-08-10-fraud-detection-part-1/featured_hu0e6881a0b5c39bbfe5c0b72138bca889_72929_180x0_resize_box_3.png data-src=/blog/2023-08-10-fraud-detection-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-08-10-fraud-detection-part-1/>Kafka, Flink and DynamoDB for Real Time Fraud Detection - Part 1 Local Development</a><div class="post-meta mt-2"><span class=post-date>August 10, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-05-04-kafka-development-with-docker-part-1/featured_hu351ee075bb995e8f69034dc54fe8364b_98355_500x0_resize_box_3.png media="(max-width: 576px)" height=322 width=500><img class=img-fluid height=116 width=180 alt=featured.png src=/blog/2023-05-04-kafka-development-with-docker-part-1/featured_hu351ee075bb995e8f69034dc54fe8364b_98355_180x0_resize_box_3.png data-src=/blog/2023-05-04-kafka-development-with-docker-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-05-04-kafka-development-with-docker-part-1/>Kafka Development With Docker - Part 1 Cluster Setup</a><div class="post-meta mt-2"><span class=post-date>May 4, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-05-03-kafka-connect-for-aws-part-1/featured_hu86011ae8fa75383c328c2b5f29f8b87d_22272_500x0_resize_box_3.png media="(max-width: 576px)" height=169 width=500><img class=img-fluid height=61 width=180 alt=featured.png src=/blog/2023-05-03-kafka-connect-for-aws-part-1/featured_hu86011ae8fa75383c328c2b5f29f8b87d_22272_180x0_resize_box_3.png data-src=/blog/2023-05-03-kafka-connect-for-aws-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-05-03-kafka-connect-for-aws-part-1/>Kafka Connect for AWS Services Integration - Part 1 Introduction</a><div class="post-meta mt-2"><span class=post-date>May 3, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_500x0_resize_box_3.png media="(max-width: 576px)" height=305 width=500><img class=img-fluid height=110 width=180 alt=featured.png src=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_180x0_resize_box_3.png data-src=/blog/2023-04-12-integrate-glue-schema-registry/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-04-12-integrate-glue-schema-registry/>Integrate Glue Schema Registry With Your Python Kafka App</a><div class="post-meta mt-2"><span class=post-date>April 12, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-02-08-simplify-streaming-ingestion-redshift/featured_hu77abd5c8ed84cebc51bde5ecaefc7320_32864_500x0_resize_box_3.png media="(max-width: 576px)" height=239 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2023-02-08-simplify-streaming-ingestion-redshift/featured_hu77abd5c8ed84cebc51bde5ecaefc7320_32864_180x0_resize_box_3.png data-src=/blog/2023-02-08-simplify-streaming-ingestion-redshift/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-02-08-simplify-streaming-ingestion-redshift/>Simplify Streaming Ingestion on AWS – Part 1 MSK and Redshift</a><div class="post-meta mt-2"><span class=post-date>February 8, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-09-28-dbt-on-aws-part-1-redshift/featured_hu35d67be5daab492ffba00e48de3bbd29_97234_500x0_resize_box_3.png media="(max-width: 576px)" height=244 width=500><img class=img-fluid height=88 width=180 alt=featured.png src=/blog/2022-09-28-dbt-on-aws-part-1-redshift/featured_hu35d67be5daab492ffba00e48de3bbd29_97234_180x0_resize_box_3.png data-src=/blog/2022-09-28-dbt-on-aws-part-1-redshift/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-09-28-dbt-on-aws-part-1-redshift/>Data Build Tool (Dbt) for Effective Data Transformation on AWS – Part 1 Redshift</a><div class="post-meta mt-2"><span class=post-date>September 28, 2022</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-08-26-emr-on-eks-with-terraform/featured_hu0db6c869a471dd7000f2d35dcf0e8ab0_67936_500x0_resize_box_3.png media="(max-width: 576px)" height=186 width=500><img class=img-fluid height=67 width=180 alt=featured.png src=/blog/2022-08-26-emr-on-eks-with-terraform/featured_hu0db6c869a471dd7000f2d35dcf0e8ab0_67936_180x0_resize_box_3.png data-src=/blog/2022-08-26-emr-on-eks-with-terraform/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-08-26-emr-on-eks-with-terraform/>Manage EMR on EKS With Terraform</a><div class="post-meta mt-2"><span class=post-date>August 26, 2022</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-07-18-sam-for-data-professionals/featured_hu896f95b0db9041cf59826714af2f73f7_22838_500x0_resize_box_3.png media="(max-width: 576px)" height=194 width=500><img class=img-fluid height=70 width=180 alt=featured.png src=/blog/2022-07-18-sam-for-data-professionals/featured_hu896f95b0db9041cf59826714af2f73f7_22838_180x0_resize_box_3.png data-src=/blog/2022-07-18-sam-for-data-professionals/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-07-18-sam-for-data-professionals/>Serverless Application Model (SAM) for Data Professionals</a><div class="post-meta mt-2"><span class=post-date>July 18, 2022</span></div></div></div></li></ul></div><div class=tab-pane id=recent-posts role=tabpanel aria-labelledby=recent-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-11-02-stateful-stream-processing/featured_hua1cae1e37e5d79dce66730fc758b0280_244920_500x0_resize_box_3.png media="(max-width: 576px)" height=250 width=500><img class=img-fluid height=90 width=180 alt=featured.png src=/blog/2023-11-02-stateful-stream-processing/featured_hua1cae1e37e5d79dce66730fc758b0280_244920_180x0_resize_box_3.png data-src=/blog/2023-11-02-stateful-stream-processing/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-11-02-stateful-stream-processing/>Benefits and Opportunities of Stateful Stream Processing</a><div class="post-meta mt-2"><span class=post-date>November 2, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-10-30-kafka-connect-for-aws-part-5/featured_hue6ace805e51d39c2a79d7a3e7795d500_85575_500x0_resize_box_3.png media="(max-width: 576px)" height=440 width=500><img class=img-fluid height=158 width=180 alt=featured.png src=/blog/2023-10-30-kafka-connect-for-aws-part-5/featured_hue6ace805e51d39c2a79d7a3e7795d500_85575_180x0_resize_box_3.png data-src=/blog/2023-10-30-kafka-connect-for-aws-part-5/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-10-30-kafka-connect-for-aws-part-5/>Kafka Connect for AWS Services Integration - Part 5 Deploy Aiven OpenSearch Sink Connector</a><div class="post-meta mt-2"><span class=post-date>October 30, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-10-23-kafka-connect-for-aws-part-4/featured_hu8acda52fcdf23bd4db3e9dcabda233b7_61820_500x0_resize_box_3.png media="(max-width: 576px)" height=288 width=500><img class=img-fluid height=104 width=180 alt=featured.png src=/blog/2023-10-23-kafka-connect-for-aws-part-4/featured_hu8acda52fcdf23bd4db3e9dcabda233b7_61820_180x0_resize_box_3.png data-src=/blog/2023-10-23-kafka-connect-for-aws-part-4/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-10-23-kafka-connect-for-aws-part-4/>Kafka Connect for AWS Services Integration - Part 4 Develop Aiven OpenSearch Sink Connector</a><div class="post-meta mt-2"><span class=post-date>October 23, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_500x0_resize_box_3.png media="(max-width: 576px)" height=241 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_180x0_resize_box_3.png data-src=/blog/2023-10-19-build-pyflink-apps/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-10-19-build-pyflink-apps/>Building Apache Flink Applications in Python</a><div class="post-meta mt-2"><span class=post-date>October 19, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-10-12-how-i-prepared-for-ckad/featured_hu6266fa892d616d56ee740677f3759115_5945_500x0_resize_box_3.png media="(max-width: 576px)" height=489 width=500><img class=img-fluid height=176 width=180 alt=featured.png src=/blog/2023-10-12-how-i-prepared-for-ckad/featured_hu6266fa892d616d56ee740677f3759115_5945_180x0_resize_box_3.png data-src=/blog/2023-10-12-how-i-prepared-for-ckad/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-10-12-how-i-prepared-for-ckad/>How I Prepared for Certified Kubernetes Application Developer (CKAD)</a><div class="post-meta mt-2"><span class=post-date>October 12, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-09-14-fraud-detection-part-2/featured_hu6e12c35fe727128749446c930c7ac3f6_66221_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2023-09-14-fraud-detection-part-2/featured_hu6e12c35fe727128749446c930c7ac3f6_66221_180x0_resize_box_3.png data-src=/blog/2023-09-14-fraud-detection-part-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-09-14-fraud-detection-part-2/>Kafka, Flink and DynamoDB for Real Time Fraud Detection - Part 2 Deployment via AWS Managed Flink</a><div class="post-meta mt-2"><span class=post-date>September 14, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/featured_hue908d327a4e776f04c90ce3d9151d268_74618_500x0_resize_box_3.png media="(max-width: 576px)" height=256 width=500><img class=img-fluid height=92 width=180 alt=featured.png src=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/featured_hue908d327a4e776f04c90ce3d9151d268_74618_180x0_resize_box_3.png data-src=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/>Getting Started With Pyflink on AWS - Part 3 AWS Managed Flink and MSK</a><div class="post-meta mt-2"><span class=post-date>September 4, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2/featured_huff907a4f1fb46be4b7ff165486006a38_64005_500x0_resize_box_3.png media="(max-width: 576px)" height=328 width=500><img class=img-fluid height=118 width=180 alt=featured.png src=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2/featured_huff907a4f1fb46be4b7ff165486006a38_64005_180x0_resize_box_3.png data-src=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-08-28-getting-started-with-pyflink-on-aws-part-2/>Getting Started With Pyflink on AWS - Part 2 Local Flink and MSK</a><div class="post-meta mt-2"><span class=post-date>August 28, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured_hu6470c0101df93a224de5159e363e8665_55960_500x0_resize_box_3.png media="(max-width: 576px)" height=289 width=500><img class=img-fluid height=104 width=180 alt=featured.png src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured_hu6470c0101df93a224de5159e363e8665_55960_180x0_resize_box_3.png data-src=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-08-17-getting-started-with-pyflink-on-aws-part-1/>Getting Started With Pyflink on AWS - Part 1 Local Flink and Local Kafka</a><div class="post-meta mt-2"><span class=post-date>August 17, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-08-10-fraud-detection-part-1/featured_hu0e6881a0b5c39bbfe5c0b72138bca889_72929_500x0_resize_box_3.png media="(max-width: 576px)" height=213 width=500><img class=img-fluid height=77 width=180 alt=featured.png src=/blog/2023-08-10-fraud-detection-part-1/featured_hu0e6881a0b5c39bbfe5c0b72138bca889_72929_180x0_resize_box_3.png data-src=/blog/2023-08-10-fraud-detection-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-08-10-fraud-detection-part-1/>Kafka, Flink and DynamoDB for Real Time Fraud Detection - Part 1 Local Development</a><div class="post-meta mt-2"><span class=post-date>August 10, 2023</span></div></div></div></li></ul></div></div></div></div></div></div></aside></div></main><footer class="footer mt-auto py-3 text-center container"><div class="offcanvas offcanvas-bottom h-auto" tabindex=-1 id=offcanvasActionsPanel aria-labelledby=offcanvasActionsPanelLabel><div class=offcanvas-header><div class="offcanvas-title h5" id=offcanvasActionsPanelLabel><i class="fas fa-fw fa-th-large me-1"></i>
Actions</div><button type=button class="btn-close ms-auto" data-bs-dismiss=offcanvas data-bs-target=offcanvasActionsPanel aria-label=Close></button></div><div class="offcanvas-body mt-2"><div class="actions d-flex overflow-auto align-items-center"><a role=button class="action action-go-back d-flex flex-column align-items-center me-3" href="javascript: window.history.back();"><span class="action-icon mb-2"><i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i></span> Go back
</a><a role=button class="action action-reload-page d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-redo-alt"></i></span> Reload
</a><a role=button class="action action-copy-url d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-link"></i></span> Copy URL</a></div></div></div><div class="row text-center"><div class="col-12 mt-2"><p class=mb-2>Jaehyeon Kim</p><p class="text-secondary mb-2"><small>Consultant at Cevo 🇦🇺 ☁ AWS Community Builder 💡 Blogger ⚡ Stateful Stream Processing Enthusiast</small></p><div class="copyright mb-2 text-secondary"><small>Copyright © 2023-2023 Jaehyeon Kim. All Rights Reserved.</small></div><nav class="social-links nav justify-content-center mb-2 mt-3"><a class="nav-link social-link p-0 me-1 mb-2" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-2x fa-rss" style=color:#ea6221></i></a></nav></div><div class="col-12 col-lg-8 offset-0 offset-lg-1"></div></div></footer><script data-precache src=/assets/main/bundle.min.494c41d6d504e4b36691cd90547b0ec9ab04d91666b603c73106a6cde8dcf809.js integrity="sha256-SUxB1tUE5LNmkc2QVHsOyasE2RZmtgPHMQamzejc+Ak=" crossorigin=anonymous async></script><script data-precache src=/assets/icons/bundle.min.4f30d5267a9f2f9d45ed93969d45ec626100a969a8b91f71f753315a261e9034.js integrity="sha256-TzDVJnqfL51F7ZOWnUXsYmEAqWmouR9x91MxWiYekDQ=" crossorigin=anonymous defer></script><script data-precache src=/assets/viewer/bundle.min.9e1c61429fe04f1983132399600e05243c275f13b600ef5c85942a4785b41a21.js integrity="sha256-nhxhQp/gTxmDEyOZYA4FJDwnXxO2AO9chZQqR4W0GiE=" crossorigin=anonymous defer></script><script data-precache defer src=/assets/katex/bundle.min.165097cfde4cb260bd27fd3d8d27f2307932d9e98bf0e2b98476cc156a4806fd.js integrity="sha256-FlCXz95MsmC9J/09jSfyMHky2emL8OK5hHbMFWpIBv0=" crossorigin=anonymous></script><script data-precache defer src=/assets/mermaid/bundle.min.cabfb769ed662df7a4b325255841a54c3547f3b4b606cf51f6b45f6c3af2b9f1.js integrity="sha256-yr+3ae1mLfeksyUlWEGlTDVH87S2Bs9R9rRfbDryufE=" crossorigin=anonymous></script><script src=/js/sw-register.js defer></script><script src=https://giscus.app/client.js data-repo=jaehyeon-kim/jaehyeon-kim.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkyNjgwMjU0NQ==" data-category data-category-id=DIC_kwDOAZj5cc4CV2fp data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous defer></script></body></html>