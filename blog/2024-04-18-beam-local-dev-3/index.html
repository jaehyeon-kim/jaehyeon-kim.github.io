<!doctype html><html class=position-relative itemscope itemtype=https://schema.org/WebPage lang=en data-bs-theme=light data-palette=blue-gray><head><script src=/assets/init/bundle.min.a17e164974693b81cda45a486ffbd5320efd6516e5c4059f032185e39c4ddac9.js integrity="sha256-oX4WSXRpO4HNpFpIb/vVMg79ZRblxAWfAyGF45xN2sk=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Apache Beam Local Development with Python - Part 3 Flink Runner - Jaehyeon Kim</title>
<link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_16x16_resize_q75_h2_box_2.webp sizes=16x16 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_32x32_resize_q75_h2_box_2.webp sizes=32x32 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_150x150_resize_q75_h2_box_2.webp sizes=150x150 type=image/webp><link rel=apple-touch-icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_180x180_resize_q75_h2_box_2.webp sizes=180x180 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_192x192_resize_q75_h2_box_2.webp sizes=192x192 type=image/webp><link rel=mask-icon href=/safari-pinned-tab.svg color=#6f42c1><meta name=keywords content="Analytics,Real-time Analytics,Data Engineering,Data Streaming,Architecture"><meta name=description content="Beam pipelines are portable between batch and streaming semantics but not every Runner is equally capable. The Apache Flink Runner supports Python, and it has good features that allow us to develop streaming pipelines effectively. We first discuss the portability layer of Apache Beam as it helps understand (1) how a pipeline developed by the Python SDK can be executed in the Flink Runner that only understands Java JAR and (2) how multiple SDKs can be used in a single pipeline. Then we move on to how to manage local Flink and Kafka clusters using bash scripts. Finally, we end up illustrating a simple streaming pipeline, which reads and writes website visit logs from and to Kafka topics."><meta name=robots content="index, follow"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jaehyeon.me/blog/2024-04-18-beam-local-dev-3/featured.png"><meta name=twitter:title content="Apache Beam Local Development with Python - Part 3 Flink Runner"><meta name=twitter:description content="Beam pipelines are portable between batch and streaming semantics but not every Runner is equally capable. The Apache Flink Runner supports Python, and it has good features that allow us to develop streaming pipelines effectively. We first discuss the portability layer of Apache Beam as it helps understand (1) how a pipeline developed by the Python SDK can be executed in the Flink Runner that only understands Java JAR and (2) how multiple SDKs can be used in a single pipeline. Then we move on to how to manage local Flink and Kafka clusters using bash scripts. Finally, we end up illustrating a simple streaming pipeline, which reads and writes website visit logs from and to Kafka topics."><meta property="og:title" content="Apache Beam Local Development with Python - Part 3 Flink Runner"><meta property="og:description" content="Beam pipelines are portable between batch and streaming semantics but not every Runner is equally capable. The Apache Flink Runner supports Python, and it has good features that allow us to develop streaming pipelines effectively. We first discuss the portability layer of Apache Beam as it helps understand (1) how a pipeline developed by the Python SDK can be executed in the Flink Runner that only understands Java JAR and (2) how multiple SDKs can be used in a single pipeline. Then we move on to how to manage local Flink and Kafka clusters using bash scripts. Finally, we end up illustrating a simple streaming pipeline, which reads and writes website visit logs from and to Kafka topics."><meta property="og:type" content="article"><meta property="og:url" content="https://jaehyeon.me/blog/2024-04-18-beam-local-dev-3/"><meta property="og:image" content="https://jaehyeon.me/blog/2024-04-18-beam-local-dev-3/featured.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2024-04-18T00:00:00+00:00"><meta property="article:modified_time" content="2024-06-04T20:11:39+10:00"><meta itemprop=name content="Apache Beam Local Development with Python - Part 3 Flink Runner"><meta itemprop=description content="Beam pipelines are portable between batch and streaming semantics but not every Runner is equally capable. The Apache Flink Runner supports Python, and it has good features that allow us to develop streaming pipelines effectively. We first discuss the portability layer of Apache Beam as it helps understand (1) how a pipeline developed by the Python SDK can be executed in the Flink Runner that only understands Java JAR and (2) how multiple SDKs can be used in a single pipeline. Then we move on to how to manage local Flink and Kafka clusters using bash scripts. Finally, we end up illustrating a simple streaming pipeline, which reads and writes website visit logs from and to Kafka topics."><meta itemprop=datePublished content="2024-04-18T00:00:00+00:00"><meta itemprop=dateModified content="2024-06-04T20:11:39+10:00"><meta itemprop=wordCount content="2891"><meta itemprop=image content="https://jaehyeon.me/blog/2024-04-18-beam-local-dev-3/featured.png"><meta itemprop=keywords content="Apache Beam,Apache Flink,Python,Jupyter Notebook,"><link rel=manifest href=/manifest.json><script async src="https://www.googletagmanager.com/gtag/js?id=G-076N8WCGWZ"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-076N8WCGWZ",{anonymize_ip:!1})}</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2764466088407958"></script><link data-precache rel=stylesheet href="/assets/main/bundle.min.dc910a9364ba50e03d47ecf493e01f798a7ff46d1f793a172c8412e0c9867284.css" integrity="sha256-3JEKk2S6UOA9R+z0k+AfeYp/9G0feToXLIQS4MmGcoQ=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/katex/bundle.min.0e62515e6b767fdcffc08f3d4ab9197f6849689a486b42ab0c98b5e7732e1f58.css integrity="sha256-DmJRXmt2f9z/wI89SrkZf2hJaJpIa0KrDJi153MuH1g=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/viewer/bundle.min.8c1002839fa22c1350d6ae1eef6593120e108f973c41348be9b5065430566aaf.css integrity="sha256-jBACg5+iLBNQ1q4e72WTEg4Qj5c8QTSL6bUGVDBWaq8=" crossorigin=anonymous></head><body><header class="mb-4 sticky-top"><nav class="top-app-bar shadow navbar navbar-expand-xxl"><div class=container><a class="navbar-brand d-flex align-items-center flex-grow-1 flex-xxl-grow-0 justify-content-xxl-start ms-2 ms-xxl-0 mx-auto me-xxl-2" href=https://jaehyeon.me/>Jaehyeon Kim</a><div class="offcanvas-xxl offcanvas-end flex-grow-1" data-bs-scroll=true tabindex=-1 id=navbarMenus aria-labelledby=navbarMenusLabel><div class="offcanvas-header px-4 pb-0"><div class="offcanvas-title h5" id=navbarMenusLabel>Jaehyeon Kim</div><button type=button class="btn-close btn-close-white" data-bs-dismiss=offcanvas data-bs-target=#navbarMenus aria-label=Close></button></div><div class="offcanvas-body p-4 pt-0 p-xxl-0"><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center me-auto"><li class="nav-item col-12 col-xxl-auto dropdown px-0"><a href=# class="nav-link dropdown-toggle" id=navbarDropdownBlog role=button data-bs-toggle=dropdown aria-expanded=false><span class="menu-icon me-1"><i class="fas fa-fw fa-blog text-warning"></i></span>Blog</a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=navbarDropdownBlog data-bs-popper=none><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/archives/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-file-archive text-primary"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-0">Archives</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/series/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Series</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/categories/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Categories</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/tags/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Tags</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li></ul></li></ul><hr class=d-xxl-none><form class="search-bar ms-auto my-auto" action=/search/ novalidate><div class="input-group align-items-center"><span class="btn btn-search disabled position-absolute left-0 border-0 px-1"><i class="fas fa-fw fa-search fa-lg"></i>
</span><input class="my-1 form-control border-white rounded-5 search-input bg-body" name=q type=search placeholder=Search aria-label=Search required>
<span class="search-shortcut position-absolute end-0 top-0 me-2"><kbd class="text-dark bg-white opacity-75 rounded-3 shadow border border-primary py-1 fw-bold">/</kbd></span></div></form><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center ms-md-auto"><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><nav class="social-links nav justify-content-center flex-row"><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fab fa-github"></i>
<span class="ms-1 d-xxl-none">Github</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fab fa-linkedin-in"></i>
<span class="ms-1 d-xxl-none">Linkedin</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fab fa-paypal"></i>
<span class="ms-1 d-xxl-none">Paypal</span>
</a><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-rss"></i>
<span class="ms-1 d-xxl-none">RSS</span></a></nav></li><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><div class="vr d-none d-xxl-flex h-100 mx-xxl-2 text-white"></div><hr class="d-xxl-none my-2"></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=fontSizeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-font"></i>
<span class=d-xxl-none>Font Size</span></a><ul class="font-size-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=fontSizeDropdown><li><button class="font-size-item dropdown-item" data-size=xs>
Extra Small</button></li><li><button class="font-size-item dropdown-item" data-size=sm>
Small</button></li><li><button class="font-size-item dropdown-item active" data-size=md>
Medium</button></li><li><button class="font-size-item dropdown-item" data-size=lg>
Large</button></li><li><button class="font-size-item dropdown-item" data-size=xl>
Extra Large</button></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=paletteDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-palette"></i>
<span class=d-xxl-none>Palette</span></a><ul class="palette-dropdown-menu dropdown-menu dropdown-menu-end px-2 row g-2" aria-labelledby=paletteDropdown><li class="col-4 my-1"><a role=button id=palette-blue aria-label=Blue class="btn btn-sm w-100 palette text-bg-blue" data-palette=blue></a></li><li class="col-4 my-1"><a role=button id=palette-blue-gray aria-label="Blue Gray" class="btn btn-sm w-100 palette text-bg-blue-gray" data-palette=blue-gray></a></li><li class="col-4 my-1"><a role=button id=palette-brown aria-label=Brown class="btn btn-sm w-100 palette text-bg-brown" data-palette=brown></a></li><li class="col-4 my-1"><a role=button id=palette-cyan aria-label=Cyan class="btn btn-sm w-100 palette text-bg-cyan" data-palette=cyan></a></li><li class="col-4 my-1"><a role=button id=palette-green aria-label=Green class="btn btn-sm w-100 palette text-bg-green" data-palette=green></a></li><li class="col-4 my-1"><a role=button id=palette-indigo aria-label=Indigo class="btn btn-sm w-100 palette text-bg-indigo" data-palette=indigo></a></li><li class="col-4 my-1"><a role=button id=palette-orange aria-label=Orange class="btn btn-sm w-100 palette text-bg-orange" data-palette=orange></a></li><li class="col-4 my-1"><a role=button id=palette-pink aria-label=Pink class="btn btn-sm w-100 palette text-bg-pink" data-palette=pink></a></li><li class="col-4 my-1"><a role=button id=palette-purple aria-label=Purple class="btn btn-sm w-100 palette text-bg-purple" data-palette=purple></a></li><li class="col-4 my-1"><a role=button id=palette-red aria-label=Red class="btn btn-sm w-100 palette text-bg-red" data-palette=red></a></li><li class="col-4 my-1"><a role=button id=palette-teal aria-label=Teal class="btn btn-sm w-100 palette text-bg-teal" data-palette=teal></a></li><li class="col-4 my-1"><a role=button id=palette-yellow aria-label=Yellow class="btn btn-sm w-100 palette text-bg-yellow" data-palette=yellow></a></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=modeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="mode-icon fas fa-fw fa-sun" id=modeIcon></i>
<span class=d-xxl-none>Mode</span></a><ul class="mode-dropdown-menu dropdown-menu dropdown-menu-end" aria-labelledby=modeDropdown><li class="mode-item active" data-color-mode=light data-icon=sun><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-sun"></i> Light</button></li><li class=mode-item data-color-mode=dark data-icon=moon><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-moon"></i> Dark</button></li><li class=mode-item data-color-mode=auto data-icon=adjust><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-adjust"></i> Auto</button></li></ul></li></ul></div></div><div class=d-flex><button class="navbar-toggler order-5 border-0" type=button data-bs-toggle=offcanvas data-bs-target=#navbarMenus aria-controls=navbarMenus aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-h"></i></button></div></div></nav></header><main class=container><div class="row content"><noscript><div class="alert alert-danger" role=alert>Your browser does not support JavaScript.</div></noscript><div class=col-xxl-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class="card-body pb-0"><ol class="hbs-breadcrumb breadcrumb flex-nowrap"><li class="breadcrumb-item text-surface"><a href=/>Home</a></li><li class="breadcrumb-item text-surface"><a href=/blog/>Blogs</a></li><li class="breadcrumb-item active">Apache Beam Local Development With Python - Part 3 Flink Runner</li></ol></div></nav><div class="post-panel-wrapper position-relative d-flex justify-content-center"><div class="d-flex flex-row justify-content-center rounded-5 border post-panel position-fixed px-3 py-1 surface shadow-1"><a class="action action-toc d-none d-xxl-block" href=#postTOC role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-toc d-block d-xxl-none" href=#post-toc-container role=button title=Contents><i class="fas fa-fw fa-list-alt"></i>
</a><a class="action action-post-comments" href=#post-comments role=button aria-label=Comments title=Comments><i class="fas fa-fw fa-comments"></i>
</a><a id=sidebarToggler class="action action-sidebar-toggler d-none d-xxl-block" role=button title="Toggle sidebar"><i class="fas fa-fw fa-expand-alt" data-fa-transform=rotate-45></i></a></div></div><article class="row card component mb-4 post"><div class=card-header><h1 class="card-title post-title my-2">Apache Beam Local Development With Python - Part 3 Flink Runner</h1></div><div class=card-body><div class="post-meta mb-3"><span class="post-date me-1 mb-1" title="created on 2024-04-18 00:00:00 +0000 UTC, updated on 2024-06-04 10:11:39 +0000 UTC.">April 18, 2024</span><span class="post-reading-time me-1 mb-1">14 min read</span><a href=/categories/apache-beam/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-category">
<i class="fas fa-fw fa-folder me-1"></i>Apache Beam</a><a href=/series/apache-beam-local-development-with-python/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-series">
<i class="fas fa-fw fa-columns me-1"></i>Apache Beam Local Development With Python</a><a href=/tags/apache-beam/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Beam</a><a href=/tags/apache-flink/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Flink</a><a href=/tags/jupyter-notebook/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Jupyter Notebook</a><a href=/tags/python/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Python</a></div><picture class="d-flex justify-content-center"><source srcset=/blog/2024-04-18-beam-local-dev-3/featured_hua9988bbf060f67942c8c24ced892e1f1_262307_0x270_resize_box_3.png type=image/png media="(max-width: 576px)" width=583 height=270><img class="post-featured-img h-auto w-auto mb-3" alt="Apache Beam Local Development with Python - Part 3 Flink Runner" src=/blog/2024-04-18-beam-local-dev-3/featured_hua9988bbf060f67942c8c24ced892e1f1_262307_0x480_resize_box_3.png width=1036 height=480 data-src=/blog/2024-04-18-beam-local-dev-3/featured.png></picture><p class="lead mb-3 text-body-emphasis">Beam pipelines are portable between batch and streaming semantics but not every Runner is equally capable. The Apache Flink Runner supports Python, and it has good features that allow us to develop streaming pipelines effectively. We first discuss the portability layer of Apache Beam as it helps understand (1) how a pipeline developed by the Python SDK can be executed in the Flink Runner that only understands Java JAR and (2) how multiple SDKs can be used in a single pipeline. Then we move on to how to manage local Flink and Kafka clusters using bash scripts. Finally, we end up illustrating a simple streaming pipeline, which reads and writes website visit logs from and to Kafka topics.</p><div id=postTOC class="mb-3 text-surface"><h2 class=mb-3>Contents<a class="anchor ms-1" href=#postTOC></a></h2><nav id=TableOfContents><ul><li><a href=#portability-layer>Portability Layer</a><ul><li><a href=#portable-pipeline-representation>Portable pipeline representation</a></li><li><a href=#job-service>Job Service</a></li><li><a href=#sdk-harness>SDK harness</a></li><li><a href=#cross-language-pipelines>Cross-language Pipelines</a></li></ul></li><li><a href=#manage-streaming-environment>Manage Streaming Environment</a><ul><li><a href=#flink-cluster>Flink Cluster</a></li><li><a href=#kafka-cluster>Kafka Cluster</a></li><li><a href=#manage-flinkkafka-clusters>Manage Flink/Kafka Clusters</a></li></ul></li><li><a href=#steaming-pipeline>Steaming Pipeline</a><ul><li><a href=#start-flinkkafka-clusters>Start Flink/Kafka Clusters</a></li><li><a href=#generate-data>Generate Data</a></li><li><a href=#run-pipeline>Run Pipeline</a></li><li><a href=#stop-flinkkafka-clusters>Stop Flink/Kafka Clusters</a></li></ul></li><li><a href=#summary>Summary</a></li></ul></nav><hr class=text-secondary></div><div class="post-content mb-3" data-bs-spy=scroll data-bs-target=#TableOfContents tabindex=0><div id=post-content-body><p>In this series, we discuss local development of <a href=https://beam.apache.org/ target=_blank rel="noopener noreferrer">Apache Beam<i class="fas fa-external-link-square-alt ms-1"></i></a> pipelines using Python. In the previous posts, we mainly talked about Batch pipelines with/without Beam SQL. Beam pipelines are portable between batch and streaming semantics, and we will discuss streaming pipeline development in this and the next posts. While there are multiple Beam Runners, not every Runner supports Python or some Runners have too limited features in streaming semantics - see <a href=https://beam.apache.org/documentation/runners/capability-matrix/ target=_blank rel="noopener noreferrer">Beam Capability Matrix<i class="fas fa-external-link-square-alt ms-1"></i></a> for details. So far, the Apache Flink and Google Cloud Dataflow Runners are the best options, and we will use the <a href=https://beam.apache.org/documentation/runners/flink/ target=_blank rel="noopener noreferrer">Flink Runner<i class="fas fa-external-link-square-alt ms-1"></i></a> in this series. This post begins with demonstrating the <em>portability layer</em> of Apache Beam as it helps understand (1) how a pipeline developed by the Python SDK can be executed in the Flink Runner that only understands Java JAR and (2) how multiple SDKs can be used in a single pipeline. Then we discuss how to start up/tear down local Flink and Kafka clusters using bash scripts. Finally, we end up demonstrating a simple streaming pipeline, which reads and writes website visit logs from and to Kafka topics.</p><ul><li><a href=/blog/2024-03-28-beam-local-dev-1>Part 1 Pipeline, Notebook, SQL and DataFrame</a></li><li><a href=/blog/2024-04-04-beam-local-dev-2>Part 2 Batch Pipelines</a></li><li><a href=/blog/2024-04-18-beam-local-dev-3/#>Part 3 Flink Runner</a> (this post)</li><li><a href=/blog/2024-05-02-beam-local-dev-4>Part 4 Streaming Pipelines</a></li><li><a href=/blog/2024-05-09-beam-local-dev-5>Part 5 Testing Pipelines</a></li></ul><h2 id=portability-layer data-numberify>Portability Layer<a class="anchor ms-1" href=#portability-layer></a></h2><p>Apache Beam Pipelines are portable on several layers between (1) Beam Runners, (2) batch/streaming semantics and (3) programming languages.</p><p>The portability between programming languages are achieved by the portability layer, and it has two components - Apache Beam components and Runner components. Essentially the Beam Runners (Apache Flink, Apache Spark, Google Cloud Datafolow &mldr;) don&rsquo;t have to understand a Beam SDK but are able to execute pipelines built by it regardless.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2024-04-18-beam-local-dev-3/beam-portability-layer.png loading=lazy width=582 height=544></picture></p><p>Each Runner typically has a coordinator that needs to receive a job submission and creates tasks for worker nodes according to the submission. For example, the coordinator of the Flink Runner is the Flink JobManager, and it receives a Java JAR file for job execution along with the Directed Acyclic Graph (DAG) of transforms, serialized user code and so on.</p><p>Then there are two problems to solve.</p><ol><li>How can a non-Java SDK converts a Beam pipeline into a Java JAR that the Flink Runner understands?</li><li>How can the Runner&rsquo;s worker nodes execute non-Java user code?</li></ol><p>These problems are tackled down by (1) portable pipeline representation, (2) Job Service, and (3) SDK harness.</p><h3 id=portable-pipeline-representation data-numberify>Portable pipeline representation<a class="anchor ms-1" href=#portable-pipeline-representation></a></h3><p>A non-Java SDK converts a Beam pipeline into a portable representation, which mainly includes the Directed Acyclic Graph (DAG) of transforms and serialized user-defined functions (UDFs)/user code - eg beam.Map(&mldr;). Protocol buffers are used for this representation, and it is submitted to Job Service once created.</p><h3 id=job-service data-numberify>Job Service<a class="anchor ms-1" href=#job-service></a></h3><p>This component receives a portable representation of a pipeline and converts it into a format that a Runner can understand. Note that, when it creates a job, it replaces calls to UDFs with calls to the SDK harness process in which the UDFs are actually executed for the Runner. Also, it instructs the Runner coordinator to create a SDK harness process for each worker.</p><h3 id=sdk-harness data-numberify>SDK harness<a class="anchor ms-1" href=#sdk-harness></a></h3><p>As mentioned, calls to UDFs on a Runner worker are delegated to calls in the SDK harness process, and the UDFs are executed using the same SDK that they are created. Note that communication between the Runner worker and the SDK harness process is made by gRPC - an HTTP/2 based protocol that relies on protocol buffers as its serialization mechanism. The harness is specific to SDK and, for the Python SDK, there are multiple options.</p><ul><li>DOCKER (default): User code is executed within a container started on each worker node.</li><li>PROCESS: User code is executed by processes that are automatically started by the runner on each worker node.</li><li>EXTERNAL: User code is dispatched to an external service.</li><li>LOOPBACK: User code is executed within the same process that submitted the pipeline and is useful for local testing.</li></ul><h3 id=cross-language-pipelines data-numberify>Cross-language Pipelines<a class="anchor ms-1" href=#cross-language-pipelines></a></h3><p>The portability layer can be extended to cross-language pipelines where transforms are mixed from multiple SDKs. A typical example is the Kafka Connector I/O for the Python SDK where the <em>ReadFromKafka</em> and <em>WriteToKafka</em> transforms are made by the Java SDK. Also, the SQL transform (<em>SqlTransform</em>) of Beam SQL is performed by the Java SDK.</p><p>Here the challenge is how to make a non-Java SDK to be able to serialize data for a Java SDK so that its portable pipeline representation can be created! This challenge is handled by the expansion service. Simply put, when a source SDK wants to submit a pipeline to a Runner, it creates its portable pipeline representation. During this process, if it sees an external (cross-language) transform, it sends a request to the expansion service, asking it to expand the transform into a portable representation. Then, the expansion service creates/returns the portable representation, and it is inserted into the complete pipeline representation. For the Python SDK, the expansion service gets started automatically, or we can customize it, for example, to change the SDK harness from DOCKER to PROCESS.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2024-04-18-beam-local-dev-3/expansion-service.png loading=lazy width=614 height=507></picture></p><p>Note this section is based on <a href=https://www.packtpub.com/product/building-big-data-pipelines-with-apache-beam/9781800564930 target=_blank rel="noopener noreferrer">Building Big Data Pipelines with Apache Beam by Jan Lukavský<i class="fas fa-external-link-square-alt ms-1"></i></a> and you can check more details in the book!</p><h2 id=manage-streaming-environment data-numberify>Manage Streaming Environment<a class="anchor ms-1" href=#manage-streaming-environment></a></h2><p>The streaming development environment requires local Apache Flink and Apache Kafka clusters. Initially I was going to create a Flink cluster on Docker, but I had an issue that the Kafka Connect I/O fails to resolve Kafka bootstrap addresses. Specifically, for the Kafka I/O, a docker container is launched by the Flink TaskManager with the host network (<code>--network host</code>) - remind that the default SDK harness option is DOCKER. Then the SDK harness container looks for Kafka bootstrap addresses in its host, which is the Flink TaskManager container, not the Docker host machine. Therefore, the address resolution fails because the Kafka cluster doesn&rsquo;t run there. It would work with other SDH harness options, but I thought it requires too much setup for local development. On the other hand, the issue no longer applies if we launch a Flink cluster locally, and we will use this approach instead. The source of this post can be found in this <a href=https://github.com/jaehyeon-kim/beam-demos/tree/master/beam-dev-env target=_blank rel="noopener noreferrer"><strong>GitHub repository</strong><i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><h3 id=flink-cluster data-numberify>Flink Cluster<a class="anchor ms-1" href=#flink-cluster></a></h3><p>The latest supported version of Apache Flink is 1.16 as of writing this post, and we can download and unpack it in a dedicated folder named <em>setup</em> as shown below. Note that some scripts in the <em>bin</em> folder should be executable, and their permission is changed at the end.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ mkdir setup <span class=o>&amp;&amp;</span> <span class=nb>cd</span> setup
</span></span><span class=line><span class=ln>2</span><span class=cl>$ wget https://dlcdn.apache.org/flink/flink-1.16.3/flink-1.16.3-bin-scala_2.12.tgz
</span></span><span class=line><span class=ln>3</span><span class=cl>$ tar -zxf flink-1.16.3-bin-scala_2.12.tgz
</span></span><span class=line><span class=ln>4</span><span class=cl>$ chmod -R +x flink-1.16.3/bin/
</span></span></code></pre></div><p>Next, Flink configuration is updated so that the Flink UI is accessible and the number of tasks slots is increased to 10.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=ln>1</span><span class=cl><span class=c># setup/flink-1.16.3/config/flink-conf.yaml</span><span class=w>
</span></span></span><span class=line><span class=ln>2</span><span class=cl><span class=w> </span><span class=nt>rest.port</span><span class=p>:</span><span class=w> </span><span class=m>8081</span><span class=w>                    </span><span class=c># uncommented</span><span class=w>
</span></span></span><span class=line><span class=ln>3</span><span class=cl><span class=w> </span><span class=nt>rest.address</span><span class=p>:</span><span class=w> </span><span class=l>localhost           </span><span class=w> </span><span class=c># kept as is</span><span class=w>
</span></span></span><span class=line><span class=ln>4</span><span class=cl><span class=w> </span><span class=nt>rest.bind-address</span><span class=p>:</span><span class=w> </span><span class=m>0.0.0.0</span><span class=w>         </span><span class=c># changed from localhost</span><span class=w>
</span></span></span><span class=line><span class=ln>5</span><span class=cl><span class=w> </span><span class=nt>taskmanager.numberOfTaskSlots</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>  </span><span class=c># updated from 1</span><span class=w>
</span></span></span></code></pre></div><h3 id=kafka-cluster data-numberify>Kafka Cluster<a class="anchor ms-1" href=#kafka-cluster></a></h3><p>A Kafka cluster with 1 broker and 1 Zookeeper node is used for this post together with a Kafka management app (<em>kafka-ui</em>). The details of setting up the resources can be found in my <em>Kafka Development with Docker</em> series.</p><ul><li><a href=/blog/2023-05-04-kafka-development-with-docker-part-1>Part 1 Cluster Setup</a></li><li><a href=/blog/2023-05-18-kafka-development-with-docker-part-2>Part 2 Management App</a></li></ul><p>Those resources are deployed using Docker Compose with the following configuration file.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=ln> 1</span><span class=cl><span class=c># setup/docker-compose.yml</span><span class=w>
</span></span></span><span class=line><span class=ln> 2</span><span class=cl><span class=w></span><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;3.5&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln> 3</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln> 4</span><span class=cl><span class=w></span><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 5</span><span class=cl><span class=w>  </span><span class=nt>zookeeper</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 6</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/zookeeper:3.5</span><span class=w>
</span></span></span><span class=line><span class=ln> 7</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=ln> 8</span><span class=cl><span class=w>    </span><span class=nt>expose</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln> 9</span><span class=cl><span class=w>      </span>- <span class=m>2181</span><span class=w>
</span></span></span><span class=line><span class=ln>10</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>11</span><span class=cl><span class=w>      </span>- <span class=l>appnet</span><span class=w>
</span></span></span><span class=line><span class=ln>12</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>13</span><span class=cl><span class=w>      </span>- <span class=l>ALLOW_ANONYMOUS_LOGIN=yes</span><span class=w>
</span></span></span><span class=line><span class=ln>14</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>15</span><span class=cl><span class=w>      </span>- <span class=l>zookeeper_data:/bitnami/zookeeper</span><span class=w>
</span></span></span><span class=line><span class=ln>16</span><span class=cl><span class=w>  </span><span class=nt>kafka-0</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>17</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>bitnami/kafka:2.8.1</span><span class=w>
</span></span></span><span class=line><span class=ln>18</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=ln>19</span><span class=cl><span class=w>    </span><span class=nt>expose</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>20</span><span class=cl><span class=w>      </span>- <span class=m>9092</span><span class=w>
</span></span></span><span class=line><span class=ln>21</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>22</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;29092:29092&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>23</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>24</span><span class=cl><span class=w>      </span>- <span class=l>appnet</span><span class=w>
</span></span></span><span class=line><span class=ln>25</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>26</span><span class=cl><span class=w>      </span>- <span class=l>ALLOW_PLAINTEXT_LISTENER=yes</span><span class=w>
</span></span></span><span class=line><span class=ln>27</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181</span><span class=w>
</span></span></span><span class=line><span class=ln>28</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_BROKER_ID=0</span><span class=w>
</span></span></span><span class=line><span class=ln>29</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT</span><span class=w>
</span></span></span><span class=line><span class=ln>30</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_LISTENERS=INTERNAL://:9092,EXTERNAL://:29092</span><span class=w>
</span></span></span><span class=line><span class=ln>31</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_ADVERTISED_LISTENERS=INTERNAL://kafka-0:9092,EXTERNAL://localhost:29092</span><span class=w>
</span></span></span><span class=line><span class=ln>32</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_INTER_BROKER_LISTENER_NAME=INTERNAL</span><span class=w>
</span></span></span><span class=line><span class=ln>33</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_NUM_PARTITIONS=3</span><span class=w>
</span></span></span><span class=line><span class=ln>34</span><span class=cl><span class=w>      </span>- <span class=l>KAFKA_CFG_DEFAULT_REPLICATION_FACTOR=1</span><span class=w>
</span></span></span><span class=line><span class=ln>35</span><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>36</span><span class=cl><span class=w>      </span>- <span class=l>kafka_0_data:/bitnami/kafka</span><span class=w>
</span></span></span><span class=line><span class=ln>37</span><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>38</span><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=ln>39</span><span class=cl><span class=w>  </span><span class=nt>kafka-ui</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>40</span><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>provectuslabs/kafka-ui:v0.7.1</span><span class=w>
</span></span></span><span class=line><span class=ln>41</span><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>kafka-ui</span><span class=w>
</span></span></span><span class=line><span class=ln>42</span><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>43</span><span class=cl><span class=w>      </span>- <span class=s2>&#34;8080:8080&#34;</span><span class=w>
</span></span></span><span class=line><span class=ln>44</span><span class=cl><span class=w>    </span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>45</span><span class=cl><span class=w>      </span>- <span class=l>appnet</span><span class=w>
</span></span></span><span class=line><span class=ln>46</span><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>47</span><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_NAME</span><span class=p>:</span><span class=w> </span><span class=l>local</span><span class=w>
</span></span></span><span class=line><span class=ln>48</span><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS</span><span class=p>:</span><span class=w> </span><span class=l>kafka-0:9092</span><span class=w>
</span></span></span><span class=line><span class=ln>49</span><span class=cl><span class=w>      </span><span class=nt>KAFKA_CLUSTERS_0_ZOOKEEPER</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper:2181</span><span class=w>
</span></span></span><span class=line><span class=ln>50</span><span class=cl><span class=w>    </span><span class=nt>depends_on</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>51</span><span class=cl><span class=w>      </span>- <span class=l>zookeeper</span><span class=w>
</span></span></span><span class=line><span class=ln>52</span><span class=cl><span class=w>      </span>- <span class=l>kafka-0</span><span class=w>
</span></span></span><span class=line><span class=ln>53</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln>54</span><span class=cl><span class=w></span><span class=nt>networks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>55</span><span class=cl><span class=w>  </span><span class=nt>appnet</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>56</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>app-network</span><span class=w>
</span></span></span><span class=line><span class=ln>57</span><span class=cl><span class=w>
</span></span></span><span class=line><span class=ln>58</span><span class=cl><span class=w></span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>59</span><span class=cl><span class=w>  </span><span class=nt>zookeeper_data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>60</span><span class=cl><span class=w>    </span><span class=nt>driver</span><span class=p>:</span><span class=w> </span><span class=l>local</span><span class=w>
</span></span></span><span class=line><span class=ln>61</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>zookeeper_data</span><span class=w>
</span></span></span><span class=line><span class=ln>62</span><span class=cl><span class=w>  </span><span class=nt>kafka_0_data</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=ln>63</span><span class=cl><span class=w>    </span><span class=nt>driver</span><span class=p>:</span><span class=w> </span><span class=l>local</span><span class=w>
</span></span></span><span class=line><span class=ln>64</span><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>kafka_0_data</span><span class=w>
</span></span></span></code></pre></div><p>Note that the bootstrap server is exposed on port <em>29092</em>, and it can be accessed via <em>localhost:29092</em> from the Docker host machine and <em>host.docker.internal:29092</em> from a Docker container that is launched with the host network. Note further that, for the latter to work, we have to update the <em>/etc/hosts</em> file by adding an entry for <em>host.docker.internal</em> as shown below.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ cat /etc/hosts <span class=p>|</span> grep host.docker.internal
</span></span><span class=line><span class=ln>2</span><span class=cl><span class=c1># 127.0.0.1       host.docker.internal</span>
</span></span></code></pre></div><h3 id=manage-flinkkafka-clusters data-numberify>Manage Flink/Kafka Clusters<a class="anchor ms-1" href=#manage-flinkkafka-clusters></a></h3><p>The Flink and Kafka clusters are managed by bash scripts. They accept three arguments: <em>-k</em> or <em>-f</em> to launch a Kafka or Flink cluster individually or <em>-a</em> to launch both of them. Below shows the startup script, and it creates a Kafka cluster on Docker followed by starting a Flink cluster if conditions are met.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl><span class=c1># setup/start-flink-env.sh</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1>#!/usr/bin/env bash</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=k>while</span> <span class=o>[[</span> <span class=s2>&#34;</span><span class=nv>$#</span><span class=s2>&#34;</span> -gt <span class=m>0</span> <span class=o>]]</span><span class=p>;</span> <span class=k>do</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>    <span class=k>case</span> <span class=nv>$1</span> in
</span></span><span class=line><span class=ln> 6</span><span class=cl>        -k<span class=p>|</span>--kafka<span class=o>)</span> <span class=nv>start_kafka</span><span class=o>=</span>true<span class=p>;;</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>        -f<span class=p>|</span>--flink<span class=o>)</span> <span class=nv>start_flink</span><span class=o>=</span>true<span class=p>;;</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>        -a<span class=p>|</span>--all<span class=o>)</span> <span class=nv>start_all</span><span class=o>=</span>true<span class=p>;;</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>        *<span class=o>)</span> <span class=nb>echo</span> <span class=s2>&#34;Unknown parameter passed: </span><span class=nv>$1</span><span class=s2>&#34;</span><span class=p>;</span> <span class=nb>exit</span> <span class=m>1</span> <span class=p>;;</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>    <span class=k>esac</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>    <span class=nb>shift</span>
</span></span><span class=line><span class=ln>12</span><span class=cl><span class=k>done</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>
</span></span><span class=line><span class=ln>14</span><span class=cl><span class=k>if</span> <span class=o>[</span> ! -z <span class=nv>$start_all</span> <span class=o>]</span> <span class=o>&amp;&amp;</span>  <span class=o>[</span> <span class=nv>$start_all</span> <span class=o>=</span> <span class=nb>true</span> <span class=o>]</span><span class=p>;</span> <span class=k>then</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>  <span class=nv>start_kafka</span><span class=o>=</span><span class=nb>true</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>  <span class=nv>start_flink</span><span class=o>=</span><span class=nb>true</span>
</span></span><span class=line><span class=ln>17</span><span class=cl><span class=k>fi</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>
</span></span><span class=line><span class=ln>19</span><span class=cl><span class=nv>SCRIPT_DIR</span><span class=o>=</span><span class=k>$(</span>dirname <span class=s2>&#34;</span><span class=k>$(</span>readlink -f <span class=s2>&#34;</span><span class=nv>$0</span><span class=s2>&#34;</span><span class=k>)</span><span class=s2>&#34;</span><span class=k>)</span>
</span></span><span class=line><span class=ln>20</span><span class=cl>
</span></span><span class=line><span class=ln>21</span><span class=cl><span class=c1>#### start kafka cluster on docker</span>
</span></span><span class=line><span class=ln>22</span><span class=cl><span class=k>if</span> <span class=o>[</span> ! -z <span class=nv>$start_kafka</span> <span class=o>]</span> <span class=o>&amp;&amp;</span>  <span class=o>[</span> <span class=nv>$start_kafka</span> <span class=o>=</span> <span class=nb>true</span> <span class=o>]</span><span class=p>;</span> <span class=k>then</span>
</span></span><span class=line><span class=ln>23</span><span class=cl>  docker-compose -f <span class=si>${</span><span class=nv>SCRIPT_DIR</span><span class=si>}</span>/docker-compose.yml up -d
</span></span><span class=line><span class=ln>24</span><span class=cl><span class=k>fi</span>
</span></span><span class=line><span class=ln>25</span><span class=cl>
</span></span><span class=line><span class=ln>26</span><span class=cl><span class=c1>#### start local flink cluster</span>
</span></span><span class=line><span class=ln>27</span><span class=cl><span class=k>if</span> <span class=o>[</span> ! -z <span class=nv>$start_flink</span> <span class=o>]</span> <span class=o>&amp;&amp;</span> <span class=o>[</span> <span class=nv>$start_flink</span> <span class=o>=</span> <span class=nb>true</span> <span class=o>]</span><span class=p>;</span> <span class=k>then</span>
</span></span><span class=line><span class=ln>28</span><span class=cl>  <span class=si>${</span><span class=nv>SCRIPT_DIR</span><span class=si>}</span>/flink-1.16.3/bin/start-cluster.sh
</span></span><span class=line><span class=ln>29</span><span class=cl><span class=k>fi</span>
</span></span></code></pre></div><p>The teardown script is structured to stop/remove the Kafka-related containers and Docker volumes, stop the Flink cluster and remove unused containers. The last pruning is for cleaning up containers that are created by Java SDK harness processes.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln> 1</span><span class=cl><span class=c1># setup/stop-flink-env.sh</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=c1>#!/usr/bin/env bash</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=k>while</span> <span class=o>[[</span> <span class=s2>&#34;</span><span class=nv>$#</span><span class=s2>&#34;</span> -gt <span class=m>0</span> <span class=o>]]</span><span class=p>;</span> <span class=k>do</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>    <span class=k>case</span> <span class=nv>$1</span> in
</span></span><span class=line><span class=ln> 6</span><span class=cl>        -k<span class=p>|</span>--kafka<span class=o>)</span> <span class=nv>stop_kafka</span><span class=o>=</span>true<span class=p>;;</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>        -f<span class=p>|</span>--flink<span class=o>)</span> <span class=nv>stop_flink</span><span class=o>=</span>true<span class=p>;;</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>        -a<span class=p>|</span>--all<span class=o>)</span> <span class=nv>stop_all</span><span class=o>=</span>true<span class=p>;;</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>        *<span class=o>)</span> <span class=nb>echo</span> <span class=s2>&#34;Unknown parameter passed: </span><span class=nv>$1</span><span class=s2>&#34;</span><span class=p>;</span> <span class=nb>exit</span> <span class=m>1</span> <span class=p>;;</span>
</span></span><span class=line><span class=ln>10</span><span class=cl>    <span class=k>esac</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>    <span class=nb>shift</span>
</span></span><span class=line><span class=ln>12</span><span class=cl><span class=k>done</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>
</span></span><span class=line><span class=ln>14</span><span class=cl><span class=k>if</span> <span class=o>[</span> ! -z <span class=nv>$stop_all</span> <span class=o>]</span> <span class=o>&amp;&amp;</span> <span class=o>[</span> <span class=nv>$stop_all</span> <span class=o>=</span> <span class=nb>true</span> <span class=o>]</span><span class=p>;</span> <span class=k>then</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>  <span class=nv>stop_kafka</span><span class=o>=</span><span class=nb>true</span>
</span></span><span class=line><span class=ln>16</span><span class=cl>  <span class=nv>stop_flink</span><span class=o>=</span><span class=nb>true</span>
</span></span><span class=line><span class=ln>17</span><span class=cl><span class=k>fi</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>
</span></span><span class=line><span class=ln>19</span><span class=cl><span class=nv>SCRIPT_DIR</span><span class=o>=</span><span class=k>$(</span>dirname <span class=s2>&#34;</span><span class=k>$(</span>readlink -f <span class=s2>&#34;</span><span class=nv>$0</span><span class=s2>&#34;</span><span class=k>)</span><span class=s2>&#34;</span><span class=k>)</span>
</span></span><span class=line><span class=ln>20</span><span class=cl>
</span></span><span class=line><span class=ln>21</span><span class=cl><span class=c1>#### stop kafka cluster in docker</span>
</span></span><span class=line><span class=ln>22</span><span class=cl><span class=k>if</span> <span class=o>[</span> ! -z <span class=nv>$stop_kafka</span> <span class=o>]</span> <span class=o>&amp;&amp;</span> <span class=o>[</span> <span class=nv>$stop_kafka</span> <span class=o>=</span> <span class=nb>true</span> <span class=o>]</span><span class=p>;</span> <span class=k>then</span>
</span></span><span class=line><span class=ln>23</span><span class=cl>    docker-compose -f <span class=si>${</span><span class=nv>SCRIPT_DIR</span><span class=si>}</span>/docker-compose.yml down -v
</span></span><span class=line><span class=ln>24</span><span class=cl><span class=k>fi</span>
</span></span><span class=line><span class=ln>25</span><span class=cl>
</span></span><span class=line><span class=ln>26</span><span class=cl><span class=c1>#### stop local flink cluster</span>
</span></span><span class=line><span class=ln>27</span><span class=cl><span class=k>if</span> <span class=o>[</span> ! -z <span class=nv>$stop_flink</span> <span class=o>]</span> <span class=o>&amp;&amp;</span> <span class=o>[</span> <span class=nv>$stop_flink</span> <span class=o>=</span> <span class=nb>true</span> <span class=o>]</span><span class=p>;</span> <span class=k>then</span>
</span></span><span class=line><span class=ln>28</span><span class=cl>    <span class=si>${</span><span class=nv>SCRIPT_DIR</span><span class=si>}</span>/flink-1.16.3/bin/stop-cluster.sh
</span></span><span class=line><span class=ln>29</span><span class=cl><span class=k>fi</span>
</span></span><span class=line><span class=ln>30</span><span class=cl>
</span></span><span class=line><span class=ln>31</span><span class=cl><span class=c1>#### remove all stopped containers</span>
</span></span><span class=line><span class=ln>32</span><span class=cl>docker container prune -f
</span></span></code></pre></div><h2 id=steaming-pipeline data-numberify>Steaming Pipeline<a class="anchor ms-1" href=#steaming-pipeline></a></h2><p>The streaming pipeline is really simple in this post that it just (1) reads/decodes messages from an input Kafka topic named <em>website-visit</em>, (2) parses the elements into a pre-defined type of <em>EventLog</em> and (3) encodes/sends them into an output Kafka topic named <em>website-out</em>.</p><p>The pipeline has a number of notable options as shown below. Those that are specific to the Flink Runner are marked in bold, and they can be checked further in the <a href=https://beam.apache.org/documentation/runners/flink/ target=_blank rel="noopener noreferrer">Flink Runner document<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p><ul><li><em>runner</em> - The name of the Beam Runner, default to <em>FlinkRunner</em>.</li><li><em>job_name</em> - The pipeline job name that can be checked eg on the Flink UI.</li><li><em>environment_type</em> - The <a href=https://beam.apache.org/documentation/runtime/sdk-harness-config/ target=_blank rel="noopener noreferrer">SDK harness<i class="fas fa-external-link-square-alt ms-1"></i></a> environment type. <em>LOOPBACK</em> is selected for development, so that user code is executed within the same process that submitted the pipeline.</li><li><em>streaming</em> - The flag whether to enforce streaming mode or not.</li><li><strong>parallelism</strong> - The degree of parallelism to be used when distributing operations onto workers.</li><li><em>experiments</em> > <em>use_deprecated_read</em> - Use the depreciated read mode for the Kafka IO to work. See <a href=https://issues.apache.org/jira/browse/BEAM-11998 target=_blank rel="noopener noreferrer">BEAM-11998<i class="fas fa-external-link-square-alt ms-1"></i></a> for details.</li><li><strong>checkpointing_interval</strong> - The interval in milliseconds at which to trigger checkpoints of the running pipeline.</li><li><strong>flink_master</strong> - The address of the Flink Master where the pipeline should be executed. It is automatically set as <em>localhost:8081</em> if the <em>use_own</em> argument is included. Otherwise, the pipeline runs with an embedded Flink cluster.</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=ln>  1</span><span class=cl><span class=c1># section3/kafka_io.py</span>
</span></span><span class=line><span class=ln>  2</span><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=ln>  3</span><span class=cl><span class=kn>import</span> <span class=nn>argparse</span>
</span></span><span class=line><span class=ln>  4</span><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=ln>  5</span><span class=cl><span class=kn>import</span> <span class=nn>logging</span>
</span></span><span class=line><span class=ln>  6</span><span class=cl><span class=kn>import</span> <span class=nn>typing</span>
</span></span><span class=line><span class=ln>  7</span><span class=cl>
</span></span><span class=line><span class=ln>  8</span><span class=cl><span class=kn>import</span> <span class=nn>apache_beam</span> <span class=k>as</span> <span class=nn>beam</span>
</span></span><span class=line><span class=ln>  9</span><span class=cl><span class=kn>from</span> <span class=nn>apache_beam.io</span> <span class=kn>import</span> <span class=n>kafka</span>
</span></span><span class=line><span class=ln> 10</span><span class=cl><span class=kn>from</span> <span class=nn>apache_beam.options.pipeline_options</span> <span class=kn>import</span> <span class=n>PipelineOptions</span>
</span></span><span class=line><span class=ln> 11</span><span class=cl><span class=kn>from</span> <span class=nn>apache_beam.options.pipeline_options</span> <span class=kn>import</span> <span class=n>SetupOptions</span>
</span></span><span class=line><span class=ln> 12</span><span class=cl>
</span></span><span class=line><span class=ln> 13</span><span class=cl>
</span></span><span class=line><span class=ln> 14</span><span class=cl><span class=k>class</span> <span class=nc>EventLog</span><span class=p>(</span><span class=n>typing</span><span class=o>.</span><span class=n>NamedTuple</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 15</span><span class=cl>    <span class=n>ip</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=ln> 16</span><span class=cl>    <span class=nb>id</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=ln> 17</span><span class=cl>    <span class=n>lat</span><span class=p>:</span> <span class=nb>float</span>
</span></span><span class=line><span class=ln> 18</span><span class=cl>    <span class=n>lng</span><span class=p>:</span> <span class=nb>float</span>
</span></span><span class=line><span class=ln> 19</span><span class=cl>    <span class=n>user_agent</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=ln> 20</span><span class=cl>    <span class=n>age_bracket</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=ln> 21</span><span class=cl>    <span class=n>opted_into_marketing</span><span class=p>:</span> <span class=nb>bool</span>
</span></span><span class=line><span class=ln> 22</span><span class=cl>    <span class=n>http_request</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=ln> 23</span><span class=cl>    <span class=n>http_response</span><span class=p>:</span> <span class=nb>int</span>
</span></span><span class=line><span class=ln> 24</span><span class=cl>    <span class=n>file_size_bytes</span><span class=p>:</span> <span class=nb>int</span>
</span></span><span class=line><span class=ln> 25</span><span class=cl>    <span class=n>event_datetime</span><span class=p>:</span> <span class=nb>str</span>
</span></span><span class=line><span class=ln> 26</span><span class=cl>    <span class=n>event_ts</span><span class=p>:</span> <span class=nb>int</span>
</span></span><span class=line><span class=ln> 27</span><span class=cl>
</span></span><span class=line><span class=ln> 28</span><span class=cl>
</span></span><span class=line><span class=ln> 29</span><span class=cl><span class=n>beam</span><span class=o>.</span><span class=n>coders</span><span class=o>.</span><span class=n>registry</span><span class=o>.</span><span class=n>register_coder</span><span class=p>(</span><span class=n>EventLog</span><span class=p>,</span> <span class=n>beam</span><span class=o>.</span><span class=n>coders</span><span class=o>.</span><span class=n>RowCoder</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 30</span><span class=cl>
</span></span><span class=line><span class=ln> 31</span><span class=cl>
</span></span><span class=line><span class=ln> 32</span><span class=cl><span class=k>def</span> <span class=nf>decode_message</span><span class=p>(</span><span class=n>kafka_kv</span><span class=p>:</span> <span class=nb>tuple</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 33</span><span class=cl>    <span class=k>return</span> <span class=n>kafka_kv</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 34</span><span class=cl>
</span></span><span class=line><span class=ln> 35</span><span class=cl>
</span></span><span class=line><span class=ln> 36</span><span class=cl><span class=k>def</span> <span class=nf>create_message</span><span class=p>(</span><span class=n>element</span><span class=p>:</span> <span class=n>EventLog</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 37</span><span class=cl>    <span class=n>key</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;event_id&#34;</span><span class=p>:</span> <span class=n>element</span><span class=o>.</span><span class=n>id</span><span class=p>,</span> <span class=s2>&#34;event_ts&#34;</span><span class=p>:</span> <span class=n>element</span><span class=o>.</span><span class=n>event_ts</span><span class=p>}</span>
</span></span><span class=line><span class=ln> 38</span><span class=cl>    <span class=n>value</span> <span class=o>=</span> <span class=n>element</span><span class=o>.</span><span class=n>_asdict</span><span class=p>()</span>
</span></span><span class=line><span class=ln> 39</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>key</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 40</span><span class=cl>    <span class=k>return</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>key</span><span class=p>)</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>),</span> <span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>value</span><span class=p>)</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 41</span><span class=cl>
</span></span><span class=line><span class=ln> 42</span><span class=cl>
</span></span><span class=line><span class=ln> 43</span><span class=cl><span class=k>def</span> <span class=nf>parse_json</span><span class=p>(</span><span class=n>element</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=ln> 44</span><span class=cl>    <span class=n>row</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>element</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 45</span><span class=cl>    <span class=c1># lat/lng sometimes empty string</span>
</span></span><span class=line><span class=ln> 46</span><span class=cl>    <span class=k>if</span> <span class=ow>not</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;lat&#34;</span><span class=p>]</span> <span class=ow>or</span> <span class=ow>not</span> <span class=n>row</span><span class=p>[</span><span class=s2>&#34;lng&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=ln> 47</span><span class=cl>        <span class=n>row</span> <span class=o>=</span> <span class=p>{</span><span class=o>**</span><span class=n>row</span><span class=p>,</span> <span class=o>**</span><span class=p>{</span><span class=s2>&#34;lat&#34;</span><span class=p>:</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=s2>&#34;lng&#34;</span><span class=p>:</span> <span class=o>-</span><span class=mi>1</span><span class=p>}}</span>
</span></span><span class=line><span class=ln> 48</span><span class=cl>    <span class=k>return</span> <span class=n>EventLog</span><span class=p>(</span><span class=o>**</span><span class=n>row</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 49</span><span class=cl>
</span></span><span class=line><span class=ln> 50</span><span class=cl>
</span></span><span class=line><span class=ln> 51</span><span class=cl><span class=k>def</span> <span class=nf>run</span><span class=p>():</span>
</span></span><span class=line><span class=ln> 52</span><span class=cl>    <span class=n>parser</span> <span class=o>=</span> <span class=n>argparse</span><span class=o>.</span><span class=n>ArgumentParser</span><span class=p>(</span><span class=n>description</span><span class=o>=</span><span class=s2>&#34;Beam pipeline arguments&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 53</span><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 54</span><span class=cl>        <span class=s2>&#34;--runner&#34;</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=s2>&#34;FlinkRunner&#34;</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s2>&#34;Specify Apache Beam Runner&#34;</span>
</span></span><span class=line><span class=ln> 55</span><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=ln> 56</span><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 57</span><span class=cl>        <span class=s2>&#34;--use_own&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 58</span><span class=cl>        <span class=n>action</span><span class=o>=</span><span class=s2>&#34;store_true&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 59</span><span class=cl>        <span class=n>default</span><span class=o>=</span><span class=s2>&#34;Flag to indicate whether to use an own local cluster&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 60</span><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=ln> 61</span><span class=cl>    <span class=n>opts</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args</span><span class=p>()</span>
</span></span><span class=line><span class=ln> 62</span><span class=cl>
</span></span><span class=line><span class=ln> 63</span><span class=cl>    <span class=n>pipeline_opts</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=ln> 64</span><span class=cl>        <span class=s2>&#34;runner&#34;</span><span class=p>:</span> <span class=n>opts</span><span class=o>.</span><span class=n>runner</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 65</span><span class=cl>        <span class=s2>&#34;job_name&#34;</span><span class=p>:</span> <span class=s2>&#34;kafka-io&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 66</span><span class=cl>        <span class=s2>&#34;environment_type&#34;</span><span class=p>:</span> <span class=s2>&#34;LOOPBACK&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 67</span><span class=cl>        <span class=s2>&#34;streaming&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 68</span><span class=cl>        <span class=s2>&#34;parallelism&#34;</span><span class=p>:</span> <span class=mi>3</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 69</span><span class=cl>        <span class=s2>&#34;experiments&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=ln> 70</span><span class=cl>            <span class=s2>&#34;use_deprecated_read&#34;</span>
</span></span><span class=line><span class=ln> 71</span><span class=cl>        <span class=p>],</span>  <span class=c1>## https://github.com/apache/beam/issues/20979</span>
</span></span><span class=line><span class=ln> 72</span><span class=cl>        <span class=s2>&#34;checkpointing_interval&#34;</span><span class=p>:</span> <span class=s2>&#34;60000&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 73</span><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=ln> 74</span><span class=cl>    <span class=k>if</span> <span class=n>opts</span><span class=o>.</span><span class=n>use_own</span> <span class=ow>is</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=ln> 75</span><span class=cl>        <span class=n>pipeline_opts</span> <span class=o>=</span> <span class=p>{</span><span class=o>**</span><span class=n>pipeline_opts</span><span class=p>,</span> <span class=o>**</span><span class=p>{</span><span class=s2>&#34;flink_master&#34;</span><span class=p>:</span> <span class=s2>&#34;localhost:8081&#34;</span><span class=p>}}</span>
</span></span><span class=line><span class=ln> 76</span><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>pipeline_opts</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 77</span><span class=cl>    <span class=n>options</span> <span class=o>=</span> <span class=n>PipelineOptions</span><span class=p>([],</span> <span class=o>**</span><span class=n>pipeline_opts</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 78</span><span class=cl>    <span class=c1># Required, else it will complain that when importing worker functions</span>
</span></span><span class=line><span class=ln> 79</span><span class=cl>    <span class=n>options</span><span class=o>.</span><span class=n>view_as</span><span class=p>(</span><span class=n>SetupOptions</span><span class=p>)</span><span class=o>.</span><span class=n>save_main_session</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=ln> 80</span><span class=cl>
</span></span><span class=line><span class=ln> 81</span><span class=cl>    <span class=n>p</span> <span class=o>=</span> <span class=n>beam</span><span class=o>.</span><span class=n>Pipeline</span><span class=p>(</span><span class=n>options</span><span class=o>=</span><span class=n>options</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 82</span><span class=cl>    <span class=p>(</span>
</span></span><span class=line><span class=ln> 83</span><span class=cl>        <span class=n>p</span>
</span></span><span class=line><span class=ln> 84</span><span class=cl>        <span class=o>|</span> <span class=s2>&#34;Read from Kafka&#34;</span>
</span></span><span class=line><span class=ln> 85</span><span class=cl>        <span class=o>&gt;&gt;</span> <span class=n>kafka</span><span class=o>.</span><span class=n>ReadFromKafka</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 86</span><span class=cl>            <span class=n>consumer_config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=ln> 87</span><span class=cl>                <span class=s2>&#34;bootstrap.servers&#34;</span><span class=p>:</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 88</span><span class=cl>                    <span class=s2>&#34;BOOTSTRAP_SERVERS&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 89</span><span class=cl>                    <span class=s2>&#34;host.docker.internal:29092&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 90</span><span class=cl>                <span class=p>),</span>
</span></span><span class=line><span class=ln> 91</span><span class=cl>                <span class=s2>&#34;auto.offset.reset&#34;</span><span class=p>:</span> <span class=s2>&#34;earliest&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 92</span><span class=cl>                <span class=c1># &#34;enable.auto.commit&#34;: &#34;true&#34;,</span>
</span></span><span class=line><span class=ln> 93</span><span class=cl>                <span class=s2>&#34;group.id&#34;</span><span class=p>:</span> <span class=s2>&#34;kafka-io&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln> 94</span><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=ln> 95</span><span class=cl>            <span class=n>topics</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;website-visit&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=ln> 96</span><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=ln> 97</span><span class=cl>        <span class=o>|</span> <span class=s2>&#34;Decode messages&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=n>decode_message</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 98</span><span class=cl>        <span class=o>|</span> <span class=s2>&#34;Parse elements&#34;</span> <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=n>parse_json</span><span class=p>)</span><span class=o>.</span><span class=n>with_output_types</span><span class=p>(</span><span class=n>EventLog</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 99</span><span class=cl>        <span class=o>|</span> <span class=s2>&#34;Create messages&#34;</span>
</span></span><span class=line><span class=ln>100</span><span class=cl>        <span class=o>&gt;&gt;</span> <span class=n>beam</span><span class=o>.</span><span class=n>Map</span><span class=p>(</span><span class=n>create_message</span><span class=p>)</span><span class=o>.</span><span class=n>with_output_types</span><span class=p>(</span><span class=n>typing</span><span class=o>.</span><span class=n>Tuple</span><span class=p>[</span><span class=nb>bytes</span><span class=p>,</span> <span class=nb>bytes</span><span class=p>])</span>
</span></span><span class=line><span class=ln>101</span><span class=cl>        <span class=o>|</span> <span class=s2>&#34;Write to Kafka&#34;</span>
</span></span><span class=line><span class=ln>102</span><span class=cl>        <span class=o>&gt;&gt;</span> <span class=n>kafka</span><span class=o>.</span><span class=n>WriteToKafka</span><span class=p>(</span>
</span></span><span class=line><span class=ln>103</span><span class=cl>            <span class=n>producer_config</span><span class=o>=</span><span class=p>{</span>
</span></span><span class=line><span class=ln>104</span><span class=cl>                <span class=s2>&#34;bootstrap.servers&#34;</span><span class=p>:</span> <span class=n>os</span><span class=o>.</span><span class=n>getenv</span><span class=p>(</span>
</span></span><span class=line><span class=ln>105</span><span class=cl>                    <span class=s2>&#34;BOOTSTRAP_SERVERS&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>106</span><span class=cl>                    <span class=s2>&#34;host.docker.internal:29092&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>107</span><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=ln>108</span><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=ln>109</span><span class=cl>            <span class=n>topic</span><span class=o>=</span><span class=s2>&#34;website-out&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>110</span><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=ln>111</span><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=ln>112</span><span class=cl>
</span></span><span class=line><span class=ln>113</span><span class=cl>    <span class=n>logging</span><span class=o>.</span><span class=n>getLogger</span><span class=p>()</span><span class=o>.</span><span class=n>setLevel</span><span class=p>(</span><span class=n>logging</span><span class=o>.</span><span class=n>INFO</span><span class=p>)</span>
</span></span><span class=line><span class=ln>114</span><span class=cl>    <span class=n>logging</span><span class=o>.</span><span class=n>info</span><span class=p>(</span><span class=s2>&#34;Building pipeline ...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>115</span><span class=cl>
</span></span><span class=line><span class=ln>116</span><span class=cl>    <span class=n>p</span><span class=o>.</span><span class=n>run</span><span class=p>()</span><span class=o>.</span><span class=n>wait_until_finish</span><span class=p>()</span>
</span></span><span class=line><span class=ln>117</span><span class=cl>
</span></span><span class=line><span class=ln>118</span><span class=cl>
</span></span><span class=line><span class=ln>119</span><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=ln>120</span><span class=cl>    <span class=n>run</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=start-flinkkafka-clusters data-numberify>Start Flink/Kafka Clusters<a class="anchor ms-1" href=#start-flinkkafka-clusters></a></h3><p>To run the pipeline, we need to launch a Kafka cluster and optionally a Flink cluster. They can be created using the startup script with the <em>-a</em> or <em>-k</em> option. We create both the clusters for the example pipeline of this post.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl><span class=c1># start both flink and kafka cluster</span>
</span></span><span class=line><span class=ln>2</span><span class=cl>$ ./setup/start-flink-env.sh -a
</span></span><span class=line><span class=ln>3</span><span class=cl>
</span></span><span class=line><span class=ln>4</span><span class=cl><span class=c1># start only kafka cluster</span>
</span></span><span class=line><span class=ln>5</span><span class=cl><span class=c1># ./setup/start-flink-env.sh -k</span>
</span></span></code></pre></div><p>Once the clusters are launched, we can check the Kafka resources on <em>localhost:8080</em>.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2024-04-18-beam-local-dev-3/kafka-ui.png loading=lazy width=1208 height=344></picture></p><p>And the Flink web UI is accessible on <em>localhost:8081</em>.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2024-04-18-beam-local-dev-3/flink-ui.png loading=lazy width=1204 height=718></picture></p><h3 id=generate-data data-numberify>Generate Data<a class="anchor ms-1" href=#generate-data></a></h3><p>For streaming data generation, we can use the website visit log generator that was introduced in <a href=/blog/2024-03-28-beam-local-dev-1>Part 1</a>. We can execute the script while specifying the <em>source</em> argument to <em>streaming</em>. Below shows an example of generating Kafka messages for the streaming pipeline.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ python datagen/generate_data.py --source streaming --num_users <span class=m>5</span> --delay_seconds 0.5
</span></span><span class=line><span class=ln>2</span><span class=cl><span class=c1># 10 events created so far...</span>
</span></span><span class=line><span class=ln>3</span><span class=cl><span class=c1># {&#39;ip&#39;: &#39;126.1.20.79&#39;, &#39;id&#39;: &#39;-2901668335848977108&#39;, &#39;lat&#39;: 35.6895, &#39;lng&#39;: 139.6917, &#39;user_agent&#39;: &#39;Mozilla/5.0 (Windows; U; Windows NT 5.1) AppleWebKit/533.44.1 (KHTML, like Gecko) Version/4.0.2 Safari/533.44.1&#39;, &#39;age_bracket&#39;: &#39;26-40&#39;, &#39;opted_into_marketing&#39;: True, &#39;http_request&#39;: &#39;GET chromista.html HTTP/1.0&#39;, &#39;http_response&#39;: 200, &#39;file_size_bytes&#39;: 316, &#39;event_datetime&#39;: &#39;2024-04-14T21:51:33.042&#39;, &#39;event_ts&#39;: 1713095493042}</span>
</span></span><span class=line><span class=ln>4</span><span class=cl><span class=c1># 20 events created so far...</span>
</span></span><span class=line><span class=ln>5</span><span class=cl><span class=c1># {&#39;ip&#39;: &#39;126.1.20.79&#39;, &#39;id&#39;: &#39;-2901668335848977108&#39;, &#39;lat&#39;: 35.6895, &#39;lng&#39;: 139.6917, &#39;user_agent&#39;: &#39;Mozilla/5.0 (Windows; U; Windows NT 5.1) AppleWebKit/533.44.1 (KHTML, like Gecko) Version/4.0.2 Safari/533.44.1&#39;, &#39;age_bracket&#39;: &#39;26-40&#39;, &#39;opted_into_marketing&#39;: True, &#39;http_request&#39;: &#39;GET archaea.html HTTP/1.0&#39;, &#39;http_response&#39;: 200, &#39;file_size_bytes&#39;: 119, &#39;event_datetime&#39;: &#39;2024-04-14T21:51:38.090&#39;, &#39;event_ts&#39;: 1713095498090}</span>
</span></span><span class=line><span class=ln>6</span><span class=cl><span class=c1># ...</span>
</span></span></code></pre></div><h3 id=run-pipeline data-numberify>Run Pipeline<a class="anchor ms-1" href=#run-pipeline></a></h3><p>The streaming pipeline can be executed as shown below. As mentioned, we use the local Flink cluster by specifying the <em>use_own</em> argument.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ python section3/kafka_io.py --use_own
</span></span></code></pre></div><p>After a while, we can check both the input and output topics in the <em>Topics</em> section of <em>kafka-ui</em>.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2024-04-18-beam-local-dev-3/kafka-topics.png loading=lazy width=1208 height=389></picture></p><p>We can use the Flink web UI to monitor the pipeline as a Flink job. When we click the <em>kafka-io</em> job in the <em>Running Jobs</em> section, we see 3 operations are linked in the <em>Overview</em> tab. The first two operations are polling and reading Kafka source description while the actual pipeline runs in the last operation.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2024-04-18-beam-local-dev-3/flink-job.png loading=lazy width=1284 height=937></picture></p><p>Note that, although the main pipeline&rsquo;s SDK harness is set to <em>LOOPBACK</em>, the Kafka I/O runs on the Java SDK, and it associates with its own SDK harness, which defaults to <em>DOCKER</em>. We can check the Kafka I/O&rsquo;s SDK harness process is launched in a container as following.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl>$ docker ps -a --format <span class=s2>&#34;table {{.ID}}\t{{.Image}}\t{{.Command}}\t{{.Status}}&#34;</span>
</span></span><span class=line><span class=ln>2</span><span class=cl>CONTAINER ID   IMAGE                           COMMAND                  STATUS
</span></span><span class=line><span class=ln>3</span><span class=cl>3cd5a628a970   apache/beam_java11_sdk:2.53.0   <span class=s2>&#34;/opt/apache/beam/bo…&#34;</span>   Up <span class=m>4</span> minutes
</span></span></code></pre></div><h3 id=stop-flinkkafka-clusters data-numberify>Stop Flink/Kafka Clusters<a class="anchor ms-1" href=#stop-flinkkafka-clusters></a></h3><p>After we stop the pipeline and data generation scripts, we can tear down the Flink and Kafka clusters using the bash script that was explained earlier with <em>-a</em> or <em>-k</em> arguments.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=ln>1</span><span class=cl><span class=c1># stop both flink and kafka cluster</span>
</span></span><span class=line><span class=ln>2</span><span class=cl>$ ./setup/stop-flink-env.sh -a
</span></span><span class=line><span class=ln>3</span><span class=cl>
</span></span><span class=line><span class=ln>4</span><span class=cl><span class=c1># stop only kafka cluster</span>
</span></span><span class=line><span class=ln>5</span><span class=cl><span class=c1># ./setup/stop-flink-env.sh -k</span>
</span></span></code></pre></div><h2 id=summary data-numberify>Summary<a class="anchor ms-1" href=#summary></a></h2><p>The Apache Flink Runner supports Python, and it has good features that allow us to develop streaming pipelines effectively. We first discussed the <em>portability layer</em> of Apache Beam as it helps understand (1) how a pipeline developed by the Python SDK can be executed in the Flink Runner that only understands Java JAR and (2) how multiple SDKs can be used in a single pipeline. Then we moved on to how to manage local Flink and Kafka clusters using bash scripts. Finally, we ended up illustrating a simple streaming pipeline, which reads and writes website visit logs from and to Kafka topics.</p></div></div></div><div class=card-footer><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-down post-prev-icon me-1" data-fa-transform=rotate-90></i>
<a href=/blog/2024-04-04-beam-local-dev-2/>Apache Beam Local Development With Python - Part 2 Batch Pipelines</a></div><div class="post-nav post-next"><a href=/blog/2024-05-02-beam-local-dev-4/>Apache Beam Local Development With Python - Part 4 Streaming Pipelines</a>
<i class="fas fa-fw fa-chevron-down post-next-icon ms-1" data-fa-transform=rotate-270></i></div></div></div></article><section class="related-posts row card component"><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Related Posts</h2></div><div class="card-body slide px-1"><div class="slide-inner row gx-0"><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2024-04-04-beam-local-dev-2/featured_huc60febc0cd72955054b95c3bf20650a7_55405_500x0_resize_box_3.png media="(max-width: 576px)" height=330 width=500><img class=img-fluid height=119 width=180 alt=featured.png src=/blog/2024-04-04-beam-local-dev-2/featured_huc60febc0cd72955054b95c3bf20650a7_55405_180x0_resize_box_3.png data-src=/blog/2024-04-04-beam-local-dev-2/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2024-04-04-beam-local-dev-2/>Apache Beam Local Development With Python - Part 2 Batch Pipelines</a><div class="post-meta mb-0">April 4, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_500x0_resize_box_3.png media="(max-width: 576px)" height=338 width=500><img class=img-fluid height=122 width=180 alt=featured.png src=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_180x0_resize_box_3.png data-src=/blog/2024-03-28-beam-local-dev-1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2024-03-28-beam-local-dev-1/>Apache Beam Local Development With Python - Part 1 Pipeline, Notebook, SQL and DataFrame</a><div class="post-meta mb-0">March 28, 2024</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-12-07-flink-spark-local-dev/featured_hu7a73c8ca7d8b8a4ddf49d1a9b8fe40bd_133053_500x0_resize_box_3.png media="(max-width: 576px)" height=373 width=500><img class=img-fluid height=134 width=180 alt=featured.png src=/blog/2023-12-07-flink-spark-local-dev/featured_hu7a73c8ca7d8b8a4ddf49d1a9b8fe40bd_133053_180x0_resize_box_3.png data-src=/blog/2023-12-07-flink-spark-local-dev/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-12-07-flink-spark-local-dev/>Setup Local Development Environment for Apache Flink and Spark Using EMR Container Images</a><div class="post-meta mb-0">December 7, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-11-23-real-time-streaming-with-kafka-and-flink-5/featured_hu934f3fa21a75bb8ccc480bfe067ce5a2_112340_500x0_resize_box_3.png media="(max-width: 576px)" height=301 width=500><img class=img-fluid height=108 width=180 alt=featured.png src=/blog/2023-11-23-real-time-streaming-with-kafka-and-flink-5/featured_hu934f3fa21a75bb8ccc480bfe067ce5a2_112340_180x0_resize_box_3.png data-src=/blog/2023-11-23-real-time-streaming-with-kafka-and-flink-5/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-11-23-real-time-streaming-with-kafka-and-flink-5/>Real Time Streaming With Kafka and Flink - Lab 4 Clean, Aggregate, and Enrich Events With Flink</a><div class="post-meta mb-0">November 23, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-11-16-real-time-streaming-with-kafka-and-flink-4/featured_hua0f43666abbaff872f0e4bf2da3a3c1a_160359_500x0_resize_box_3.png media="(max-width: 576px)" height=301 width=500><img class=img-fluid height=108 width=180 alt=featured.png src=/blog/2023-11-16-real-time-streaming-with-kafka-and-flink-4/featured_hua0f43666abbaff872f0e4bf2da3a3c1a_160359_180x0_resize_box_3.png data-src=/blog/2023-11-16-real-time-streaming-with-kafka-and-flink-4/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-11-16-real-time-streaming-with-kafka-and-flink-4/>Real Time Streaming With Kafka and Flink - Lab 3 Transform and Write Data to S3 From Kafka Using Flink</a><div class="post-meta mb-0">November 16, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured_hucc8053169eb3042cf56156294e716152_139114_500x0_resize_box_3.png media="(max-width: 576px)" height=301 width=500><img class=img-fluid height=108 width=180 alt=featured.png src=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured_hucc8053169eb3042cf56156294e716152_139114_180x0_resize_box_3.png data-src=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-11-09-real-time-streaming-with-kafka-and-flink-3/>Real Time Streaming With Kafka and Flink - Lab 2 Write Data to Kafka From S3 Using Flink</a><div class="post-meta mb-0">November 9, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_500x0_resize_box_3.png media="(max-width: 576px)" height=241 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2023-10-19-build-pyflink-apps/featured_hubbcf607e326a86791dcaeb23a1bfd08e_154736_180x0_resize_box_3.png data-src=/blog/2023-10-19-build-pyflink-apps/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-10-19-build-pyflink-apps/>Building Apache Flink Applications in Python</a><div class="post-meta mb-0">October 19, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-10-05-real-time-streaming-with-kafka-and-flink-1/featured_hua45c2e579ce8f6bc0318d15d62654514_138141_500x0_resize_box_3.png media="(max-width: 576px)" height=299 width=500><img class=img-fluid height=108 width=180 alt=featured.png src=/blog/2023-10-05-real-time-streaming-with-kafka-and-flink-1/featured_hua45c2e579ce8f6bc0318d15d62654514_138141_180x0_resize_box_3.png data-src=/blog/2023-10-05-real-time-streaming-with-kafka-and-flink-1/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-10-05-real-time-streaming-with-kafka-and-flink-1/>Real Time Streaming With Kafka and Flink - Introduction</a><div class="post-meta mb-0">October 5, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-09-14-fraud-detection-part-2/featured_hu6e12c35fe727128749446c930c7ac3f6_66221_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2023-09-14-fraud-detection-part-2/featured_hu6e12c35fe727128749446c930c7ac3f6_66221_180x0_resize_box_3.png data-src=/blog/2023-09-14-fraud-detection-part-2/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-09-14-fraud-detection-part-2/>Kafka, Flink and DynamoDB for Real Time Fraud Detection - Part 2 Deployment via AWS Managed Flink</a><div class="post-meta mb-0">September 14, 2023</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><picture><source srcset=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/featured_hue908d327a4e776f04c90ce3d9151d268_74618_500x0_resize_box_3.png media="(max-width: 576px)" height=256 width=500><img class=img-fluid height=92 width=180 alt=featured.png src=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/featured_hue908d327a4e776f04c90ce3d9151d268_74618_180x0_resize_box_3.png data-src=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/featured.png loading=lazy>
</picture><a class=post-title href=/blog/2023-09-04-getting-started-with-pyflink-on-aws-part-3/>Getting Started With Pyflink on AWS - Part 3 AWS Managed Flink and MSK</a><div class="post-meta mb-0">September 4, 2023</div></div></div></div><button class=slide-control-left>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i>
<span class=visually-hidden>Left</span>
</button>
<button class=slide-control-right>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-270></i>
<span class=visually-hidden>Right</span></button></div></section><div class="card component row post-comments" id=post-comments><div class=card-header><h2 class="card-title my-2 fs-4 text-surface">Comments</h2></div><div class=card-body><div class=giscus></div></div></div></div></div><aside class="col-xxl-4 sidebar d-flex"><div class="container d-flex flex-column"><div class="accordion profile"><div class="accordion-item card row text-center component"><div class="accordion-header card-header border-0" id=profile-header><a class="accordion-button d-lg-none mb-2 shadow-none p-0 bg-transparent text-surface" role=button data-bs-toggle=collapse href=#profile aria-expanded=true aria-controls=profile>Profile</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=profile aria-labelledby=profile-header><div class="col-12 d-flex align-items-center justify-content-center"><picture><img class="profile-avatar rounded-circle" alt="Jaehyeon Kim" src="https://jaehyeon.me/images/profile.png?v=5c60aafa6dc93e93ca5aaa870a22b15f" loading=lazy data-viewer-invisible width=200 height=200></picture></div><div class="col-12 profile-meta"><div class="profile-name fw-fold fs-lg">Jaehyeon Kim</div><div class=profile-bio>⚙️ Data Engineer 📝 Blogger 👯 OSS Maintainer</div></div><nav class="social-links nav justify-content-center mt-1 justify-content-around"><a class="nav-link social-link" href=mailto:dottami@gmail.com title=Email><i class="fas fa-fw fa-2x fa-envelope" style=color:#0963ac></i>
</a><a class="nav-link social-link" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fa-2x fab fa-github"></i>
</a><a class="nav-link social-link" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fa-2x fab fa-linkedin-in" style=color:#0a66c2></i>
</a><a class="nav-link social-link" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fa-2x fab fa-paypal"></i></a></nav></div></div></div><div class="accordion taxonomies-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#taxonomies-toggle aria-expanded=true aria-controls=taxonomies-toggle>Taxonomies</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=taxonomies-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=taxonomyCategoriesTab data-bs-toggle=tab data-bs-target=#taxonomyCategories type=button role=tab aria-controls=taxonomyCategories aria-selected=true>
Categories</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyTagsTab data-bs-toggle=tab data-bs-target=#taxonomyTags type=button role=tab aria-controls=taxonomyTags aria-selected=true>
Tags</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomySeriesTab data-bs-toggle=tab data-bs-target=#taxonomySeries type=button role=tab aria-controls=taxonomySeries aria-selected=true>
Series</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyArchivesTab data-bs-toggle=tab data-bs-target=#taxonomyArchives type=button role=tab aria-controls=taxonomyArchives aria-selected=true>
Archives</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=taxonomyCategories role=tabpanel aria-labelledby=taxonomyCategoriesTab tabindex=0><a href=/categories/data-streaming/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Streaming">Data Streaming
<span class="badge badge-sm text-secondary bg-white ms-1">28</span>
</a><a href=/categories/data-engineering/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Engineering">Data Engineering
<span class="badge badge-sm text-secondary bg-white ms-1">26</span>
</a><a href=/categories/development/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Development>Development
<span class="badge badge-sm text-secondary bg-white ms-1">19</span>
</a><a href=/categories/apache-beam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Beam">Apache Beam
<span class="badge badge-sm text-secondary bg-white ms-1">16</span>
</a><a href=/categories/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/categories/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/categories/machine-learning/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Machine Learning">Machine Learning
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/categories/general/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=General>General
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/categories/data-product/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Product">Data Product
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a></div><div class=tab-pane id=taxonomyTags role=tabpanel aria-labelledby=taxonomyTagsTab tabindex=0><a href=/tags/docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Docker>Docker
<span class="badge badge-sm text-secondary bg-white ms-1">65</span>
</a><a href=/tags/python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Python>Python
<span class="badge badge-sm text-secondary bg-white ms-1">65</span>
</a><a href=/tags/docker-compose/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Docker Compose">Docker Compose
<span class="badge badge-sm text-secondary bg-white ms-1">55</span>
</a><a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">46</span>
</a><a href=/tags/aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=AWS>AWS
<span class="badge badge-sm text-secondary bg-white ms-1">43</span>
</a><a href=/tags/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">36</span>
</a><a href=/tags/apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Flink">Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">29</span>
</a><a href=/tags/amazon-msk/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK">Amazon MSK
<span class="badge badge-sm text-secondary bg-white ms-1">21</span>
</a><a href=/tags/apache-beam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Beam">Apache Beam
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/tags/apache-spark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Spark">Apache Spark
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/tags/kafka-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Kafka Connect">Kafka Connect
<span class="badge badge-sm text-secondary bg-white ms-1">17</span>
</a><a href=/tags/aws-lambda/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Lambda">AWS Lambda
<span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/tags/terraform/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Terraform>Terraform
<span class="badge badge-sm text-secondary bg-white ms-1">14</span>
</a><a href=/tags/data-build-tool-dbt/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Data Build Tool (DBT)">Data Build Tool (DBT)
<span class="badge badge-sm text-secondary bg-white ms-1">13</span>
</a><a href=/tags/amazon-emr/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EMR">Amazon EMR
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/pyflink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PyFlink>PyFlink
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/tags/kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Kubernetes>Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">10</span>
</a><a href=/tags/amazon-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK Connect">Amazon MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">9</span>
</a><a href=/tags/grpc/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=GRPC>GRPC
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/tags/amazon-athena/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Athena">Amazon Athena
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/minikube/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Minikube>Minikube
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/pyspark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PySpark>PySpark
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/tags/amazon-dynamodb/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon DynamoDB">Amazon DynamoDB
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/apache-airflow/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Airflow">Apache Airflow
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/rserve/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Rserve>Rserve
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/visual-studio-code/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Visual Studio Code">Visual Studio Code
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/tags/amazon-api-gateway/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon API Gateway">Amazon API Gateway
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-managed-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Managed Flink">Amazon Managed Flink
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-managed-service-for-apache-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Managed Service for Apache Flink">Amazon Managed Service for Apache Flink
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-quicksight/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon QuickSight">Amazon QuickSight
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/aws-glue/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Glue">AWS Glue
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/bigquery/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=BigQuery>BigQuery
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/fastapi/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=FastAPI>FastAPI
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/gcp/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=GCP>GCP
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/opensearch/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=OpenSearch>OpenSearch
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/postgresql/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PostgreSQL>PostgreSQL
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/security/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Security>Security
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/shiny/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Shiny>Shiny
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/tags/amazon-eks/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EKS">Amazon EKS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/tags/amazon-opensearch-service/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon OpenSearch Service">Amazon OpenSearch Service
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=https://jaehyeon.me/tags class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=ALL>ALL
<span class="badge badge-sm text-secondary bg-white ms-1">109</span></a></div><div class=tab-pane id=taxonomySeries role=tabpanel aria-labelledby=taxonomySeriesTab tabindex=0><a href=/series/kafka-development-with-docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development With Docker">Kafka Development With Docker
<span class="badge badge-sm text-secondary bg-white ms-1">11</span>
</a><a href=/series/apache-beam-python-examples/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Apache Beam Python Examples">Apache Beam Python Examples
<span class="badge badge-sm text-secondary bg-white ms-1">10</span>
</a><a href=/series/real-time-streaming-with-kafka-and-flink/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Real Time Streaming With Kafka and Flink">Real Time Streaming With Kafka and Flink
<span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/series/dbt-pizza-shop-demo/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT Pizza Shop Demo">DBT Pizza Shop Demo
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/series/tree-based-methods-in-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Tree Based Methods in R">Tree Based Methods in R
<span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/series/apache-beam-local-development-with-python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Apache Beam Local Development With Python">Apache Beam Local Development With Python
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/dbt-for-effective-data-transformation-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT for Effective Data Transformation on AWS">DBT for Effective Data Transformation on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/kafka-connect-for-aws-services-integration/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Connect for AWS Services Integration">Kafka Connect for AWS Services Integration
<span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/series/serverless-data-product/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Serverless Data Product">Serverless Data Product
<span class="badge badge-sm text-secondary bg-white ms-1">4</span>
</a><a href=/series/data-lake-demo-using-change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Data Lake Demo Using Change Data Capture">Data Lake Demo Using Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/getting-started-with-pyflink-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Getting Started With Pyflink on AWS">Getting Started With Pyflink on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/kafka-development-on-kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development on Kubernetes">Kafka Development on Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/parallel-processing-on-single-machine/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Parallel Processing on Single Machine">Parallel Processing on Single Machine
<span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/series/api-development-with-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="API Development With R">API Development With R
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/dbt-guide-for-production/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT Guide for Production">DBT Guide for Production
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/deploy-python-stream-processing-app-on-kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Deploy Python Stream Processing App on Kubernetes">Deploy Python Stream Processing App on Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/integrate-schema-registry-with-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Integrate Schema Registry With MSK Connect">Integrate Schema Registry With MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/kafka-flink-and-dynamodb-for-real-time-fraud-detection/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka, Flink and DynamoDB for Real Time Fraud Detection">Kafka, Flink and DynamoDB for Real Time Fraud Detection
<span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/series/simplify-streaming-ingestion-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Simplify Streaming Ingestion on AWS">Simplify Streaming Ingestion on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a></div><div class=tab-pane id=taxonomyArchives role=tabpanel aria-labelledby=taxonomyArchivesTab tabindex=0><a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2025>2025 <span class="badge badge-sm text-secondary bg-white ms-1">3</span>
</a><a href=/archives/2024/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2024>2024 <span class="badge badge-sm text-secondary bg-white ms-1">29</span>
</a><a href=/archives/2023/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2023>2023 <span class="badge badge-sm text-secondary bg-white ms-1">39</span>
</a><a href=/archives/2022/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2022>2022 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2021/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2021>2021 <span class="badge badge-sm text-secondary bg-white ms-1">7</span>
</a><a href=/archives/2020/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2020>2020 <span class="badge badge-sm text-secondary bg-white ms-1">1</span>
</a><a href=/archives/2019/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2019>2019 <span class="badge badge-sm text-secondary bg-white ms-1">5</span>
</a><a href=/archives/2018/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2018>2018 <span class="badge badge-sm text-secondary bg-white ms-1">2</span>
</a><a href=/archives/2017/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2017>2017 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2016/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2016>2016 <span class="badge badge-sm text-secondary bg-white ms-1">6</span>
</a><a href=/archives/2015/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2015>2015 <span class="badge badge-sm text-secondary bg-white ms-1">15</span>
</a><a href=/archives/2014/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2014>2014 <span class="badge badge-sm text-secondary bg-white ms-1">5</span></a></div></div></div></div></div><div class="accordion posts-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#posts-toggle aria-expanded=true aria-controls=posts-toggle>Posts</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=posts-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=featured-posts-tab data-bs-toggle=tab data-bs-target=#featured-posts type=button role=tab aria-controls=featured-posts aria-selected=true>
Featured Posts</button></li><li class=nav-item role=presentation><button class=nav-link id=recent-posts-tab data-bs-toggle=tab data-bs-target=#recent-posts type=button role=tab aria-controls=recent-posts aria-selected=true>
Recent Posts</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=featured-posts role=tabpanel aria-labelledby=featured-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2025-02-18-realtime-dashboard-1/featured_huee9b93665e527412f696e9c6f53a7850_1207440_500x0_resize_box_1.gif media="(max-width: 576px)" height=211 width=500><img class=img-fluid height=76 width=180 alt=featured.gif src=/blog/2025-02-18-realtime-dashboard-1/featured_huee9b93665e527412f696e9c6f53a7850_1207440_180x0_resize_box_1.gif data-src=/blog/2025-02-18-realtime-dashboard-1/featured.gif loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2025-02-18-realtime-dashboard-1/>Realtime Dashboard With FastAPI, Streamlit and Next.js - Part 1 Data Producer</a><div class="post-meta mt-2"><span class=post-date>February 18, 2025</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-11-07-cdc-local-dev/featured_hu1be5b7cd9299c136c309544dd6dd598d_83605_500x0_resize_box_3.png media="(max-width: 576px)" height=369 width=500><img class=img-fluid height=133 width=180 alt=featured.png src=/blog/2024-11-07-cdc-local-dev/featured_hu1be5b7cd9299c136c309544dd6dd598d_83605_180x0_resize_box_3.png data-src=/blog/2024-11-07-cdc-local-dev/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-11-07-cdc-local-dev/>Change Data Capture (CDC) Local Development With PostgreSQL, Debezium Server and Pub/Sub Emulator</a><div class="post-meta mt-2"><span class=post-date>November 7, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-09-13-dbt-guide/featured_hu02c411e2b810e83058a2abf514c3ab2e_71185_500x0_resize_box_3.png media="(max-width: 576px)" height=253 width=500><img class=img-fluid height=91 width=180 alt=featured.png src=/blog/2024-09-13-dbt-guide/featured_hu02c411e2b810e83058a2abf514c3ab2e_71185_180x0_resize_box_3.png data-src=/blog/2024-09-13-dbt-guide/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-09-13-dbt-guide/>Guide to Running DBT in Production</a><div class="post-meta mt-2"><span class=post-date>September 13, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-09-05-dbt-cicd-demo/featured_huad11874eeea265d1d4cc984ffd50128c_60835_500x0_resize_box_3.png media="(max-width: 576px)" height=367 width=500><img class=img-fluid height=132 width=180 alt=featured.png src=/blog/2024-09-05-dbt-cicd-demo/featured_huad11874eeea265d1d4cc984ffd50128c_60835_180x0_resize_box_3.png data-src=/blog/2024-09-05-dbt-cicd-demo/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-09-05-dbt-cicd-demo/>DBT CI/CD Demo With BigQuery and GitHub Actions</a><div class="post-meta mt-2"><span class=post-date>September 5, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-08-22-cache-using-shared-object/featured_hu9078f8221b3da3b9c4a7fded6a2842e2_49574_500x0_resize_box_3.png media="(max-width: 576px)" height=211 width=500><img class=img-fluid height=76 width=180 alt=featured.png src=/blog/2024-08-22-cache-using-shared-object/featured_hu9078f8221b3da3b9c4a7fded6a2842e2_49574_180x0_resize_box_3.png data-src=/blog/2024-08-22-cache-using-shared-object/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-08-22-cache-using-shared-object/>Cache Data on Apache Beam Pipelines Using a Shared Object</a><div class="post-meta mt-2"><span class=post-date>August 22, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-07-04-beam-examples-1/featured_hud3ce9831fcc98de0424cfc6e53706491_96881_500x0_resize_box_3.png media="(max-width: 576px)" height=318 width=500><img class=img-fluid height=115 width=180 alt=featured.png src=/blog/2024-07-04-beam-examples-1/featured_hud3ce9831fcc98de0424cfc6e53706491_96881_180x0_resize_box_3.png data-src=/blog/2024-07-04-beam-examples-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-07-04-beam-examples-1/>Apache Beam Python Examples - Part 1 Calculate K Most Frequent Words and Max Word Length</a><div class="post-meta mt-2"><span class=post-date>July 4, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-05-30-beam-deploy-1/featured_hu716373a174df6c1bd689346398ab2e3c_64457_500x0_resize_box_3.png media="(max-width: 576px)" height=365 width=500><img class=img-fluid height=131 width=180 alt=featured.png src=/blog/2024-05-30-beam-deploy-1/featured_hu716373a174df6c1bd689346398ab2e3c_64457_180x0_resize_box_3.png data-src=/blog/2024-05-30-beam-deploy-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-05-30-beam-deploy-1/>Deploy Python Stream Processing App on Kubernetes - Part 1 PyFlink Application</a><div class="post-meta mt-2"><span class=post-date>May 30, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_500x0_resize_box_3.png media="(max-width: 576px)" height=338 width=500><img class=img-fluid height=122 width=180 alt=featured.png src=/blog/2024-03-28-beam-local-dev-1/featured_hu8df3c1065468b257d73fe4ccb72b4c47_88260_180x0_resize_box_3.png data-src=/blog/2024-03-28-beam-local-dev-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-03-28-beam-local-dev-1/>Apache Beam Local Development With Python - Part 1 Pipeline, Notebook, SQL and DataFrame</a><div class="post-meta mt-2"><span class=post-date>March 28, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_500x0_resize_box_3.png media="(max-width: 576px)" height=238 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2024-01-18-dbt-pizza-shop-1/featured_hua8fc52ecfe83e5abaf1872cc948e583f_85093_180x0_resize_box_3.png data-src=/blog/2024-01-18-dbt-pizza-shop-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-01-18-dbt-pizza-shop-1/>Data Build Tool (Dbt) Pizza Shop Demo - Part 1 Modelling on PostgreSQL</a><div class="post-meta mt-2"><span class=post-date>January 18, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_500x0_resize_box_3.png media="(max-width: 576px)" height=263 width=500><img class=img-fluid height=95 width=180 alt=featured.png src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured_hu216964ff6c7a4996550e95c3e0e5f209_108975_180x0_resize_box_3.png data-src=/blog/2023-12-21-kafka-development-on-k8s-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-12-21-kafka-development-on-k8s-part-1/>Kafka Development on Kubernetes - Part 1 Cluster Setup</a><div class="post-meta mt-2"><span class=post-date>December 21, 2023</span></div></div></div></li></ul></div><div class=tab-pane id=recent-posts role=tabpanel aria-labelledby=recent-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2025-03-04-realtime-dashboard-3/featured_huc44ed1742dbfab4aec394da7a1c831d6_323475_500x0_resize_box_1.gif media="(max-width: 576px)" height=239 width=500><img class=img-fluid height=86 width=180 alt=featured.gif src=/blog/2025-03-04-realtime-dashboard-3/featured_huc44ed1742dbfab4aec394da7a1c831d6_323475_180x0_resize_box_1.gif data-src=/blog/2025-03-04-realtime-dashboard-3/featured.gif loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2025-03-04-realtime-dashboard-3/>Realtime Dashboard With FastAPI, Streamlit and Next.js - Part 3 Next.js Dashboard</a><div class="post-meta mt-2"><span class=post-date>March 4, 2025</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2025-02-25-realtime-dashboard-2/featured_hu4cdb2491898d8b9c07e29ade60c511fa_417216_500x0_resize_box_1.gif media="(max-width: 576px)" height=239 width=500><img class=img-fluid height=86 width=180 alt=featured.gif src=/blog/2025-02-25-realtime-dashboard-2/featured_hu4cdb2491898d8b9c07e29ade60c511fa_417216_180x0_resize_box_1.gif data-src=/blog/2025-02-25-realtime-dashboard-2/featured.gif loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2025-02-25-realtime-dashboard-2/>Realtime Dashboard With FastAPI, Streamlit and Next.js - Part 2 Streamlit Dashboard</a><div class="post-meta mt-2"><span class=post-date>February 25, 2025</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2025-02-18-realtime-dashboard-1/featured_huee9b93665e527412f696e9c6f53a7850_1207440_500x0_resize_box_1.gif media="(max-width: 576px)" height=211 width=500><img class=img-fluid height=76 width=180 alt=featured.gif src=/blog/2025-02-18-realtime-dashboard-1/featured_huee9b93665e527412f696e9c6f53a7850_1207440_180x0_resize_box_1.gif data-src=/blog/2025-02-18-realtime-dashboard-1/featured.gif loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2025-02-18-realtime-dashboard-1/>Realtime Dashboard With FastAPI, Streamlit and Next.js - Part 1 Data Producer</a><div class="post-meta mt-2"><span class=post-date>February 18, 2025</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-12-19-beam-examples-10/featured_hub568c2243b8abbde1de177b7ded1ccd4_305211_500x0_resize_box_3.png media="(max-width: 576px)" height=310 width=500><img class=img-fluid height=112 width=180 alt=featured.png src=/blog/2024-12-19-beam-examples-10/featured_hub568c2243b8abbde1de177b7ded1ccd4_305211_180x0_resize_box_3.png data-src=/blog/2024-12-19-beam-examples-10/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-12-19-beam-examples-10/>Apache Beam Python Examples - Part 10 Develop Streaming File Reader Using Splittable DoFn</a><div class="post-meta mt-2"><span class=post-date>December 19, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-12-05-beam-examples-9/featured_huaaa7329b84aeb9db71963413acd643af_309371_500x0_resize_box_3.png media="(max-width: 576px)" height=317 width=500><img class=img-fluid height=114 width=180 alt=featured.png src=/blog/2024-12-05-beam-examples-9/featured_huaaa7329b84aeb9db71963413acd643af_309371_180x0_resize_box_3.png data-src=/blog/2024-12-05-beam-examples-9/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-12-05-beam-examples-9/>Apache Beam Python Examples - Part 9 Develop Batch File Reader and PiSampler Using Splittable DoFn</a><div class="post-meta mt-2"><span class=post-date>December 5, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-11-21-beam-examples-8/featured_hua1bed0ac2a8d7df60d85401d258c29bb_402888_500x0_resize_box_3.png media="(max-width: 576px)" height=304 width=500><img class=img-fluid height=109 width=180 alt=featured.png src=/blog/2024-11-21-beam-examples-8/featured_hua1bed0ac2a8d7df60d85401d258c29bb_402888_180x0_resize_box_3.png data-src=/blog/2024-11-21-beam-examples-8/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-11-21-beam-examples-8/>Apache Beam Python Examples - Part 8 Enhance Sport Activity Tracker With Runner Motivation</a><div class="post-meta mt-2"><span class=post-date>November 21, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-11-07-cdc-local-dev/featured_hu1be5b7cd9299c136c309544dd6dd598d_83605_500x0_resize_box_3.png media="(max-width: 576px)" height=369 width=500><img class=img-fluid height=133 width=180 alt=featured.png src=/blog/2024-11-07-cdc-local-dev/featured_hu1be5b7cd9299c136c309544dd6dd598d_83605_180x0_resize_box_3.png data-src=/blog/2024-11-07-cdc-local-dev/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-11-07-cdc-local-dev/>Change Data Capture (CDC) Local Development With PostgreSQL, Debezium Server and Pub/Sub Emulator</a><div class="post-meta mt-2"><span class=post-date>November 7, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-10-24-beam-examples-7/featured_hu336cff41161b0f32f430902350f8d12d_214574_500x0_resize_box_3.png media="(max-width: 576px)" height=320 width=500><img class=img-fluid height=115 width=180 alt=featured.png src=/blog/2024-10-24-beam-examples-7/featured_hu336cff41161b0f32f430902350f8d12d_214574_180x0_resize_box_3.png data-src=/blog/2024-10-24-beam-examples-7/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-10-24-beam-examples-7/>Apache Beam Python Examples - Part 7 Separate Droppable Data Into Side Output</a><div class="post-meta mt-2"><span class=post-date>October 24, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-10-02-beam-examples-6/featured_hu5f29b15cfad1fc457b0f3b5efe55ac30_99452_500x0_resize_box_3.png media="(max-width: 576px)" height=314 width=500><img class=img-fluid height=113 width=180 alt=featured.png src=/blog/2024-10-02-beam-examples-6/featured_hu5f29b15cfad1fc457b0f3b5efe55ac30_99452_180x0_resize_box_3.png data-src=/blog/2024-10-02-beam-examples-6/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-10-02-beam-examples-6/>Apache Beam Python Examples - Part 6 Call RPC Service in Batch With Defined Batch Size Using Stateful DoFn</a><div class="post-meta mt-2"><span class=post-date>October 2, 2024</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2024-09-18-beam-examples-5/featured_hu4163a2e5ad4cff386dbfbcbd0650f4f7_95285_500x0_resize_box_3.png media="(max-width: 576px)" height=310 width=500><img class=img-fluid height=112 width=180 alt=featured.png src=/blog/2024-09-18-beam-examples-5/featured_hu4163a2e5ad4cff386dbfbcbd0650f4f7_95285_180x0_resize_box_3.png data-src=/blog/2024-09-18-beam-examples-5/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2024-09-18-beam-examples-5/>Apache Beam Python Examples - Part 5 Call RPC Service in Batch Using Stateless DoFn</a><div class="post-meta mt-2"><span class=post-date>September 18, 2024</span></div></div></div></li></ul></div></div></div></div></div></div></aside></div></main><footer class="footer mt-auto py-3 text-center container"><div class="offcanvas offcanvas-bottom h-auto" tabindex=-1 id=offcanvasActionsPanel aria-labelledby=offcanvasActionsPanelLabel><div class=offcanvas-header><div class="offcanvas-title h5" id=offcanvasActionsPanelLabel><i class="fas fa-fw fa-th-large me-1"></i>
Actions</div><button type=button class="btn-close ms-auto" data-bs-dismiss=offcanvas data-bs-target=offcanvasActionsPanel aria-label=Close></button></div><div class="offcanvas-body mt-2"><div class="actions d-flex overflow-auto align-items-center"><a role=button class="action action-go-back d-flex flex-column align-items-center me-3" href="javascript: window.history.back();"><span class="action-icon mb-2"><i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i></span> Go back
</a><a role=button class="action action-reload-page d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-redo-alt"></i></span> Reload
</a><a role=button class="action action-copy-url d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-link"></i></span> Copy URL</a></div></div></div><div class="row text-center"><div class="col-12 mt-2"><p class=mb-2>Jaehyeon Kim</p><p class="text-secondary mb-2"><small>⚙️ Data Engineer 📝 Blogger 👯 OSS Maintainer</small></p><div class="copyright mb-2 text-secondary"><small>Copyright © 2023-2025 Jaehyeon Kim. All Rights Reserved.</small></div><nav class="social-links nav justify-content-center mb-2 mt-3"><a class="nav-link social-link p-0 me-1 mb-2" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-2x fa-rss" style=color:#ea6221></i></a></nav></div><div class="col-12 col-lg-8 offset-0 offset-lg-1"></div></div></footer><script data-precache src=/assets/main/bundle.min.4185504578555b5b3c0a49a82726fac16c8dbe5ab2bf92d2dd2b9665d4a6a140.js integrity="sha256-QYVQRXhVW1s8CkmoJyb6wWyNvlqyv5LS3SuWZdSmoUA=" crossorigin=anonymous async></script><script data-precache src=/assets/icons/bundle.min.4f30d5267a9f2f9d45ed93969d45ec626100a969a8b91f71f753315a261e9034.js integrity="sha256-TzDVJnqfL51F7ZOWnUXsYmEAqWmouR9x91MxWiYekDQ=" crossorigin=anonymous defer></script><script data-precache src=/assets/viewer/bundle.min.06371891cfe6d10d36cba465c61c4d7cb17591a3be2fd9af4a38444d2074e709.js integrity="sha256-BjcYkc/m0Q02y6RlxhxNfLF1kaO+L9mvSjhETSB05wk=" crossorigin=anonymous defer></script><script data-precache defer src=/assets/katex/bundle.min.ecfaac987a9ad8e8c435500e3a2dc277d9c1bdedc12ea02390b093db3788c0d4.js integrity="sha256-7PqsmHqa2OjENVAOOi3Cd9nBve3BLqAjkLCT2zeIwNQ=" crossorigin=anonymous></script><script data-precache defer src=/assets/mermaid/bundle.min.76a078d0eb0c863cdcae6518fbf7259910f0d612b7c7b9d0ee8511a6d1a6c332.js integrity="sha256-dqB40OsMhjzcrmUY+/clmRDw1hK3x7nQ7oURptGmwzI=" crossorigin=anonymous></script><script src=/js/sw-register.js defer></script><script src=https://giscus.app/client.js data-repo=jaehyeon-kim/jaehyeon-kim.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkyNjgwMjU0NQ==" data-category data-category-id=DIC_kwDOAZj5cc4CV2fp data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous defer></script></body></html>