<!doctype html><html class=position-relative itemscope itemtype=http://schema.org/WebPage lang=en data-bs-theme=light data-palette=blue-gray><head><script src=/assets/init/bundle.min.75fc37559b43c1a1031e6683d5ec9e833130be1398e4332f364273c68c9037d0.js integrity="sha256-dfw3VZtDwaEDHmaD1eyegzEwvhOY5DMvNkJzxoyQN9A=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Quick Start SparkR in Local and Cluster Mode - Jaehyeon Kim</title><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_16x16_resize_q75_h2_box_2.webp sizes=16x16 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_32x32_resize_q75_h2_box_2.webp sizes=32x32 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_150x150_resize_q75_h2_box_2.webp sizes=150x150 type=image/webp><link rel=apple-touch-icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_180x180_resize_q75_h2_box_2.webp sizes=180x180 type=image/webp><link rel=icon href=/favicon_huf63427acbec4fbe11db6a32164cc2763_6040_192x192_resize_q75_h2_box_2.webp sizes=192x192 type=image/webp><link rel=mask-icon href=/safari-pinned-tab.svg color=#6f42c1><meta name=keywords content="AWS,Data,Analytics,Containers,Serverless"><meta name=description content="In this post, we discuss how to execute SparkR in a local and cluster mode."><meta name=robots content="index, follow"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://jaehyeon.me/site-feature-image.png"><meta name=twitter:title content="Quick Start SparkR in Local and Cluster Mode"><meta name=twitter:description content="In this post, we discuss how to execute SparkR in a local and cluster mode."><meta property="og:title" content="Quick Start SparkR in Local and Cluster Mode"><meta property="og:description" content="In this post, we discuss how to execute SparkR in a local and cluster mode."><meta property="og:type" content="article"><meta property="og:url" content="https://jaehyeon.me/blog/2016-03-02-quick-start-sparkr-in-local-and-cluster-mode/"><meta property="og:image" content="https://jaehyeon.me/site-feature-image.png"><meta property="article:section" content="blog"><meta property="article:published_time" content="2016-03-02T00:00:00+00:00"><meta property="article:modified_time" content="2023-05-04T09:22:05+10:00"><meta itemprop=name content="Quick Start SparkR in Local and Cluster Mode"><meta itemprop=description content="In this post, we discuss how to execute SparkR in a local and cluster mode."><meta itemprop=datePublished content="2016-03-02T00:00:00+00:00"><meta itemprop=dateModified content="2023-05-04T09:22:05+10:00"><meta itemprop=wordCount content="1570"><meta itemprop=image content="https://jaehyeon.me/site-feature-image.png"><meta itemprop=keywords content="Apache Spark,R,SparkR,"><link rel=manifest href=/manifest.json><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-2764466088407958"></script>
<link data-precache rel=stylesheet href="/assets/main/bundle.min.76ed053a00b5cbfb699d7f01a609bc3d36f09840ef420d5d1d53618d49a8c0ea.css" integrity="sha256-du0FOgC1y/tpnX8Bpgm8PTbwmEDvQg1dHVNhjUmowOo=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/katex/bundle.min.222aac0b0b2e29944e5e468ecbd302b4ece09ac5ee29a0c811086b03659edd76.css integrity="sha256-IiqsCwsuKZROXkaOy9MCtOzgmsXuKaDIEQhrA2We3XY=" crossorigin=anonymous><link data-precache rel=stylesheet href=/assets/viewer/bundle.min.eb914844636cd41f221f109e99c887bbc3b6b5ffb2af7c664b284cea2d1b54b7.css integrity="sha256-65FIRGNs1B8iHxCemciHu8O2tf+yr3xmSyhM6i0bVLc=" crossorigin=anonymous></head><body><header><nav class="top-app-bar shadow navbar navbar-expand-xxl fixed-top"><div class=container><a class="navbar-brand d-flex align-items-center flex-grow-1 flex-xxl-grow-0 justify-content-xxl-start ms-2 ms-xxl-0 mx-auto me-xxl-2" href=https://jaehyeon.me/>Jaehyeon Kim</a><div class="offcanvas-xxl offcanvas-end flex-grow-1" data-bs-scroll=true tabindex=-1 id=navbarMenus aria-labelledby=navbarMenusLabel><div class="offcanvas-header px-4 pb-0"><div class="offcanvas-title h5" id=navbarMenusLabel>Jaehyeon Kim</div><button type=button class="btn-close btn-close-white" data-bs-dismiss=offcanvas data-bs-target=#navbarMenus aria-label=Close></button></div><div class="offcanvas-body p-4 pt-0 p-xxl-0"><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center me-auto"><li class="nav-item col-12 col-xxl-auto dropdown px-0"><a href=# class="nav-link dropdown-toggle" id=navbarDropdownBlog role=button data-bs-toggle=dropdown aria-expanded=false><span class="menu-icon me-1"><i class="fas fa-fw fa-blog text-warning"></i></span>Blog</a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=navbarDropdownBlog data-bs-popper=none><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/archives/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-file-archive text-primary"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-0">Archives</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/series/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-columns"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Series</p><p class="dropdown-item-description mb-0 text-secondary">List of series.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/categories/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-folder text-success"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Categories</p><p class="dropdown-item-description mb-0 text-secondary">List of categories.</p></div></a></li><li><a class="dropdown-item d-flex align-items-center text-wrap text-xxl-nowrap" href=https://jaehyeon.me/tags/><span class="dropdown-item-icon me-2 p-2 rounded"><i class="fas fa-fw fa-tags"></i></span><div class=dropdown-item-content><p class="dropdown-item-title mb-1">Tags</p><p class="dropdown-item-description mb-0 text-secondary">List of tags.</p></div></a></li></ul></li></ul><hr class=d-xxl-none><form class="search-bar ms-auto my-1" action=/search/ novalidate><div class="input-group input-group-sm align-items-center"><span class="btn btn-search disabled position-absolute left-0 border-0 px-1"><i class="fas fa-fw fa-search fa-lg"></i></span>
<input class="my-1 form-control border-white rounded search-input bg-body" name=q type=search placeholder="Press / to search" aria-label=Search required></div></form><hr class=d-xxl-none><ul class="navbar-nav flex-row flex-wrap align-items-center ms-md-auto"><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><nav class="social-links nav justify-content-center flex-row"><a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fab fa-github"></i>
<span class="ms-1 d-xxl-none">Github</span></a>
<a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fab fa-linkedin-in"></i>
<span class="ms-1 d-xxl-none">Linkedin</span></a>
<a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fab fa-paypal"></i>
<span class="ms-1 d-xxl-none">Paypal</span></a>
<a class="nav-link social-link col-6 col-xxl-auto p-1" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-rss"></i>
<span class="ms-1 d-xxl-none">RSS</span></a></nav></li><li class="nav-item py-2 py-xxl-1 col-12 col-xxl-auto"><div class="vr d-none d-xxl-flex h-100 mx-xxl-2 text-white"></div><hr class="d-xxl-none my-2"></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=fontSizeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-font"></i>
<span class=d-xxl-none>Font Size</span></a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=fontSizeDropdown><li><button class="font-size-item dropdown-item" data-size=xs>
Extra Small</button></li><li><button class="font-size-item dropdown-item" data-size=sm>
Small</button></li><li><button class="font-size-item dropdown-item active" data-size=md>
Medium</button></li><li><button class="font-size-item dropdown-item" data-size=lg>
Large</button></li><li><button class="font-size-item dropdown-item" data-size=xl>
Extra Large</button></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=paletteDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="fas fa-fw fa-palette"></i>
<span class=d-xxl-none>Palette</span></a><ul class="palette-dropdown-menu dropdown-menu dropdown-menu-end px-2 row g-2" aria-labelledby=paletteDropdown><li class="col-4 my-1"><a role=button id=palette-blue aria-label=Blue class="btn btn-sm w-100 palette text-bg-blue" data-palette=blue></a></li><li class="col-4 my-1"><a role=button id=palette-blue-gray aria-label="Blue Gray" class="btn btn-sm w-100 palette text-bg-blue-gray" data-palette=blue-gray></a></li><li class="col-4 my-1"><a role=button id=palette-brown aria-label=Brown class="btn btn-sm w-100 palette text-bg-brown" data-palette=brown></a></li><li class="col-4 my-1"><a role=button id=palette-cyan aria-label=Cyan class="btn btn-sm w-100 palette text-bg-cyan" data-palette=cyan></a></li><li class="col-4 my-1"><a role=button id=palette-green aria-label=Green class="btn btn-sm w-100 palette text-bg-green" data-palette=green></a></li><li class="col-4 my-1"><a role=button id=palette-indigo aria-label=Indigo class="btn btn-sm w-100 palette text-bg-indigo" data-palette=indigo></a></li><li class="col-4 my-1"><a role=button id=palette-orange aria-label=Orange class="btn btn-sm w-100 palette text-bg-orange" data-palette=orange></a></li><li class="col-4 my-1"><a role=button id=palette-pink aria-label=Pink class="btn btn-sm w-100 palette text-bg-pink" data-palette=pink></a></li><li class="col-4 my-1"><a role=button id=palette-purple aria-label=Purple class="btn btn-sm w-100 palette text-bg-purple" data-palette=purple></a></li><li class="col-4 my-1"><a role=button id=palette-red aria-label=Red class="btn btn-sm w-100 palette text-bg-red" data-palette=red></a></li><li class="col-4 my-1"><a role=button id=palette-teal aria-label=Teal class="btn btn-sm w-100 palette text-bg-teal" data-palette=teal></a></li><li class="col-4 my-1"><a role=button id=palette-yellow aria-label=Yellow class="btn btn-sm w-100 palette text-bg-yellow" data-palette=yellow></a></li></ul></li><li class="nav-item dropdown col-6 col-xxl-auto"><a class="nav-link px-0 py-2 px-xxl-1" href=# id=modeDropdown role=button data-bs-toggle=dropdown aria-expanded=false><i class="mode-icon fas fa-fw fa-sun" id=modeIcon></i>
<span class=d-xxl-none>Mode</span></a><ul class="dropdown-menu dropdown-menu-end" aria-labelledby=modeDropdown><li class="mode-item active" data-color-mode=light data-icon=sun><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-sun"></i> Light</button></li><li class=mode-item data-color-mode=dark data-icon=moon><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-moon"></i> Dark</button></li><li class=mode-item data-color-mode=auto data-icon=adjust><button class=dropdown-item>
<i class="mode-icon fas fa-fw fa-adjust"></i> Auto</button></li></ul></li></ul></div></div><div class=d-flex><button class="navbar-toggler order-5 border-0" type=button data-bs-toggle=offcanvas data-bs-target=#navbarMenus aria-controls=navbarMenus aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-h"></i></button></div></div></nav></header><main class=container><div class="row content"><noscript><div class="alert alert-danger" role=alert>Your browser does not support JavaScript.</div></noscript><div class=col-xxl-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class="card-body pb-0"><ol class="hbs-breadcrumb breadcrumb flex-nowrap"><li class="breadcrumb-item text-surface"><a href=/>Home</a></li><li class="breadcrumb-item text-surface"><a href=/blog/>Blogs</a></li><li class="breadcrumb-item active">Quick Start SparkR in Local and Cluster Mode</li></ol></div></nav><div class="post-panel-wrapper position-relative d-flex justify-content-center"><div class="d-flex flex-row justify-content-center rounded rounded-5 border border-primary post-panel position-fixed px-3 py-1 surface shadow"><a class="action action-toc d-none d-xxl-block" href=#postTOC role=button title="Table of contents"><i class="fas fa-fw fa-list-alt"></i></a>
<a class="action action-toc d-block d-xxl-none" href=#post-toc-container role=button title="Table of contents"><i class="fas fa-fw fa-list-alt"></i></a>
<a class="action action-post-comments" href=#post-comments role=button aria-label=Comments title=Comments><i class="fas fa-fw fa-comments"></i></a>
<a id=sidebarToggler class="action action-sidebar-toggler d-none d-xxl-block" role=button title="Sidebar toggler"><i class="fas fa-fw fa-expand-alt" data-fa-transform=rotate-45></i></a></div></div><article class="row card component mb-4 post"><div class=card-header><h1 class="card-title post-title my-2">Quick Start SparkR in Local and Cluster Mode</h1></div><div class=card-body><div class="post-meta mb-3"><span class="post-date me-1 mb-1" title="created on 2016-03-02 00:00:00 +0000 UTC, updated on 2023-05-03 23:22:05 +0000 UTC.">March 2, 2016</span><span class="post-reading-time me-1 mb-1">8 min read</span><a href=/categories/r/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-category">
<i class="fas fa-fw fa-folder me-1"></i>R</a><a href=/tags/apache-spark/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">Apache Spark</a><a href=/tags/r/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">R</a><a href=/tags/sparkr/ class="btn btn-sm btn-secondary mb-1 me-2 py-0 pe-1 post-taxonomy post-taxonomy-sm post-tag">SparkR</a></div><div id=postTOC class="mb-3 text-surface"><h2 class=mb-3>Contents<a class="anchor ms-1" href=#postTOC></a></h2><nav id=TableOfContents><ul><li><a href=#sparkr-testhttpsbitbucketorgjaehyeonsparkr-test-repo><a href=https://bitbucket.org/jaehyeon/sparkr-test>sparkr-test</a> repo</a></li><li><a href=#initialization>Initialization</a><ul><li><a href=#local-mode>Local mode</a></li><li><a href=#standalone-cluster>standalone cluster</a></li></ul></li></ul></nav><hr class=text-secondary></div><div class="post-content mb-3" data-bs-spy=scroll data-bs-target=#TableOfContents tabindex=0><div id=post-content-body><p>In the <a href=/blog/2016-02-22-spark-cluster-setup-on-virtualbox>previous post</a>, a Spark cluster is set up using 2 VirtualBox Ubuntu guests. While this is a viable option for many, it is not always for others. For those who find setting-up such a cluster is not convenient, there&rsquo;s still another option, which is relying on the local mode of Spark. In this post, a <a href=https://bitbucket.org/jaehyeon/sparkr-test target=_blank rel="noopener noreferrer"><strong>BitBucket repository</strong><i class="fas fa-external-link-square-alt ms-1"></i></a> is introduced, which is a R project that includes <em>Spark 1.6.0 Pre-built for Hadoop 2.0 and later</em> and <em>hadoop-common 2.2.0</em> - the latter is necessary if it is tested on Windows. Then several initialization steps are discussed such as setting-up environment variables and library path as well as including the <a href=https://github.com/databricks/spark-csv target=_blank rel="noopener noreferrer">spark-csv package<i class="fas fa-external-link-square-alt ms-1"></i></a> and a JDBC driver. Finally it shows some examples of reading JSON and CSV files in the cluster mode.</p><h2 id=sparkr-testhttpsbitbucketorgjaehyeonsparkr-test-repo data-numberify>sparkr-test repo<a class="anchor ms-1" href=#sparkr-testhttpsbitbucketorgjaehyeonsparkr-test-repo></a></h2><p><em>Spark 1.6.0 Pre-built for Hadoop 2.0 and later</em> is downloaded and renamed as <em>spark</em> after decompressing. Also, <em>hadoop-common 2.2.0</em> is downloaded from this <a href=https://github.com/srccodes/hadoop-common-2.2.0-bin/archive/master.zip target=_blank rel="noopener noreferrer">GitHub repo<i class="fas fa-external-link-square-alt ms-1"></i></a> and saved within the <em>spark</em> folder as <em>hadoop</em>. The <em>SparkR</em> package is in <em>R/lib</em> and the <em>bin</em> path includes files that execute spark applications interactively and in batch mode. The <em>conf</em> folder includes a number of configuration templates. At the moment, only one of the templates is modified - <em>log4j.properties.template</em>. This template is renanmed as <em>log4j.properties</em> and <em>log4j.rootCategory</em> is set to be <em>WARN</em> as shown below. Previously it was <em>INFO</em> and it may be distracting as a lot of messages are printed with this option.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln>1</span><span class=cl><span class=c1># Set everything to be logged to the console</span>
</span></span><span class=line><span class=ln>2</span><span class=cl><span class=n>log4j.rootCategory</span><span class=o>=</span><span class=n>WARN</span><span class=p>,</span> <span class=n>console</span>
</span></span></code></pre></div><p>The spark folder in the repository is shown below.</p><p><picture><img class="img-fluid mx-auto d-block" alt src=/blog/2016-03-02-quick-start-sparkr-in-local-and-cluster-mode/01_spark_foler.png loading=lazy width=354 height=471></picture></p><p>There are 2 data files. <em>iris.json</em> is the popular iris data set in JSON format. <em>iris_up.csv</em> is the same data set in CSV format with 3 extra columns - 1 integer, 1 date and 1 integer column with NA values - how to read them will be discussed shortly. <em>postgresql-9.3-1103.jdbc3.jar</em> is a JDBC driver to connect <em>PostgreSQL</em>-like database servers such as PostgreSQL server or Amazon Redshift - you may add another driver for your own DB server.</p><h2 id=initialization data-numberify>Initialization<a class="anchor ms-1" href=#initialization></a></h2><h3 id=local-mode data-numberify>Local mode<a class="anchor ms-1" href=#local-mode></a></h3><p>It sets two environment variables: <strong>SPARK_HOME</strong> and <strong>HADOOP_HOME</strong>. The latter is mandatory if you&rsquo;re running this example on Windows (possibly in local mode). Otherwise the following error is thrown: <code>java.lang.NullPointerException</code>. Note that the Spark pre-built distribution doesn&rsquo;t include <em>Hadoop-common</em> and it is downloaded from <a href=https://github.com/srccodes/hadoop-common-2.2.0-bin/archive/master.zip target=_blank rel="noopener noreferrer">this repo<i class="fas fa-external-link-square-alt ms-1"></i></a> and added within the <em>spark</em> folder - the foler is named as <em>hadoop</em>. If it is running on Linux, this part can be commented out as in the cluster mode example below.</p><p>Also the spark <em>bin</em> directory is added to the <strong>PATH</strong> environment variable - this path is where <em>spark-submit</em> (Spark batch excutor) and Saprk REPL launchers exist. Then the path of the db driver (<em>postgresql-9.3-1103.jdbc3.jar</em>) is specified - see <strong>postgresql_drv</strong>. As can be seen in <em>sparkR.init()</em>, the path is added to environment variable on the worker node by adding <em>sparkEnvir</em> and the driver is passed to the worker node by setting <em>sparkJars</em>.</p><p>Finally the search path is updated to add the SparkR package (<strong>sparkr_lib</strong>). For the local mode, the master can be set as <em>local[*]</em> if it is required to use all existing cores or a specific number can be specified - see <strong>spark_link</strong>. The last environment variable (<strong>SPARKR_SUBMIT_ARGS</strong>) is for controlling <em>spark-submit</em>. In this setting, the <em>spark-csv package</em> is included at launch.</p><p>At the end, a spark context (<strong>sc</strong>) and sql context (<strong>sqlContext</strong>) are defined. Note that, in this way, it is possible to run a Spark application interactively as well as in batch mode using Rscript, rather than using <em>spark-submit</em>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln> 1</span><span class=cl><span class=c1>#### set up environment variables</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=n>base_path</span> <span class=o>&lt;-</span> <span class=nf>getwd</span><span class=p>()</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl><span class=c1>## SPARK_HOME</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=n>spark_home</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>base_path</span><span class=p>,</span> <span class=s>&#39;/spark&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl><span class=nf>Sys.setenv</span><span class=p>(</span><span class=n>SPARK_HOME</span> <span class=o>=</span> <span class=n>spark_home</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl><span class=c1>## $SPARK_HOME/bin to PATH</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl><span class=n>spark_bin</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>spark_home</span><span class=p>,</span> <span class=s>&#39;/bin&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl><span class=nf>Sys.setenv</span><span class=p>(</span><span class=n>PATH</span> <span class=o>=</span> <span class=nf>paste</span><span class=p>(</span><span class=nf>Sys.getenv</span><span class=p>(</span><span class=nf>c</span><span class=p>(</span><span class=s>&#39;PATH&#39;</span><span class=p>)),</span> <span class=n>spark_bin</span><span class=p>,</span> <span class=n>sep</span><span class=o>=</span><span class=s>&#39;:&#39;</span><span class=p>))</span> 
</span></span><span class=line><span class=ln> 9</span><span class=cl><span class=c1>## HADOOP_HOME</span>
</span></span><span class=line><span class=ln>10</span><span class=cl><span class=c1># hadoop-common missing on Windows and downloaded from </span>
</span></span><span class=line><span class=ln>11</span><span class=cl><span class=c1>#   https://github.com/srccodes/hadoop-common-2.2.0-bin/archive/master.zip</span>
</span></span><span class=line><span class=ln>12</span><span class=cl><span class=c1># java.lang.NullPointerException if not set</span>
</span></span><span class=line><span class=ln>13</span><span class=cl><span class=n>hadoop_home</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>spark_home</span><span class=p>,</span> <span class=s>&#39;/hadoop&#39;</span><span class=p>)</span> <span class=c1># hadoop-common missing on Windows</span>
</span></span><span class=line><span class=ln>14</span><span class=cl><span class=nf>Sys.setenv</span><span class=p>(</span><span class=n>HADOOP_HOME</span> <span class=o>=</span> <span class=n>hadoop_home</span><span class=p>)</span> <span class=c1># hadoop-common missing on Windows</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>
</span></span><span class=line><span class=ln>16</span><span class=cl><span class=c1>#### extra driver jar to be passed</span>
</span></span><span class=line><span class=ln>17</span><span class=cl><span class=n>postgresql_drv</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=nf>getwd</span><span class=p>(),</span> <span class=s>&#39;/postgresql-9.3-1103.jdbc3.jar&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>
</span></span><span class=line><span class=ln>19</span><span class=cl><span class=c1>#### add SparkR to search path</span>
</span></span><span class=line><span class=ln>20</span><span class=cl><span class=n>sparkr_lib</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>spark_home</span><span class=p>,</span> <span class=s>&#39;/R/lib&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>21</span><span class=cl><span class=nf>.libPaths</span><span class=p>(</span><span class=nf>c</span><span class=p>(</span><span class=nf>.libPaths</span><span class=p>(),</span> <span class=n>sparkr_lib</span><span class=p>))</span>
</span></span><span class=line><span class=ln>22</span><span class=cl>
</span></span><span class=line><span class=ln>23</span><span class=cl><span class=c1>#### specify master host name or localhost</span>
</span></span><span class=line><span class=ln>24</span><span class=cl><span class=c1>#spark_link &lt;- system(&#39;cat /root/spark-ec2/cluster-url&#39;, intern=TRUE)</span>
</span></span><span class=line><span class=ln>25</span><span class=cl><span class=n>spark_link</span> <span class=o>&lt;-</span> <span class=s>&#34;local[*]&#34;</span>
</span></span><span class=line><span class=ln>26</span><span class=cl><span class=c1>#spark_link &lt;- &#39;spark://192.168.1.10:7077&#39;</span>
</span></span><span class=line><span class=ln>27</span><span class=cl>
</span></span><span class=line><span class=ln>28</span><span class=cl><span class=nf>library</span><span class=p>(</span><span class=n>SparkR</span><span class=p>)</span>
</span></span><span class=line><span class=ln>29</span><span class=cl>
</span></span><span class=line><span class=ln>30</span><span class=cl><span class=c1>## include spark-csv package</span>
</span></span><span class=line><span class=ln>31</span><span class=cl><span class=nf>Sys.setenv</span><span class=p>(</span><span class=s>&#39;SPARKR_SUBMIT_ARGS&#39;</span><span class=o>=</span><span class=s>&#39;&#34;--packages&#34; &#34;com.databricks:spark-csv_2.10:1.3.0&#34; &#34;sparkr-shell&#34;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>32</span><span class=cl>
</span></span><span class=line><span class=ln>33</span><span class=cl><span class=n>sc</span> <span class=o>&lt;-</span> <span class=nf>sparkR.init</span><span class=p>(</span><span class=n>master</span> <span class=o>=</span> <span class=n>spark_link</span><span class=p>,</span> <span class=n>appName</span> <span class=o>=</span> <span class=s>&#34;SparkR_local&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>34</span><span class=cl>                  <span class=n>sparkEnvir</span> <span class=o>=</span> <span class=nf>list</span><span class=p>(</span><span class=n>spark.driver.extraClassPath</span> <span class=o>=</span> <span class=n>postgresql_drv</span><span class=p>),</span>
</span></span><span class=line><span class=ln>35</span><span class=cl>                  <span class=n>sparkJars</span> <span class=o>=</span> <span class=n>postgresql_drv</span><span class=p>)</span> 
</span></span><span class=line><span class=ln>36</span><span class=cl><span class=n>sqlContext</span> <span class=o>&lt;-</span> <span class=nf>sparkRSQL.init</span><span class=p>(</span><span class=n>sc</span><span class=p>)</span>
</span></span><span class=line><span class=ln>37</span><span class=cl>
</span></span><span class=line><span class=ln>38</span><span class=cl><span class=c1>## do something</span>
</span></span><span class=line><span class=ln>39</span><span class=cl>
</span></span><span class=line><span class=ln>40</span><span class=cl><span class=nf>sparkR.stop</span><span class=p>()</span>
</span></span></code></pre></div><h3 id=standalone-cluster data-numberify>standalone cluster<a class="anchor ms-1" href=#standalone-cluster></a></h3><p>In order to run the script in the cluster mode, the two data files (<em>iris.json</em> and <em>iris_up.csv</em>) are copied to <code>~/data</code> in both the master and slave machines. (Files should exist in the same location if you&rsquo;re not using HDFS, S3 &mldr;) I simply used WinSCP and you may find <a href=http://jaehyeon-kim.github.io/2015/11/Connecting-to-VirtualBox-Guest-via-SSH-And-RStudio-Server target=_blank rel="noopener noreferrer">this post<i class="fas fa-external-link-square-alt ms-1"></i></a> useful. Also I started a cluster by <code>~/spark/sbin/start-all.sh</code> - see <a href=http://jaehyeon-kim.github.io/2016/02/Spark-Cluster-Setup-on-VirtualBox target=_blank rel="noopener noreferrer">this post<i class="fas fa-external-link-square-alt ms-1"></i></a> for further details.</p><p>The main difference is the Spark master, which is set to be <em>spark://192.168.1.10:7077</em>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln> 1</span><span class=cl><span class=c1>#### set up environment variables</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl><span class=n>base_path</span> <span class=o>&lt;-</span> <span class=s>&#39;/home/jaehyeon&#39;</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl><span class=c1>## SPARK_HOME</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl><span class=n>spark_home</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>base_path</span><span class=p>,</span> <span class=s>&#39;/spark&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl><span class=nf>Sys.setenv</span><span class=p>(</span><span class=n>SPARK_HOME</span> <span class=o>=</span> <span class=n>spark_home</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl><span class=c1>## $SPARK_HOME/bin to PATH</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl><span class=n>spark_bin</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>spark_home</span><span class=p>,</span> <span class=s>&#39;/bin&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl><span class=nf>Sys.setenv</span><span class=p>(</span><span class=n>PATH</span> <span class=o>=</span> <span class=nf>paste</span><span class=p>(</span><span class=nf>Sys.getenv</span><span class=p>(</span><span class=nf>c</span><span class=p>(</span><span class=s>&#39;PATH&#39;</span><span class=p>)),</span> <span class=n>spark_bin</span><span class=p>,</span> <span class=n>sep</span><span class=o>=</span><span class=s>&#39;:&#39;</span><span class=p>))</span> 
</span></span><span class=line><span class=ln> 9</span><span class=cl><span class=c1>## HADOOP_HOME</span>
</span></span><span class=line><span class=ln>10</span><span class=cl><span class=c1># hadoop-common missing on Windows and downloaded from </span>
</span></span><span class=line><span class=ln>11</span><span class=cl><span class=c1>#	https://github.com/srccodes/hadoop-common-2.2.0-bin/archive/master.zip</span>
</span></span><span class=line><span class=ln>12</span><span class=cl><span class=c1># java.lang.NullPointerException if not set</span>
</span></span><span class=line><span class=ln>13</span><span class=cl><span class=c1>#hadoop_home &lt;- paste0(spark_home, &#39;/hadoop&#39;) # hadoop-common missing on Windows</span>
</span></span><span class=line><span class=ln>14</span><span class=cl><span class=c1>#Sys.setenv(HADOOP_HOME = hadoop_home) # hadoop-common missing on Windows</span>
</span></span><span class=line><span class=ln>15</span><span class=cl>
</span></span><span class=line><span class=ln>16</span><span class=cl><span class=c1>#### extra driver jar to be passed</span>
</span></span><span class=line><span class=ln>17</span><span class=cl><span class=n>postgresql_drv</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=nf>getwd</span><span class=p>(),</span> <span class=s>&#39;/postgresql-9.3-1103.jdbc3.jar&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>18</span><span class=cl>
</span></span><span class=line><span class=ln>19</span><span class=cl><span class=c1>#### add SparkR to search path</span>
</span></span><span class=line><span class=ln>20</span><span class=cl><span class=n>sparkr_lib</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>spark_home</span><span class=p>,</span> <span class=s>&#39;/R/lib&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>21</span><span class=cl><span class=nf>.libPaths</span><span class=p>(</span><span class=nf>c</span><span class=p>(</span><span class=nf>.libPaths</span><span class=p>(),</span> <span class=n>sparkr_lib</span><span class=p>))</span>
</span></span><span class=line><span class=ln>22</span><span class=cl>
</span></span><span class=line><span class=ln>23</span><span class=cl><span class=c1>#### specify master host name or localhost</span>
</span></span><span class=line><span class=ln>24</span><span class=cl><span class=c1>#spark_link &lt;- system(&#39;cat /root/spark-ec2/cluster-url&#39;, intern=TRUE)</span>
</span></span><span class=line><span class=ln>25</span><span class=cl><span class=c1>#spark_link &lt;- &#34;local[*]&#34;</span>
</span></span><span class=line><span class=ln>26</span><span class=cl><span class=n>spark_link</span> <span class=o>&lt;-</span> <span class=s>&#39;spark://192.168.1.10:7077&#39;</span>
</span></span><span class=line><span class=ln>27</span><span class=cl>
</span></span><span class=line><span class=ln>28</span><span class=cl><span class=nf>library</span><span class=p>(</span><span class=n>SparkR</span><span class=p>)</span>
</span></span><span class=line><span class=ln>29</span><span class=cl>
</span></span><span class=line><span class=ln>30</span><span class=cl><span class=c1>## include spark-csv package</span>
</span></span><span class=line><span class=ln>31</span><span class=cl><span class=nf>Sys.setenv</span><span class=p>(</span><span class=s>&#39;SPARKR_SUBMIT_ARGS&#39;</span><span class=o>=</span><span class=s>&#39;&#34;--packages&#34; &#34;com.databricks:spark-csv_2.10:1.3.0&#34; &#34;sparkr-shell&#34;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>32</span><span class=cl>
</span></span><span class=line><span class=ln>33</span><span class=cl><span class=n>sc</span> <span class=o>&lt;-</span> <span class=nf>sparkR.init</span><span class=p>(</span><span class=n>master</span> <span class=o>=</span> <span class=n>spark_link</span><span class=p>,</span> <span class=n>appName</span> <span class=o>=</span> <span class=s>&#34;SparkR_cluster&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=ln>34</span><span class=cl>                  <span class=n>sparkEnvir</span> <span class=o>=</span> <span class=nf>list</span><span class=p>(</span><span class=n>spark.driver.extraClassPath</span> <span class=o>=</span> <span class=n>postgresql_drv</span><span class=p>),</span>
</span></span><span class=line><span class=ln>35</span><span class=cl>                  <span class=n>sparkJars</span> <span class=o>=</span> <span class=n>postgresql_drv</span><span class=p>)</span> 
</span></span></code></pre></div><pre tabindex=0><code>## Launching java with spark-submit command /home/jaehyeon/spark/bin/spark-submit --jars /home/jaehyeon/jaehyeon-kim.github.io/_posts/projects/postgresql-9.3-1103.jdbc3.jar  --driver-class-path &#34;/home/jaehyeon/jaehyeon-kim.github.io/_posts/projects/postgresql-9.3-1103.jdbc3.jar&#34; &#34;--packages&#34; &#34;com.databricks:spark-csv_2.10:1.3.0&#34; &#34;sparkr-shell&#34; /tmp/RtmpuQHgNQ/backend_port1ee16d63ec86
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln>1</span><span class=cl><span class=n>sqlContext</span> <span class=o>&lt;-</span> <span class=nf>sparkRSQL.init</span><span class=p>(</span><span class=n>sc</span><span class=p>)</span>
</span></span><span class=line><span class=ln>2</span><span class=cl>
</span></span><span class=line><span class=ln>3</span><span class=cl><span class=n>data_path</span> <span class=o>&lt;-</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>base_path</span><span class=p>,</span> <span class=s>&#39;/data&#39;</span><span class=p>)</span>
</span></span></code></pre></div><p>The JSON format is built-in so that it suffices to specify the source. By default, <code>read.df()</code> infers the schema (or data type) and it is found that all data types are identified correctly except for the last one where it includes some NA values.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln>1</span><span class=cl><span class=n>iris_js</span> <span class=o>&lt;-</span> <span class=nf>read.df</span><span class=p>(</span><span class=n>sqlContext</span><span class=p>,</span> <span class=n>path</span> <span class=o>=</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>data_path</span><span class=p>,</span> <span class=s>&#34;/iris.json&#34;</span><span class=p>),</span> <span class=n>source</span> <span class=o>=</span> <span class=s>&#34;json&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>2</span><span class=cl><span class=nf>head</span><span class=p>(</span><span class=n>iris_js</span><span class=p>)</span>
</span></span></code></pre></div><pre tabindex=0><code>##   Petal_Length Petal_Width Sepal_Length Sepal_Width Species
## 1          1.4         0.2          5.1         3.5  setosa
## 2          1.4         0.2          4.9         3.0  setosa
## 3          1.3         0.2          4.7         3.2  setosa
## 4          1.5         0.2          4.6         3.1  setosa
## 5          1.4         0.2          5.0         3.6  setosa
## 6          1.7         0.4          5.4         3.9  setosa
</code></pre><p>The schema inference is worse on CSV as the date field is identified as string.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln>1</span><span class=cl><span class=n>iris_inf</span> <span class=o>&lt;-</span> <span class=nf>read.df</span><span class=p>(</span><span class=n>sqlContext</span><span class=p>,</span> <span class=n>path</span> <span class=o>=</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>data_path</span><span class=p>,</span> <span class=s>&#34;/iris_up.csv&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln>2</span><span class=cl>                    <span class=n>source</span> <span class=o>=</span> <span class=s>&#34;com.databricks.spark.csv&#34;</span><span class=p>,</span> <span class=n>inferSchema</span> <span class=o>=</span> <span class=s>&#34;true&#34;</span><span class=p>,</span> <span class=n>header</span> <span class=o>=</span> <span class=s>&#34;true&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>3</span><span class=cl><span class=nf>head</span><span class=p>(</span><span class=n>iris_inf</span><span class=p>)</span>
</span></span></code></pre></div><pre tabindex=0><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species int       date
## 1          5.1         3.5          1.4         0.2  setosa   1 2016-02-29
## 2          4.9         3.0          1.4         0.2  setosa   2 2016-02-29
## 3          4.7         3.2          1.3         0.2  setosa   3 2016-02-29
## 4          4.6         3.1          1.5         0.2  setosa   4 2016-02-29
## 5          5.0         3.6          1.4         0.2  setosa   5 2016-02-29
## 6          5.4         3.9          1.7         0.4  setosa   6 2016-02-29
##   null
## 1   NA
## 2   NA
## 3   NA
## 4    4
## 5    5
## 6    6
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln>1</span><span class=cl><span class=nf>schema</span><span class=p>(</span><span class=n>iris_inf</span><span class=p>)</span>
</span></span></code></pre></div><pre tabindex=0><code>## StructType
## |-name = &#34;Sepal.Length&#34;, type = &#34;DoubleType&#34;, nullable = TRUE
## |-name = &#34;Sepal.Width&#34;, type = &#34;DoubleType&#34;, nullable = TRUE
## |-name = &#34;Petal.Length&#34;, type = &#34;DoubleType&#34;, nullable = TRUE
## |-name = &#34;Petal.Width&#34;, type = &#34;DoubleType&#34;, nullable = TRUE
## |-name = &#34;Species&#34;, type = &#34;StringType&#34;, nullable = TRUE
## |-name = &#34;int&#34;, type = &#34;IntegerType&#34;, nullable = TRUE
## |-name = &#34;date&#34;, type = &#34;StringType&#34;, nullable = TRUE
## |-name = &#34;null&#34;, type = &#34;StringType&#34;, nullable = TRUE
</code></pre><p>It is possible to specify individual data types by constructing a custom schema (<em>customSchema</em>). Note that the last column (<em>null</em>) is set as <em>string</em> in the custom schema and converted into <em>integer</em> using <code>cast()</code> after the data is loaded. The reason is <em>NA</em> is considered as <em>string</em> that the following error will be thrown if it is set as <em>integer</em>: <code>java.lang.NumberFormatException: For input string: "NA"</code>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln> 1</span><span class=cl><span class=n>customSchema</span> <span class=o>&lt;-</span> <span class=nf>structType</span><span class=p>(</span>
</span></span><span class=line><span class=ln> 2</span><span class=cl>  <span class=nf>structField</span><span class=p>(</span><span class=s>&#34;Sepal.Length&#34;</span><span class=p>,</span> <span class=s>&#34;double&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 3</span><span class=cl>  <span class=nf>structField</span><span class=p>(</span><span class=s>&#34;Sepal.Width&#34;</span><span class=p>,</span> <span class=s>&#34;double&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 4</span><span class=cl>  <span class=nf>structField</span><span class=p>(</span><span class=s>&#34;Petal.Length&#34;</span><span class=p>,</span> <span class=s>&#34;double&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 5</span><span class=cl>  <span class=nf>structField</span><span class=p>(</span><span class=s>&#34;Petal.Width&#34;</span><span class=p>,</span> <span class=s>&#34;double&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 6</span><span class=cl>  <span class=nf>structField</span><span class=p>(</span><span class=s>&#34;Species&#34;</span><span class=p>,</span> <span class=s>&#34;string&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 7</span><span class=cl>  <span class=nf>structField</span><span class=p>(</span><span class=s>&#34;integer&#34;</span><span class=p>,</span> <span class=s>&#34;integer&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 8</span><span class=cl>  <span class=nf>structField</span><span class=p>(</span><span class=s>&#34;date&#34;</span><span class=p>,</span> <span class=s>&#34;date&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln> 9</span><span class=cl>  <span class=nf>structField</span><span class=p>(</span><span class=s>&#34;null&#34;</span><span class=p>,</span> <span class=s>&#34;string&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>10</span><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=ln>11</span><span class=cl>
</span></span><span class=line><span class=ln>12</span><span class=cl><span class=n>iris_cus</span> <span class=o>&lt;-</span> <span class=nf>read.df</span><span class=p>(</span><span class=n>sqlContext</span><span class=p>,</span> <span class=n>path</span> <span class=o>=</span> <span class=nf>paste0</span><span class=p>(</span><span class=n>data_path</span><span class=p>,</span> <span class=s>&#34;/iris_up.csv&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=ln>13</span><span class=cl>                    <span class=n>source</span> <span class=o>=</span> <span class=s>&#34;com.databricks.spark.csv&#34;</span><span class=p>,</span> <span class=n>schema</span> <span class=o>=</span> <span class=n>customSchema</span><span class=p>,</span> <span class=n>header</span> <span class=o>=</span> <span class=s>&#34;true&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=ln>14</span><span class=cl><span class=nf>cast</span><span class=p>(</span><span class=n>iris_cus</span><span class=o>$</span><span class=n>null</span><span class=p>,</span> <span class=s>&#34;integer&#34;</span><span class=p>)</span>
</span></span></code></pre></div><pre tabindex=0><code>## Column unresolvedalias(cast(null as int))
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln>1</span><span class=cl><span class=nf>head</span><span class=p>(</span><span class=n>iris_cus</span><span class=p>)</span>
</span></span></code></pre></div><pre tabindex=0><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width Species integer
## 1          5.1         3.5          1.4         0.2  setosa       1
## 2          4.9         3.0          1.4         0.2  setosa       2
## 3          4.7         3.2          1.3         0.2  setosa       3
## 4          4.6         3.1          1.5         0.2  setosa       4
## 5          5.0         3.6          1.4         0.2  setosa       5
## 6          5.4         3.9          1.7         0.4  setosa       6
##         date null
## 1 2016-02-29   NA
## 2 2016-02-29   NA
## 3 2016-02-29   NA
## 4 2016-02-29    4
## 5 2016-02-29    5
## 6 2016-02-29    6
</code></pre><div class=highlight><pre tabindex=0 class=chroma><code class=language-r data-lang=r><span class=line><span class=ln>1</span><span class=cl><span class=nf>schema</span><span class=p>(</span><span class=n>iris_cus</span><span class=p>)</span>
</span></span></code></pre></div><pre tabindex=0><code>## StructType
## |-name = &#34;Sepal.Length&#34;, type = &#34;DoubleType&#34;, nullable = TRUE
## |-name = &#34;Sepal.Width&#34;, type = &#34;DoubleType&#34;, nullable = TRUE
## |-name = &#34;Petal.Length&#34;, type = &#34;DoubleType&#34;, nullable = TRUE
## |-name = &#34;Petal.Width&#34;, type = &#34;DoubleType&#34;, nullable = TRUE
## |-name = &#34;Species&#34;, type = &#34;StringType&#34;, nullable = TRUE
## |-name = &#34;integer&#34;, type = &#34;IntegerType&#34;, nullable = TRUE
## |-name = &#34;date&#34;, type = &#34;DateType&#34;, nullable = TRUE
## |-name = &#34;null&#34;, type = &#34;StringType&#34;, nullable = TRUE
</code></pre><p>I hope this post is useful.</p></div></div></div><div class=card-footer><div class="post-navs d-flex justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-down post-prev-icon me-1" data-fa-transform=rotate-90></i>
<a href=/blog/2016-02-22-spark-cluster-setup-on-virtualbox/>Spark Cluster Setup on VirtualBox</a></div><div class="post-nav post-next"><a href=/blog/2016-04-30-boost-sparkr-with-hive/>Boost SparkR With Hive</a>
<i class="fas fa-fw fa-chevron-down post-next-icon ms-1" data-fa-transform=rotate-270></i></div></div></div></article><section class="related-posts row card component"><div class=card-header><h2 class="card-title fs-4 my-2 text-surface">Related Posts</h2></div><div class="card-body slide px-1"><div class="slide-inner row gx-0"><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2016-02-22-spark-cluster-setup-on-virtualbox/>Spark Cluster Setup on VirtualBox</a><div class="post-meta mb-0">February 22, 2016</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2015-11-21-quick-test-to-wrap-python-in-r/>Quick Test to Wrap Python in R</a><div class="post-meta mb-0">November 21, 2015</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2015-08-09-some-thoughts-on-python-for-r-users/>Some Thoughts on Python for R Users</a><div class="post-meta mb-0">August 9, 2015</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2015-05-30-setup-random-seeds-on-caret-package/>Setup Random Seeds on Caret Package</a><div class="post-meta mb-0">May 30, 2015</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2015-03-24-packaging-analysis/>Packaging Analysis</a><div class="post-meta mb-0">March 24, 2015</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2015-03-19-parallel-processing-on-single-machine-3/>Parallel Processing on Single Machine - Part III</a><div class="post-meta mb-0">March 19, 2015</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2015-03-17-parallel-processing-on-single-machine-2/>Parallel Processing on Single Machine - Part II</a><div class="post-meta mb-0">March 17, 2015</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2015-03-14-parallel-processing-on-single-machine-1/>Parallel Processing on Single Machine - Part I</a><div class="post-meta mb-0">March 14, 2015</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2015-03-07-tree-based-methods-6/>Tree Based Methods in R - Part VI</a><div class="post-meta mb-0">March 7, 2015</div></div></div><div class="col-12 col-md-6 col-lg-4 me-2"><div class="post-card card card-body p-0 border-0 surface"><div class="post-card-default-img card-img-top d-flex align-items-center justify-content-center bg-body-secondary mb-1">NO IMAGE</div><a class=post-title href=/blog/2015-03-05-tree-based-methods-5/>Tree Based Methods in R - Part V</a><div class="post-meta mb-0">March 5, 2015</div></div></div></div><button class=slide-control-left>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i>
<span class=visually-hidden>Left</span></button>
<button class=slide-control-right>
<i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-270></i>
<span class=visually-hidden>Right</span></button></div></section><div class="card component row post-comments" id=post-comments><div class=card-header><h2 class="card-title my-2 fs-4 text-surface">Comments</h2></div><div class=card-body><div class=giscus></div></div></div></div></div><aside class="col-xxl-4 sidebar d-flex"><div class="container d-flex flex-column"><div class="accordion profile"><div class="accordion-item card row text-center component"><div class="accordion-header card-header border-0" id=profile-header><a class="accordion-button d-lg-none mb-2 shadow-none p-0 bg-transparent text-surface" role=button data-bs-toggle=collapse href=#profile aria-expanded=true aria-controls=profile>Profile</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=profile aria-labelledby=profile-header><div class="col-12 d-flex align-items-center justify-content-center"><picture><img class="profile-avatar rounded-circle" alt="Jaehyeon Kim" src=https://jaehyeon.me/images/profile.png loading=lazy data-viewer-invisible width=200 height=200></picture></div><div class="col-12 profile-meta"><div class="profile-name fw-fold fs-lg">Jaehyeon Kim</div><div class=profile-bio>Consultant at Cevo    AWS Community Builder   Blogger   Real-time Enthusiast</div><a class="profile-about text-primary" href=/about/><i class="fas fa-fw fa-user"></i>About</a><a class="profile-contact text-primary" href=/contact/><i class="fas fa-fw fa-question-circle"></i>Contact Me</a></div><nav class="social-links nav justify-content-center mt-1 justify-content-around"><a class="nav-link social-link" href=mailto:dottami@gmail.com title=Email><i class="fas fa-fw fa-2x fa-envelope" style=color:#0963ac></i></a>
<a class="nav-link social-link" target=_blank href=https://github.com/jaehyeon-kim title=GitHub rel=me><i class="fa-fw fa-2x fab fa-github"></i></a>
<a class="nav-link social-link" target=_blank href=https://linkedin.com/in/jaehyeon-kim-76b93429 title=LinkedIn rel=me><i class="fa-fw fa-2x fab fa-linkedin-in" style=color:#0a66c2></i></a>
<a class="nav-link social-link" target=_blank href=https://www.paypal.com/paypalme/dottami title=PayPal rel=me><i class="fa-fw fa-2x fab fa-paypal"></i></a></nav></div></div></div><div class="accordion taxonomies-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#taxonomies-toggle aria-expanded=true aria-controls=taxonomies-toggle>Taxonomies</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=taxonomies-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=taxonomyCategoriesTab data-bs-toggle=tab data-bs-target=#taxonomyCategories type=button role=tab aria-controls=taxonomyCategories aria-selected=true>
Categories</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyTagsTab data-bs-toggle=tab data-bs-target=#taxonomyTags type=button role=tab aria-controls=taxonomyTags aria-selected=true>
Tags</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomySeriesTab data-bs-toggle=tab data-bs-target=#taxonomySeries type=button role=tab aria-controls=taxonomySeries aria-selected=true>
Series</button></li><li class=nav-item role=presentation><button class=nav-link id=taxonomyArchivesTab data-bs-toggle=tab data-bs-target=#taxonomyArchives type=button role=tab aria-controls=taxonomyArchives aria-selected=true>
Archives</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=taxonomyCategories role=tabpanel aria-labelledby=taxonomyCategoriesTab tabindex=0><a href=/categories/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">15</span></a>
<a href=/categories/data-product/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Product">Data Product
<span class="badge badge-sm text-secondary bg-white ms-1">11</span></a>
<a href=/categories/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">7</span></a>
<a href=/categories/data-engineering/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Engineering">Data Engineering
<span class="badge badge-sm text-secondary bg-white ms-1">7</span></a>
<a href=/categories/machine-learning/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Machine Learning">Machine Learning
<span class="badge badge-sm text-secondary bg-white ms-1">7</span></a>
<a href=/categories/data-build-tool-dbt/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Data Build Tool (DBT)">Data Build Tool (DBT)
<span class="badge badge-sm text-secondary bg-white ms-1">5</span></a>
<a href=/categories/development/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Development>Development
<span class="badge badge-sm text-secondary bg-white ms-1">5</span></a>
<a href=/categories/general/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=General>General
<span class="badge badge-sm text-secondary bg-white ms-1">4</span></a>
<a href=/categories/change-data-capture-cdc/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Change Data Capture (CDC)">Change Data Capture (CDC)
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/categories/engineering/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title=Engineering>Engineering
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/categories/apache-airflow/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-category me-2 mb-2" title="Apache Airflow">Apache Airflow
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a></div><div class=tab-pane id=taxonomyTags role=tabpanel aria-labelledby=taxonomyTagsTab tabindex=0><a href=/tags/r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=R>R
<span class="badge badge-sm text-secondary bg-white ms-1">36</span></a>
<a href=/tags/aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=AWS>AWS
<span class="badge badge-sm text-secondary bg-white ms-1">29</span></a>
<a href=/tags/docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Docker>Docker
<span class="badge badge-sm text-secondary bg-white ms-1">19</span></a>
<a href=/tags/python/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Python>Python
<span class="badge badge-sm text-secondary bg-white ms-1">19</span></a>
<a href=/tags/apache-spark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Spark">Apache Spark
<span class="badge badge-sm text-secondary bg-white ms-1">16</span></a>
<a href=/tags/docker-compose/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Docker Compose">Docker Compose
<span class="badge badge-sm text-secondary bg-white ms-1">14</span></a>
<a href=/tags/terraform/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Terraform>Terraform
<span class="badge badge-sm text-secondary bg-white ms-1">14</span></a>
<a href=/tags/aws-lambda/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Lambda">AWS Lambda
<span class="badge badge-sm text-secondary bg-white ms-1">12</span></a>
<a href=/tags/apache-kafka/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Kafka">Apache Kafka
<span class="badge badge-sm text-secondary bg-white ms-1">11</span></a>
<a href=/tags/amazon-emr/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EMR">Amazon EMR
<span class="badge badge-sm text-secondary bg-white ms-1">10</span></a>
<a href=/tags/amazon-msk/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK">Amazon MSK
<span class="badge badge-sm text-secondary bg-white ms-1">8</span></a>
<a href=/tags/amazon-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon MSK Connect">Amazon MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">5</span></a>
<a href=/tags/data-build-tool-dbt/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Data Build Tool (DBT)">Data Build Tool (DBT)
<span class="badge badge-sm text-secondary bg-white ms-1">5</span></a>
<a href=/tags/pyspark/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=PySpark>PySpark
<span class="badge badge-sm text-secondary bg-white ms-1">5</span></a>
<a href=/tags/rserve/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Rserve>Rserve
<span class="badge badge-sm text-secondary bg-white ms-1">5</span></a>
<a href=/tags/visual-studio-code/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Visual Studio Code">Visual Studio Code
<span class="badge badge-sm text-secondary bg-white ms-1">5</span></a>
<a href=/tags/amazon-api-gateway/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon API Gateway">Amazon API Gateway
<span class="badge badge-sm text-secondary bg-white ms-1">4</span></a>
<a href=/tags/amazon-quicksight/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon QuickSight">Amazon QuickSight
<span class="badge badge-sm text-secondary bg-white ms-1">4</span></a>
<a href=/tags/kubernetes/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Kubernetes>Kubernetes
<span class="badge badge-sm text-secondary bg-white ms-1">4</span></a>
<a href=/tags/shiny/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Shiny>Shiny
<span class="badge badge-sm text-secondary bg-white ms-1">4</span></a>
<a href=/tags/amazon-eks/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EKS">Amazon EKS
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/tags/apache-hudi/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Hudi">Apache Hudi
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/tags/aws-glue/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS Glue">AWS Glue
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/tags/aws-sam/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="AWS SAM">AWS SAM
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/tags/change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Change Data Capture">Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/tags/data-lake/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Data Lake">Data Lake
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/tags/fastapi/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=FastAPI>FastAPI
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/tags/sparkr/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=SparkR>SparkR
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/tags/amazon-athena/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Athena">Amazon Athena
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/tags/amazon-eventbridge/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon EventBridge">Amazon EventBridge
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/tags/amazon-redshift/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon Redshift">Amazon Redshift
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/tags/apache-airflow/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Airflow">Apache Airflow
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/tags/javascript/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=JavaScript>JavaScript
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/tags/node.js/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Node.js>Node.js
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/tags/plumber/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=Plumber>Plumber
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/tags/rapache/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=rApache>rApache
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/tags/amazon-ecs/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon ECS">Amazon ECS
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a>
<a href=/tags/amazon-s3/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon S3">Amazon S3
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a>
<a href=/tags/amazon-sqs/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Amazon SQS">Amazon SQS
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a>
<a href=/tags/apache-hive/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title="Apache Hive">Apache Hive
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a>
<a href=https://jaehyeon.me/tags class="btn btn-sm btn-secondary post-taxonomy ps-3 post-tag me-2 mb-2" title=ALL>ALL
<span class="badge badge-sm text-secondary bg-white ms-1">72</span></a></div><div class=tab-pane id=taxonomySeries role=tabpanel aria-labelledby=taxonomySeriesTab tabindex=0><a href=/series/tree-based-methods-in-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Tree based methods in R">Tree based methods in R
<span class="badge badge-sm text-secondary bg-white ms-1">6</span></a>
<a href=/series/dbt-for-effective-data-transformation-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="DBT for Effective Data Transformation on AWS">DBT for Effective Data Transformation on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">5</span></a>
<a href=/series/serverless-data-product/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Serverless Data Product">Serverless Data Product
<span class="badge badge-sm text-secondary bg-white ms-1">4</span></a>
<a href=/series/data-lake-demo-using-change-data-capture/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Data Lake Demo Using Change Data Capture">Data Lake Demo Using Change Data Capture
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/series/parallel-processing-on-single-machine/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Parallel processing on single machine">Parallel processing on single machine
<span class="badge badge-sm text-secondary bg-white ms-1">3</span></a>
<a href=/series/api-development-with-r/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="API development with R">API development with R
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/series/integrate-schema-registry-with-msk-connect/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Integrate Schema Registry with MSK Connect">Integrate Schema Registry with MSK Connect
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/series/simplify-streaming-ingestion-on-aws/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Simplify Streaming Ingestion on AWS">Simplify Streaming Ingestion on AWS
<span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href=/series/kafka-development-with-docker/ class="btn btn-sm btn-secondary post-taxonomy ps-3 post-series me-2 mb-2" title="Kafka Development with Docker">Kafka Development with Docker
<span class="badge badge-sm text-secondary bg-white ms-1">1</span></a></div><div class=tab-pane id=taxonomyArchives role=tabpanel aria-labelledby=taxonomyArchivesTab tabindex=0><a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2023>2023 <span class="badge badge-sm text-secondary bg-white ms-1">7</span></a>
<a href=/archives/2022/ class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2022>2022 <span class="badge badge-sm text-secondary bg-white ms-1">15</span></a>
<a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2021>2021 <span class="badge badge-sm text-secondary bg-white ms-1">7</span></a>
<a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2020>2020 <span class="badge badge-sm text-secondary bg-white ms-1">1</span></a>
<a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2019>2019 <span class="badge badge-sm text-secondary bg-white ms-1">5</span></a>
<a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2018>2018 <span class="badge badge-sm text-secondary bg-white ms-1">2</span></a>
<a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2017>2017 <span class="badge badge-sm text-secondary bg-white ms-1">6</span></a>
<a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2016>2016 <span class="badge badge-sm text-secondary bg-white ms-1">6</span></a>
<a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2015>2015 <span class="badge badge-sm text-secondary bg-white ms-1">15</span></a>
<a href class="btn btn-sm btn-secondary post-taxonomy ps-3 me-2 mb-2" title=2014>2014 <span class="badge badge-sm text-secondary bg-white ms-1">5</span></a></div></div></div></div></div><div class="accordion posts-toggle"><div class="row card component accordion-item"><div class="accordion-header card-header border-0"><a class="accordion-button d-lg-none mb-1 shadow-none p-0 bg-transparent" role=button data-bs-toggle=collapse href=#posts-toggle aria-expanded=true aria-controls=posts-toggle>Posts</a></div><div class="card-body collapse accordion-collapse accordion-body d-lg-block show" id=posts-toggle><ul class="nav nav-pills nav-fill" role=tablist><li class=nav-item role=presentation><button class="nav-link active" id=featured-posts-tab data-bs-toggle=tab data-bs-target=#featured-posts type=button role=tab aria-controls=featured-posts aria-selected=true>
Featured Posts</button></li><li class=nav-item role=presentation><button class=nav-link id=recent-posts-tab data-bs-toggle=tab data-bs-target=#recent-posts type=button role=tab aria-controls=recent-posts aria-selected=true>
Recent Posts</button></li></ul><div class="tab-content mt-3"><div class="tab-pane active" id=featured-posts role=tabpanel aria-labelledby=featured-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-05-04-kafka-development-with-docker-part-1/featured_hu351ee075bb995e8f69034dc54fe8364b_98355_500x0_resize_box_3.png media="(max-width: 576px)" height=322 width=500><img class=img-fluid height=116 width=180 alt=featured.png src=/blog/2023-05-04-kafka-development-with-docker-part-1/featured_hu351ee075bb995e8f69034dc54fe8364b_98355_180x0_resize_box_3.png data-src=/blog/2023-05-04-kafka-development-with-docker-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-05-04-kafka-development-with-docker-part-1/>Kafka Development With Docker - Part 1 Kafka Cluster Setup</a><div class="post-meta mt-2"><span class=post-date>May 4, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_500x0_resize_box_3.png media="(max-width: 576px)" height=305 width=500><img class=img-fluid height=110 width=180 alt=featured.png src=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_180x0_resize_box_3.png data-src=/blog/2023-04-12-integrate-glue-schema-registry/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-04-12-integrate-glue-schema-registry/>Integrate Glue Schema Registry With Your Python Kafka App</a><div class="post-meta mt-2"><span class=post-date>April 12, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-02-08-simplify-streaming-ingestion-redshift/featured_hu77abd5c8ed84cebc51bde5ecaefc7320_32864_500x0_resize_box_3.png media="(max-width: 576px)" height=239 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2023-02-08-simplify-streaming-ingestion-redshift/featured_hu77abd5c8ed84cebc51bde5ecaefc7320_32864_180x0_resize_box_3.png data-src=/blog/2023-02-08-simplify-streaming-ingestion-redshift/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-02-08-simplify-streaming-ingestion-redshift/>Simplify Streaming Ingestion on AWS  Part 1 MSK and Redshift</a><div class="post-meta mt-2"><span class=post-date>February 8, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-09-28-dbt-on-aws-part-1-redshift/featured_hu35d67be5daab492ffba00e48de3bbd29_97234_500x0_resize_box_3.png media="(max-width: 576px)" height=244 width=500><img class=img-fluid height=88 width=180 alt=featured.png src=/blog/2022-09-28-dbt-on-aws-part-1-redshift/featured_hu35d67be5daab492ffba00e48de3bbd29_97234_180x0_resize_box_3.png data-src=/blog/2022-09-28-dbt-on-aws-part-1-redshift/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-09-28-dbt-on-aws-part-1-redshift/>Data Build Tool (Dbt) for Effective Data Transformation on AWS  Part 1 Redshift</a><div class="post-meta mt-2"><span class=post-date>September 28, 2022</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-08-26-emr-on-eks-with-terraform/featured_hu0db6c869a471dd7000f2d35dcf0e8ab0_67936_500x0_resize_box_3.png media="(max-width: 576px)" height=186 width=500><img class=img-fluid height=67 width=180 alt=featured.png src=/blog/2022-08-26-emr-on-eks-with-terraform/featured_hu0db6c869a471dd7000f2d35dcf0e8ab0_67936_180x0_resize_box_3.png data-src=/blog/2022-08-26-emr-on-eks-with-terraform/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-08-26-emr-on-eks-with-terraform/>Manage EMR on EKS With Terraform</a><div class="post-meta mt-2"><span class=post-date>August 26, 2022</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-07-18-sam-for-data-professionals/featured_hu896f95b0db9041cf59826714af2f73f7_22838_500x0_resize_box_3.png media="(max-width: 576px)" height=194 width=500><img class=img-fluid height=70 width=180 alt=featured.png src=/blog/2022-07-18-sam-for-data-professionals/featured_hu896f95b0db9041cf59826714af2f73f7_22838_180x0_resize_box_3.png data-src=/blog/2022-07-18-sam-for-data-professionals/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-07-18-sam-for-data-professionals/>Serverless Application Model (SAM) for Data Professionals</a><div class="post-meta mt-2"><span class=post-date>July 18, 2022</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-05-08-emr-local-dev/featured_hu653aa93a98a5139fededca231658be70_25693_500x0_resize_box_3.png media="(max-width: 576px)" height=291 width=500><img class=img-fluid height=105 width=180 alt=featured.png src=/blog/2022-05-08-emr-local-dev/featured_hu653aa93a98a5139fededca231658be70_25693_180x0_resize_box_3.png data-src=/blog/2022-05-08-emr-local-dev/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-05-08-emr-local-dev/>Develop and Test Apache Spark Apps for EMR Locally Using Docker</a><div class="post-meta mt-2"><span class=post-date>May 8, 2022</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2021-12-05-datalake-demo-part1/featured_hua25eccd3824300d3b1ed87f56797248c_164526_500x0_resize_box_3.png media="(max-width: 576px)" height=229 width=500><img class=img-fluid height=83 width=180 alt=featured.png src=/blog/2021-12-05-datalake-demo-part1/featured_hua25eccd3824300d3b1ed87f56797248c_164526_180x0_resize_box_3.png data-src=/blog/2021-12-05-datalake-demo-part1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2021-12-05-datalake-demo-part1/>Data Lake Demo Using Change Data Capture (CDC) on AWS  Part 1 Local Development</a><div class="post-meta mt-2"><span class=post-date>December 5, 2021</span></div></div></div></li></ul></div><div class=tab-pane id=recent-posts role=tabpanel aria-labelledby=recent-posts-tab tabindex=0><ul class="post-list list-unstyled ms-1"><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-05-11-how-i-prepared-for-ccdak/featured_hu7986024347fc7f8f9182c862049fa008_215227_500x0_resize_box_3.png media="(max-width: 576px)" height=500 width=500><img class=img-fluid height=180 width=180 alt=featured.png src=/blog/2023-05-11-how-i-prepared-for-ccdak/featured_hu7986024347fc7f8f9182c862049fa008_215227_180x0_resize_box_3.png data-src=/blog/2023-05-11-how-i-prepared-for-ccdak/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-05-11-how-i-prepared-for-ccdak/>How I Prepared for Confluent Certified Developer for Apache Kafka as a Non-Java Developer</a><div class="post-meta mt-2"><span class=post-date>May 11, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-05-04-kafka-development-with-docker-part-1/featured_hu351ee075bb995e8f69034dc54fe8364b_98355_500x0_resize_box_3.png media="(max-width: 576px)" height=322 width=500><img class=img-fluid height=116 width=180 alt=featured.png src=/blog/2023-05-04-kafka-development-with-docker-part-1/featured_hu351ee075bb995e8f69034dc54fe8364b_98355_180x0_resize_box_3.png data-src=/blog/2023-05-04-kafka-development-with-docker-part-1/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-05-04-kafka-development-with-docker-part-1/>Kafka Development With Docker - Part 1 Kafka Cluster Setup</a><div class="post-meta mt-2"><span class=post-date>May 4, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-04-24-self-hosted-blog/featured_hu1fddab158d55343a3c1c024afda22657_41850_500x0_resize_box_3.png media="(max-width: 576px)" height=240 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2023-04-24-self-hosted-blog/featured_hu1fddab158d55343a3c1c024afda22657_41850_180x0_resize_box_3.png data-src=/blog/2023-04-24-self-hosted-blog/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-04-24-self-hosted-blog/>Self-Managed Blog With Hugo and GitHub Pages</a><div class="post-meta mt-2"><span class=post-date>April 24, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_500x0_resize_box_3.png media="(max-width: 576px)" height=305 width=500><img class=img-fluid height=110 width=180 alt=featured.png src=/blog/2023-04-12-integrate-glue-schema-registry/featured_hu57e44328735e0754f0de2b0f6335f8bb_46040_180x0_resize_box_3.png data-src=/blog/2023-04-12-integrate-glue-schema-registry/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-04-12-integrate-glue-schema-registry/>Integrate Glue Schema Registry With Your Python Kafka App</a><div class="post-meta mt-2"><span class=post-date>April 12, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-03-14-simplify-streaming-ingestion-athena/featured_huef6334952f8505bdd5ee5a48de258194_43403_500x0_resize_box_3.png media="(max-width: 576px)" height=258 width=500><img class=img-fluid height=93 width=180 alt=featured.png src=/blog/2023-03-14-simplify-streaming-ingestion-athena/featured_huef6334952f8505bdd5ee5a48de258194_43403_180x0_resize_box_3.png data-src=/blog/2023-03-14-simplify-streaming-ingestion-athena/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-03-14-simplify-streaming-ingestion-athena/>Simplify Streaming Ingestion on AWS  Part 2 MSK and Athena</a><div class="post-meta mt-2"><span class=post-date>March 14, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-02-08-simplify-streaming-ingestion-redshift/featured_hu77abd5c8ed84cebc51bde5ecaefc7320_32864_500x0_resize_box_3.png media="(max-width: 576px)" height=239 width=500><img class=img-fluid height=86 width=180 alt=featured.png src=/blog/2023-02-08-simplify-streaming-ingestion-redshift/featured_hu77abd5c8ed84cebc51bde5ecaefc7320_32864_180x0_resize_box_3.png data-src=/blog/2023-02-08-simplify-streaming-ingestion-redshift/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-02-08-simplify-streaming-ingestion-redshift/>Simplify Streaming Ingestion on AWS  Part 1 MSK and Redshift</a><div class="post-meta mt-2"><span class=post-date>February 8, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2023-01-10-kafka-consumer-seek-offsets/featured_hua222fe3eeaae92dfa98b24cdf7061694_47217_500x0_resize_box_3.png media="(max-width: 576px)" height=368 width=500><img class=img-fluid height=132 width=180 alt=featured.png src=/blog/2023-01-10-kafka-consumer-seek-offsets/featured_hua222fe3eeaae92dfa98b24cdf7061694_47217_180x0_resize_box_3.png data-src=/blog/2023-01-10-kafka-consumer-seek-offsets/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2023-01-10-kafka-consumer-seek-offsets/>How to Configure Kafka Consumers to Seek Offsets by Timestamp</a><div class="post-meta mt-2"><span class=post-date>January 10, 2023</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-12-06-dbt-on-aws-part-5-athena/featured_hu2cb992d854f23cc962e70e6949802760_91796_500x0_resize_box_3.png media="(max-width: 576px)" height=243 width=500><img class=img-fluid height=87 width=180 alt=featured.png src=/blog/2022-12-06-dbt-on-aws-part-5-athena/featured_hu2cb992d854f23cc962e70e6949802760_91796_180x0_resize_box_3.png data-src=/blog/2022-12-06-dbt-on-aws-part-5-athena/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-12-06-dbt-on-aws-part-5-athena/>Data Build Tool (Dbt) for Effective Data Transformation on AWS  Part 5 Athena</a><div class="post-meta mt-2"><span class=post-date>December 6, 2022</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/featured_huad7bc56c3140ba61f8a863cb7496d5ad_91067_500x0_resize_box_3.png media="(max-width: 576px)" height=244 width=500><img class=img-fluid height=88 width=180 alt=featured.png src=/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/featured_huad7bc56c3140ba61f8a863cb7496d5ad_91067_180x0_resize_box_3.png data-src=/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/>Data Build Tool (Dbt) for Effective Data Transformation on AWS  Part 4 EMR on EKS</a><div class="post-meta mt-2"><span class=post-date>November 1, 2022</span></div></div></div></li><li class=mb-2><div class=d-flex><div class="flex-shrink-0 d-flex justify-content-center align-items-center" style=max-width:100px><picture><source srcset=/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/featured_huad7bc56c3140ba61f8a863cb7496d5ad_91067_500x0_resize_box_3.png media="(max-width: 576px)" height=244 width=500><img class=img-fluid height=88 width=180 alt=featured.png src=/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/featured_huad7bc56c3140ba61f8a863cb7496d5ad_91067_180x0_resize_box_3.png data-src=/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/featured.png loading=lazy></picture></div><div class="flex-grow-1 d-flex flex-column h-auto justify-content-center ms-3"><a class=post-title href=/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/>Data Build Tool (Dbt) for Effective Data Transformation on AWS  Part 3 EMR on EC2</a><div class="post-meta mt-2"><span class=post-date>October 19, 2022</span></div></div></div></li></ul></div></div></div></div></div></div></aside></div></main><footer class="footer mt-auto py-3 text-center container"><div class="offcanvas offcanvas-bottom h-auto" tabindex=-1 id=offcanvasActionsPanel aria-labelledby=offcanvasActionsPanelLabel><div class=offcanvas-header><div class="offcanvas-title h5" id=offcanvasActionsPanelLabel><i class="fas fa-fw fa-th-large me-1"></i>
Actions</div><button type=button class="btn-close ms-auto" data-bs-dismiss=offcanvas data-bs-target=offcanvasActionsPanel aria-label=Close></button></div><div class="offcanvas-body mt-2"><div class="actions d-flex overflow-auto align-items-center"><a role=button class="action action-go-back d-flex flex-column align-items-center me-3" href="javascript: window.history.back();"><span class="action-icon mb-2"><i class="fas fa-2x fa-chevron-circle-down" data-fa-transform=rotate-90></i></span> Go back</a>
<a role=button class="action action-reload-page d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-redo-alt"></i></span> Reload</a>
<a role=button class="action action-copy-url d-flex flex-column align-items-center me-3"><span class="action-icon mb-2"><i class="fas fa-2x fa-link"></i></span> Copy URL</a></div></div></div><div class="row text-center"><div class="col-12 mt-2"><p class=mb-2>Jaehyeon Kim</p><p class="text-secondary mb-2"><small>Consultant at Cevo    AWS Community Builder   Blogger   Real-time Enthusiast</small></p><div class="copyright mb-2 text-secondary"><small>Copyright  2023-2023 Jaehyeon Kim. All Rights Reserved.</small></div><nav class="social-links nav justify-content-center mb-2 mt-3"><a class="nav-link social-link p-0 me-1 mb-2" target=_blank href=/index.xml title=RSS rel=me><i class="fas fa-fw fa-2x fa-rss" style=color:#ea6221></i></a></nav></div><div class="col-12 col-lg-8 offset-0 offset-lg-1"></div></div></footer><script data-precache src=/assets/main/bundle.min.973e2834c632824648b0a05f184bdd913ea7064eb1314b87c2ac9cc9891223a6.js integrity="sha256-lz4oNMYygkZIsKBfGEvdkT6nBk6xMUuHwqycyYkSI6Y=" crossorigin=anonymous async></script><script data-precache src=/assets/icons/bundle.min.4f30d5267a9f2f9d45ed93969d45ec626100a969a8b91f71f753315a261e9034.js integrity="sha256-TzDVJnqfL51F7ZOWnUXsYmEAqWmouR9x91MxWiYekDQ=" crossorigin=anonymous defer></script>
<script data-precache src=/assets/viewer/bundle.min.7f7e123a50432aec1a2b911aa055ea464134e1c29cbdd67ff0ec18fab6ab3335.js integrity="sha256-f34SOlBDKuwaK5EaoFXqRkE04cKcvdZ/8OwY+rarMzU=" crossorigin=anonymous defer></script>
<script data-precache defer src=/assets/katex/bundle.min.f2bed17e252bf9064f3762211c0c01ca20721553c300c0870497712bd9ae4b9d.js integrity="sha256-8r7RfiUr+QZPN2IhHAwByiByFVPDAMCHBJdxK9muS50=" crossorigin=anonymous></script>
<script data-precache defer src=/assets/mermaid/bundle.min.6ac89481082878c4db0f641e78a7c950995fe4d7978008551531a080754919ca.js integrity="sha256-asiUgQgoeMTbD2QeeKfJUJlf5NeXgAhVFTGggHVJGco=" crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-076N8WCGWZ"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-076N8WCGWZ",{anonymize_ip:!1})}</script><script>"serviceWorker"in navigator&&window.addEventListener("load",()=>{navigator.serviceWorker.register("/service-worker.min.js").then(function(e){console.log("Successfully registered service worker",e)}).catch(function(e){console.warn("Error whilst registering service worker",e)})})</script><script src=https://giscus.app/client.js data-repo=jaehyeon-kim/jaehyeon-kim.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkyNjgwMjU0NQ==" data-category data-category-id=DIC_kwDOAZj5cc4CV2fp data-mapping=pathname data-reactions-enabled=1 data-emit-metadata=1 data-input-position=bottom data-theme=preferred_color_scheme data-lang=en data-loading=lazy crossorigin=anonymous defer></script></body></html>