<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Development on Jaehyeon Kim</title><link>https://jaehyeon.me/categories/development/</link><description>Recent content in Development on Jaehyeon Kim</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright © 2023-2024 Jaehyeon Kim. All Rights Reserved.</copyright><lastBuildDate>Mon, 18 Jul 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jaehyeon.me/categories/development/index.xml" rel="self" type="application/rss+xml"/><item><title>Serverless Application Model (SAM) for Data Professionals</title><link>https://jaehyeon.me/blog/2022-07-18-sam-for-data-professionals/</link><pubDate>Mon, 18 Jul 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2022-07-18-sam-for-data-professionals/</guid><description><![CDATA[<p><a href="https://aws.amazon.com/lambda/" target="_blank" rel="noopener noreferrer">AWS Lambda<i class="fas fa-external-link-square-alt ms-1"></i></a> provides serverless computing capabilities, and it can be used for performing validation or light processing/transformation of data. Moreover, with its integration with more than 140 AWS services, it facilitates building complex systems employing <a href="https://docs.aws.amazon.com/lambda/latest/operatorguide/event-driven-architectures.html" target="_blank" rel="noopener noreferrer">event-driven architectures<i class="fas fa-external-link-square-alt ms-1"></i></a>. There are many ways to build serverless applications and one of the most efficient ways is using specialised frameworks such as the <a href="https://aws.amazon.com/serverless/sam/" target="_blank" rel="noopener noreferrer">AWS Serverless Application Model (SAM)<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href="https://www.serverless.com/framework/docs" target="_blank" rel="noopener noreferrer">Serverless Framework<i class="fas fa-external-link-square-alt ms-1"></i></a>. In this post, I’ll demonstrate how to build a serverless data processing application using SAM.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2022-07-18-sam-for-data-professionals/featured.png" length="22838" type="image/png"/></item><item><title>Simplify Your Development on AWS with Terraform</title><link>https://jaehyeon.me/blog/2022-02-06-dev-infra-terraform/</link><pubDate>Sun, 06 Feb 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2022-02-06-dev-infra-terraform/</guid><description><![CDATA[<p>When I wrote my data lake demo series (<a href="/blog/2021-12-05-datalake-demo-part1">part 1</a>, <a href="/blog/2021-12-12-datalake-demo-part2">part 2</a> and <a href="/blog/2021-12-19-datalake-demo-part3">part 3</a>) recently, I used an Aurora PostgreSQL, MSK and EMR cluster. All of them were deployed to private subnets and dedicated infrastructure was created using CloudFormation. Using the infrastructure as code (IaC) tool helped a lot, but it resulted in creating 7 CloudFormation stacks, which was a bit harder to manage in the end. Then I looked into how to simplify building infrastructure and managing resources on AWS and decided to use Terraform instead. I find it has useful constructs (e.g. <a href="https://blog.knoldus.com/meta-arguments-in-terraform/" target="_blank" rel="noopener noreferrer">meta-arguments<i class="fas fa-external-link-square-alt ms-1"></i></a>) to make it simpler to create and manage resources. It also has a wide range of useful <a href="https://registry.terraform.io/namespaces/terraform-aws-modules" target="_blank" rel="noopener noreferrer">modules<i class="fas fa-external-link-square-alt ms-1"></i></a> that facilitate development significantly. In this post, we’ll build an infrastructure for development on AWS with Terraform. A VPN server will also be included in order to improve developer experience by accessing resources in private subnets from developer machines.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2022-02-06-dev-infra-terraform/featured.png" length="46253" type="image/png"/></item><item><title>Yet another serverless solution for invoking AWS Lambda at a sub-minute frequency</title><link>https://jaehyeon.me/blog/2021-10-13-lambda-schedule/</link><pubDate>Wed, 13 Oct 2021 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2021-10-13-lambda-schedule/</guid><description><![CDATA[<p><a href="https://docs.aws.amazon.com/eventbridge/latest/userguide/eb-run-lambda-schedule.html" target="_blank" rel="noopener noreferrer">Triggering a Lambda function by an EventBridge Events rule<i class="fas fa-external-link-square-alt ms-1"></i></a> can be used as a _serverless _replacement of <a href="https://en.wikipedia.org/wiki/Cron" target="_blank" rel="noopener noreferrer">cron job<i class="fas fa-external-link-square-alt ms-1"></i></a>. The highest frequency of it is one invocation per minute so that it cannot be used directly if you need to schedule a Lambda function more frequently. For example, it may be refreshing an application with real time metrics from an Amazon Connect instance where <a href="https://docs.aws.amazon.com/connect/latest/adminguide/real-time-metrics-reports.html" target="_blank" rel="noopener noreferrer">some metrics are updated every 15 seconds<i class="fas fa-external-link-square-alt ms-1"></i></a>. There is a <a href="https://aws.amazon.com/blogs/architecture/a-serverless-solution-for-invoking-aws-lambda-at-a-sub-minute-frequency/" target="_blank" rel="noopener noreferrer">post in the AWS Architecture Blog<i class="fas fa-external-link-square-alt ms-1"></i></a>, and it suggests using <a href="https://aws.amazon.com/step-functions/" target="_blank" rel="noopener noreferrer">AWS Step Functions<i class="fas fa-external-link-square-alt ms-1"></i></a>. Or a usual recommendation is using <a href="https://stackoverflow.com/questions/35878619/scheduled-aws-lambda-task-at-less-than-1-minute-frequency" target="_blank" rel="noopener noreferrer">Amazon EC2<i class="fas fa-external-link-square-alt ms-1"></i></a>. Albeit being <em>serverless</em>, the former gets a bit complicated especially in order to <a href="https://docs.aws.amazon.com/step-functions/latest/dg/tutorial-continue-new.html" target="_blank" rel="noopener noreferrer">handle the hard quota of 25,000 entries in the execution history<i class="fas fa-external-link-square-alt ms-1"></i></a>. And the latter is not an option if you look for a <em>serverless</em> solution. In this post, I’ll demonstrate another <em>serverless</em> solution of scheduling a Lambda function at a sub-minute frequency using <a href="https://aws.amazon.com/sqs/" target="_blank" rel="noopener noreferrer">Amazon SQS<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2021-10-13-lambda-schedule/featured.png" length="46921" type="image/png"/></item><item><title>Adding Authorization to a Graphql API</title><link>https://jaehyeon.me/blog/2021-07-20-graphql-api-authorization/</link><pubDate>Tue, 20 Jul 2021 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2021-07-20-graphql-api-authorization/</guid><description><![CDATA[<p>Authorization is the mechanism that controls who can do what on which resource in an application. Although it is a critical part of an application, there are limited resources available on how to build authorization into an app effectively. In this post, I&rsquo;ll be illustrating how to set up authorization in a GraphQL API using a custom <a href="https://www.apollographql.com/docs/apollo-server/schema/directives/" target="_blank" rel="noopener noreferrer">directive<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href="https://www.osohq.com/" target="_blank" rel="noopener noreferrer">Oso<i class="fas fa-external-link-square-alt ms-1"></i></a>, an open-source authorization library. This tutorial covers the NodeJS variant of Oso, but it also supports Python and other languages.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2021-07-20-graphql-api-authorization/featured.png" length="52143" type="image/png"/></item><item><title>Dynamic Routing and Centralized Auth with Traefik, Python and R Example</title><link>https://jaehyeon.me/blog/2019-11-29-traefik-example/</link><pubDate>Fri, 29 Nov 2019 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2019-11-29-traefik-example/</guid><description><![CDATA[<p><a href="https://kubernetes.io/docs/concepts/services-networking/ingress/" target="_blank" rel="noopener noreferrer">Ingress<i class="fas fa-external-link-square-alt ms-1"></i></a> in <a href="https://kubernetes.io/" target="_blank" rel="noopener noreferrer">Kubernetes<i class="fas fa-external-link-square-alt ms-1"></i></a> exposes HTTP and HTTPS routes from outside the cluster to services within the cluster. By setting rules, it routes requests to appropriate services (precisely requests are sent to individual <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-overview/" target="_blank" rel="noopener noreferrer">Pods<i class="fas fa-external-link-square-alt ms-1"></i></a> by <a href="https://kubernetes.io/docs/concepts/services-networking/ingress-controllers/" target="_blank" rel="noopener noreferrer">Ingress Controller<i class="fas fa-external-link-square-alt ms-1"></i></a>). Rules can be set up dynamically and I find it&rsquo;s more efficient compared to traditional <a href="https://en.wikipedia.org/wiki/Reverse_proxy" target="_blank" rel="noopener noreferrer">reverse proxy<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2019-11-29-traefik-example/featured.png" length="139790" type="image/png"/></item><item><title>Distributed Task Queue with Python and R Example</title><link>https://jaehyeon.me/blog/2019-11-15-task-queue/</link><pubDate>Fri, 15 Nov 2019 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2019-11-15-task-queue/</guid><description><![CDATA[<p>While I&rsquo;m looking into <a href="https://airflow.apache.org/" target="_blank" rel="noopener noreferrer">Apache Airflow<i class="fas fa-external-link-square-alt ms-1"></i></a>, a workflow management tool, I thought it would be beneficial to get some understanding of how <a href="http://www.celeryproject.org/" target="_blank" rel="noopener noreferrer">Celery<i class="fas fa-external-link-square-alt ms-1"></i></a> works. To do so, I built a simple web service that sends tasks to Celery workers and collects the results from them. <a href="https://fastapi.tiangolo.com/" target="_blank" rel="noopener noreferrer">FastAPI<i class="fas fa-external-link-square-alt ms-1"></i></a> is used for developing the web service and <a href="https://redis.io/" target="_blank" rel="noopener noreferrer">Redis<i class="fas fa-external-link-square-alt ms-1"></i></a> is used for the message broker and result backend. During the development, I thought it would be possible to implement similar functionality in R with <a href="https://www.rforge.net/Rserve/" target="_blank" rel="noopener noreferrer">Rserve<i class="fas fa-external-link-square-alt ms-1"></i></a>. Therefore a Rserve worker is added as an example as well. Coupling a web service with distributed task queue is beneficial on its own as it helps the service be more responsive by offloading heavyweight and long running processes to task workers.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2019-11-15-task-queue/featured.png" length="51615" type="image/png"/></item><item><title>Linux Dev Environment on Windows</title><link>https://jaehyeon.me/blog/2019-11-01-linux-on-windows/</link><pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2019-11-01-linux-on-windows/</guid><description><![CDATA[<p>I use Linux containers a lot for development. Having Windows computers at home and work, I used to use Linux VMs on VirtualBox or VMWare Workstation. It&rsquo;s not a bad option but it requires a lot of resources. Recently, after my home computer was updated, I was not able to start my hypervisor anymore. Also I didn&rsquo;t like huge resource consumption of it so that I began to look for a different development environment. A while ago, I played with <a href="https://docs.microsoft.com/en-us/windows/wsl/about" target="_blank" rel="noopener noreferrer">Windows Subsystem for Linux (WSL)<i class="fas fa-external-link-square-alt ms-1"></i></a> and it was alright. Also <a href="https://code.visualstudio.com/" target="_blank" rel="noopener noreferrer">Visual Studio Code (VSCode)<i class="fas fa-external-link-square-alt ms-1"></i></a>, <em>my favourite editor</em>, now supports <a href="https://code.visualstudio.com/docs/remote/remote-overview" target="_blank" rel="noopener noreferrer">remote development<i class="fas fa-external-link-square-alt ms-1"></i></a>. Initially I thought I would be able to create a new development environment with WSL and <a href="https://docs.docker.com/docker-for-windows/install/" target="_blank" rel="noopener noreferrer">Docker for Windows<i class="fas fa-external-link-square-alt ms-1"></i></a>. However it was until I tried a bigger app with <a href="https://docs.docker.com/compose/" target="_blank" rel="noopener noreferrer">Docker Compose<i class="fas fa-external-link-square-alt ms-1"></i></a> that Docker for Windows has a number of issues especially when containers are started by Docker Compose in WSL. I didn&rsquo;t like to spend too much time on fixing those issues as I concerned those might not be the only ones. Then I decided to install a Linux VM on <a href="https://docs.microsoft.com/en-us/virtualization/hyper-v-on-windows/about/" target="_blank" rel="noopener noreferrer">Hyper-V<i class="fas fa-external-link-square-alt ms-1"></i></a>. Luckly VSCode also supports a remote VM via SSH.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2019-11-01-linux-on-windows/featured.png" length="187978" type="image/png"/></item><item><title>AWS Local Development with LocalStack</title><link>https://jaehyeon.me/blog/2019-07-20-aws-localstack/</link><pubDate>Sat, 20 Jul 2019 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2019-07-20-aws-localstack/</guid><description><![CDATA[<p><a href="https://github.com/localstack/localstack" target="_blank" rel="noopener noreferrer">LocalStack<i class="fas fa-external-link-square-alt ms-1"></i></a> provides an easy-to-use test/mocking framework for developing AWS applications. In this post, I&rsquo;ll demonstrate how to utilize LocalStack for development using a web service.</p>
<p>Specifically a simple web service built with <a href="https://flask-restplus.readthedocs.io/en/stable/" target="_blank" rel="noopener noreferrer">Flask-RestPlus<i class="fas fa-external-link-square-alt ms-1"></i></a> is used. It supports simple CRUD operations against a database table. It is set that SQS and Lambda are used for creating and updating a record. When a <em>POST</em> or <em>PUT</em> request is made, the service sends a message to a SQS queue and directly returns <em>204</em> reponse. Once a message is received, a Lambda function is invoked and a relevant database operation is performed.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2019-07-20-aws-localstack/featured.png" length="164886" type="image/png"/></item><item><title>Cronicle Multi Server Setup</title><link>https://jaehyeon.me/blog/2019-07-19-cronicle-multi-server-setup/</link><pubDate>Fri, 19 Jul 2019 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2019-07-19-cronicle-multi-server-setup/</guid><description><![CDATA[<p>Accroding to the <a href="https://github.com/jhuckaby/Cronicle" target="_blank" rel="noopener noreferrer">project GitHub repository<i class="fas fa-external-link-square-alt ms-1"></i></a>,</p>
<blockquote>
<p>Cronicle is a multi-server task scheduler and runner, with a web based front-end UI. It handles both scheduled, repeating and on-demand jobs, targeting any number of slave servers, with real-time stats and live log viewer.</p>
</blockquote>
<p>By default, Cronicle is configured to launch a single master server - task scheduling is controlled by the master server. For high availability, it is important that another server takes the role of master when the existing master server fails.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2019-07-19-cronicle-multi-server-setup/featured.png" length="64396" type="image/png"/></item><item><title>Shiny to Vue.js</title><link>https://jaehyeon.me/blog/2018-05-26-shiny-to-vue.js/</link><pubDate>Sat, 26 May 2018 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2018-05-26-shiny-to-vue.js/</guid><description>&lt;p>In the &lt;a href="/blog/2018-05-19-asyn-shiny-and-its-limitation">last post&lt;/a>, the async feature of Shiny was discussed. Although it is a remarkable step forward to web development in R, it is not to the full extent that a Javascript application can bring. In fact, (long running) requests of a user (or session) are not impacted by those of other users (or sessions) but, for a given user, all requests are handled sequentially. On the other hand, it is not the case for a Javascript-backed app where all requests are processed asynchronously.&lt;/p></description><enclosure url="https://jaehyeon.me/blog/2018-05-26-shiny-to-vue.js/featured.png" length="247205" type="image/png"/></item><item><title>Async Shiny and Its Limitation</title><link>https://jaehyeon.me/blog/2018-05-19-asyn-shiny-and-its-limitation/</link><pubDate>Sat, 19 May 2018 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2018-05-19-asyn-shiny-and-its-limitation/</guid><description><![CDATA[<p>A Shiny app is served by one (<em>single-threaded blocking</em>) process by <a href="https://www.rstudio.com/products/shiny/download-server/" target="_blank" rel="noopener noreferrer">Open Source Shiny Server<i class="fas fa-external-link-square-alt ms-1"></i></a>. This causes a scalability issue because all requests are handled one by one in a queue. Recently the creator of <em>Shiny</em> introduced the <a href="https://rstudio.github.io/promises/" target="_blank" rel="noopener noreferrer">promises<i class="fas fa-external-link-square-alt ms-1"></i></a> package, which brings <em>asynchronous programming capabilities to R</em>. This is a remarkable step forward to web development in R.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2018-05-19-asyn-shiny-and-its-limitation/featured.png" length="247205" type="image/png"/></item><item><title>API Development with R Part II</title><link>https://jaehyeon.me/blog/2017-11-19-api-development-with-r-2/</link><pubDate>Sun, 19 Nov 2017 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2017-11-19-api-development-with-r-2/</guid><description><![CDATA[<p>In <a href="/blog/2017-11-18-api-development-with-r-1">Part I</a>, it is discussed how to serve an R function with <em>plumber</em>, <em>Rserve</em> and <em>rApache</em>. In this post, the APIs are deployed in a Docker container and, after showing example requests, their performance is compared. The <a href="https://hub.docker.com/r/rocker/r-ver/" target="_blank" rel="noopener noreferrer">rocker/r-ver:3.4<i class="fas fa-external-link-square-alt ms-1"></i></a> is used as the base image and each of the APIs is added to it. For simplicity, the APIs are served by <a href="http://supervisord.org/" target="_blank" rel="noopener noreferrer">Supervisor<i class="fas fa-external-link-square-alt ms-1"></i></a>. For performance testing, <a href="https://locust.io/" target="_blank" rel="noopener noreferrer">Locust<i class="fas fa-external-link-square-alt ms-1"></i></a> is used. The source of this post can be found in this <a href="https://github.com/jaehyeon-kim/r-api-demo" target="_blank" rel="noopener noreferrer"><strong>GitHub repository</strong><i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2017-11-19-api-development-with-r-2/featured.png" length="367256" type="image/png"/></item><item><title>API Development with R Part I</title><link>https://jaehyeon.me/blog/2017-11-18-api-development-with-r-1/</link><pubDate>Sat, 18 Nov 2017 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2017-11-18-api-development-with-r-1/</guid><description><![CDATA[<p>API is an effective way of distributing analysis outputs to external clients. When it comes to API development with R, however, there are not many choices. Probably development would be made with <a href="https://github.com/trestletech/plumber" target="_blank" rel="noopener noreferrer">plumber<i class="fas fa-external-link-square-alt ms-1"></i></a>, <a href="https://www.rforge.net/Rserve/" target="_blank" rel="noopener noreferrer">Rserve<i class="fas fa-external-link-square-alt ms-1"></i></a>, <a href="http://rapache.net/" target="_blank" rel="noopener noreferrer">rApache<i class="fas fa-external-link-square-alt ms-1"></i></a> or <a href="https://www.opencpu.org/" target="_blank" rel="noopener noreferrer">OpenCPU<i class="fas fa-external-link-square-alt ms-1"></i></a> if a client or bridge layer to R is not considered.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2017-11-18-api-development-with-r-1/featured.png" length="367256" type="image/png"/></item><item><title>Serverless Data Product POC Backend Part IV - Serving R ML Model via S3</title><link>https://jaehyeon.me/blog/2017-04-17-serverless-data-product-4/</link><pubDate>Mon, 17 Apr 2017 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2017-04-17-serverless-data-product-4/</guid><description><![CDATA[<p>In the previous posts, it is discussed how to package/deploy an <a href="https://www.r-project.org/about.html" target="_blank" rel="noopener noreferrer">R<i class="fas fa-external-link-square-alt ms-1"></i></a> model with <a href="https://aws.amazon.com/lambda/details/" target="_blank" rel="noopener noreferrer">AWS Lambda<i class="fas fa-external-link-square-alt ms-1"></i></a> and to expose the Lambda function via <a href="https://aws.amazon.com/api-gateway/" target="_blank" rel="noopener noreferrer">Amazon API Gateway<i class="fas fa-external-link-square-alt ms-1"></i></a>. Main benefits of <strong>serverless architecture</strong> is cost-effectiveness and being hassle-free from provisioning/managing servers. While the API returns a predicted admission status value given <em>GRE</em>, <em>GPA</em> and <em>Rank</em>, there is an issue if it is served within a web application: <em>Cross-Origin Resource Sharing (CORS)</em>. This post discusses how to resolve this issue by updating API configuration and the Lambda function handler with a simple web application. Also it is illustrated how to host the application in a serverless environment.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2017-04-17-serverless-data-product-4/featured.png" length="225463" type="image/png"/></item><item><title>Serverless Data Product POC Backend Part III - Exposing R ML Model via APIG</title><link>https://jaehyeon.me/blog/2017-04-13-serverless-data-product-3/</link><pubDate>Thu, 13 Apr 2017 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2017-04-13-serverless-data-product-3/</guid><description><![CDATA[<p>In <a href="/blog/2017-04-08-serverless-data-product-1">Part I</a> of this series, R and necessary libraries/packages together with a Lambda function handler are packaged and saved to <a href="https://aws.amazon.com/s3/" target="_blank" rel="noopener noreferrer">Amazon S3<i class="fas fa-external-link-square-alt ms-1"></i></a>. Then, in <a href="/blog/2017-04-11-serverless-data-product-2">Part II</a>, the package is deployed at <a href="https://aws.amazon.com/lambda/" target="_blank" rel="noopener noreferrer">AWS Lambda<i class="fas fa-external-link-square-alt ms-1"></i></a> after creating and assigning a role to the Lambda function. Although the Lambda function can be called via the Invoke API, it&rsquo;ll be much more useful if the function can be called as a web service (or API). In this post, it is discussed how to expose the Lambda function via <a href="https://aws.amazon.com/api-gateway/" target="_blank" rel="noopener noreferrer">Amazon API Gateway<i class="fas fa-external-link-square-alt ms-1"></i></a>. After creating an API by integrating the Lambda function, it is protected with an API key. Finally a custom domain name is used as an alternative URL of the API.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2017-04-13-serverless-data-product-3/featured.png" length="173293" type="image/png"/></item><item><title>Serverless Data Product POC Backend Part II - Deploying R ML Model via Lambda</title><link>https://jaehyeon.me/blog/2017-04-11-serverless-data-product-2/</link><pubDate>Tue, 11 Apr 2017 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2017-04-11-serverless-data-product-2/</guid><description><![CDATA[<p>In the <a href="/blog/2017-04-08-serverless-data-product-1">previous post</a>, <strong>serverless</strong> <strong>event-driven</strong> application development is introduced. Also how to package R, necessary libraries/packages and a Lambda function handler is discussed. No need of provisioning/managing servers is one of the key benefits of the architecture. It is also a cost-effective way of delivering a data product as functions are executed <em>on-demand</em> rather than in servers that run 24/7. Furthermore <a href="https://aws.amazon.com/lambda/pricing/" target="_blank" rel="noopener noreferrer">AWS Lambda free tier<i class="fas fa-external-link-square-alt ms-1"></i></a> includes 1M free requests per month and 400,000 GB-seconds of compute time per month, which is available to both existing and new AWS customers indefinitely. (GB-seconds is applicable when execution is made with 1 GB of memory.) Lowering the size of memory increases the execution time and thus 3.2M seconds or about 37 days are free with 128 MB of memory (1 GB divided by 8) - note that CPU power is proportional to allocated memory.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2017-04-11-serverless-data-product-2/featured.png" length="139725" type="image/png"/></item><item><title>Serverless Data Product POC Backend Part I - Packaging R ML Model for Lambda</title><link>https://jaehyeon.me/blog/2017-04-08-serverless-data-product-1/</link><pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2017-04-08-serverless-data-product-1/</guid><description><![CDATA[<p>Let say you&rsquo;ve got a prediction model built in R and you&rsquo;d like to <em>productionize</em> it, for example, by serving it in a web application. One way is exposing the model through an API that returns the predicted result as a web service. However there are many issues. Firstly R is not a language for API development although there may be some ways - eg the <a href="https://github.com/trestletech/plumber" target="_blank" rel="noopener noreferrer">plumber<i class="fas fa-external-link-square-alt ms-1"></i></a> package. More importantly developing an API is not the end of the story as the API can&rsquo;t be served in a production system if it is not <em>deployed/managed/upgraded/patched/&hellip;</em> appropriately in a server or if it is not <em>scalable</em>, <em>protected via authentication/authorization</em> and so on. Therefore it requires quite a vast range of skill sets that cover both development and DevOps (engineering).</p>]]></description><enclosure url="https://jaehyeon.me/blog/2017-04-08-serverless-data-product-1/featured.png" length="139725" type="image/png"/></item><item><title>Some Thoughts on Shiny Open Source - Render Multiple Pages</title><link>https://jaehyeon.me/blog/2016-06-27-shiny-open-source-render-multiple-pages/</link><pubDate>Mon, 27 Jun 2016 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2016-06-27-shiny-open-source-render-multiple-pages/</guid><description><![CDATA[<p>R Shiny applications are served as a single page application and it is not built to render multiple pages. There are benefits of rendering multiple pages such as code management and implement authentication. In this page, we discuss how to implement multi-page rendering in a Shiny app.</p>
<p>As indicated above, Shiny is not designed to render multiple pages and, in general, the UI is rendered on the fly as defined in <em>ui.R</em> or <em>app.R</em>. However this is not the only way as the UI can be rendered as a html output using <code>htmlOutput()</code> in <em>ui.R</em> and <code>renderUI()</code> in <em>server.R</em>. In this post, rendering multiple pages will be illustrated using an <a href="https://github.com/jaehyeon-kim/shiny-multipage" target="_blank" rel="noopener noreferrer"><strong>example application</strong><i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>]]></description></item><item><title>Some Thoughts on Shiny Open Source - Internal Load Balancing</title><link>https://jaehyeon.me/blog/2016-05-23-shiny-open-source-internal-load-balancing/</link><pubDate>Mon, 23 May 2016 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2016-05-23-shiny-open-source-internal-load-balancing/</guid><description>&lt;p>Shiny is an interesting web framework that helps create a web application quickly. If it targets a large number of users, however, there are several limitations and it is so true when the open source version of Shiny is in use. It would be possible to tackle down some of the limitations with the enterprise version but it is not easy to see enough examples of Shiny applications in production environment. While whether Shiny can be used in production environment is a controversial issue, this series of posts illustrate some ways to use &lt;strong>open source Shiny&lt;/strong> a bit more wisely. Specifically the following topics are going to be covered.&lt;/p></description></item></channel></rss>