<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>R on Jaehyeon Kim</title><link>https://jaehyeon.me/categories/r/</link><description>Recent content in R on Jaehyeon Kim</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright Â© 2023-2024 Jaehyeon Kim. All Rights Reserved.</copyright><lastBuildDate>Thu, 12 May 2016 00:00:00 +0000</lastBuildDate><atom:link href="https://jaehyeon.me/categories/r/index.xml" rel="self" type="application/rss+xml"/><item><title>Asynchronous Processing Using Job Queue</title><link>https://jaehyeon.me/blog/2016-05-12-asynchronous-processing-using-job-queue/</link><pubDate>Thu, 12 May 2016 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2016-05-12-asynchronous-processing-using-job-queue/</guid><description><![CDATA[<p>In this post, a way to overcome one of R&rsquo;s limitations (<strong>lack of multi-threading</strong>) is discussed by job queuing using the <a href="http://jobqueue.r-forge.r-project.org/" target="_blank" rel="noopener noreferrer">jobqueue package<i class="fas fa-external-link-square-alt ms-1"></i></a> - a generic asynchronous job queue implementation for R. See the package description below.</p>
<blockquote>
<p>The jobqueue package is meant to provide an easy-to-use interface that allows to queue computations for background evaluation while the calling R session remains responsive. It is based on a <em>1-node socket cluster from the parallel package</em>. The package provides a way to do basic threading in R. The main focus of the package is on an intuitive and easy-to-use interface for the job queue programming construct. &hellip; Typical applications include: <strong>background computation of lengthy tasks (such as data sourcing, model fitting, bootstrapping), simple/interactive parallelization (if you have 5 different jobs, move them to up to 5 different job queues), and concurrent task scheduling in more complicated R programs.</strong> &hellip;</p>]]></description></item><item><title>Boost SparkR with Hive</title><link>https://jaehyeon.me/blog/2016-04-30-boost-sparkr-with-hive/</link><pubDate>Sat, 30 Apr 2016 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2016-04-30-boost-sparkr-with-hive/</guid><description><![CDATA[<p>In the <a href="/blog/2016-03-02-quick-start-sparkr-in-local-and-cluster-mode">previous post</a>, it is demonstrated how to start SparkR in local and cluster mode. While SparkR is in active development, it is yet to fully support Spark&rsquo;s key libraries such as MLlib and Spark Streaming. Even, as a data processing engine, this R API is still limited as it is not possible to manipulate RDDs directly but only via Spark SQL/DataFrame API. As can be checked in the <a href="http://spark.apache.org/docs/latest/api/R/index.html" target="_blank" rel="noopener noreferrer">API doc<i class="fas fa-external-link-square-alt ms-1"></i></a>, SparkR rebuilds many existing R functions to work with Spark DataFrame and notably it borrows some functions from the dplyr package. Also there are some alien functions (eg <code>from_utc_timestamp()</code>) and many of them are from <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual" target="_blank" rel="noopener noreferrer">Hive Query Language (HiveQL)<i class="fas fa-external-link-square-alt ms-1"></i></a>. In relation to those functions from HiveQL, although some Hive user defined functions (UDFs) are ported, still many useful <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual&#43;UDF" target="_blank" rel="noopener noreferrer">UDFs<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual&#43;WindowingAndAnalytics" target="_blank" rel="noopener noreferrer">Window functions<i class="fas fa-external-link-square-alt ms-1"></i></a> don&rsquo;t exist.</p>]]></description></item><item><title>Quick Start SparkR in Local and Cluster Mode</title><link>https://jaehyeon.me/blog/2016-03-02-quick-start-sparkr-in-local-and-cluster-mode/</link><pubDate>Wed, 02 Mar 2016 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2016-03-02-quick-start-sparkr-in-local-and-cluster-mode/</guid><description><![CDATA[<p>In the <a href="/blog/2016-02-22-spark-cluster-setup-on-virtualbox">previous post</a>, a Spark cluster is set up using 2 VirtualBox Ubuntu guests. While this is a viable option for many, it is not always for others. For those who find setting-up such a cluster is not convenient, there&rsquo;s still another option, which is relying on the local mode of Spark. In this post, a <a href="https://bitbucket.org/jaehyeon/sparkr-test" target="_blank" rel="noopener noreferrer"><strong>BitBucket repository</strong><i class="fas fa-external-link-square-alt ms-1"></i></a> is introduced, which is a R project that includes <em>Spark 1.6.0 Pre-built for Hadoop 2.0 and later</em> and <em>hadoop-common 2.2.0</em> - the latter is necessary if it is tested on Windows. Then several initialization steps are discussed such as setting-up environment variables and library path as well as including the <a href="https://github.com/databricks/spark-csv" target="_blank" rel="noopener noreferrer">spark-csv package<i class="fas fa-external-link-square-alt ms-1"></i></a> and a JDBC driver. Finally it shows some examples of reading JSON and CSV files in the cluster mode.</p>]]></description></item><item><title>Spark Cluster Setup on VirtualBox</title><link>https://jaehyeon.me/blog/2016-02-22-spark-cluster-setup-on-virtualbox/</link><pubDate>Mon, 22 Feb 2016 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2016-02-22-spark-cluster-setup-on-virtualbox/</guid><description><![CDATA[<p>We discuss how to set up a Spark cluser between 2 Ubuntu guests. Firstly it begins with machine preparation. Once a machine is baked, its image file (<em>VDI</em>) is be copied for the second one. Then how to launch a cluster by <a href="http://spark.apache.org/docs/latest/spark-standalone.html" target="_blank" rel="noopener noreferrer">standalone mode<i class="fas fa-external-link-square-alt ms-1"></i></a> is discussed. Let&rsquo;s get started.</p>

<h2 id="machine-preparation" data-numberify>Machine preparation<a class="anchor ms-1" href="#machine-preparation"></a></h2>
<p>If you haven&rsquo;t read the previous post, I recommend reading as it introduces <a href="http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html" target="_blank" rel="noopener noreferrer">Putty<i class="fas fa-external-link-square-alt ms-1"></i></a> as well. Also, as Spark need Java Development Kit (JDK), you may need to <em>apt-get</em> it first - see <a href="https://www.digitalocean.com/community/tutorials/how-to-install-java-on-ubuntu-with-apt-get" target="_blank" rel="noopener noreferrer">this tutorial<i class="fas fa-external-link-square-alt ms-1"></i></a> for further details.</p>]]></description></item><item><title>Quick Test to Wrap Python in R</title><link>https://jaehyeon.me/blog/2015-11-21-quick-test-to-wrap-python-in-r/</link><pubDate>Sat, 21 Nov 2015 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2015-11-21-quick-test-to-wrap-python-in-r/</guid><description><![CDATA[<p>As mentioned in an <a href="/blog/2015-08-09-some-thoughts-on-python-for-r-users">earlier post</a>, things that are not easy in R can be relatively simple in other languages. Another example would be connecting to Amazon Web Services. In relation to s3, although there are a number of existing packages, many of them seem to be deprecated, premature or platform-dependent. (I consider the <a href="https://cloudyr.github.io/" target="_blank" rel="noopener noreferrer">cloudyr<i class="fas fa-external-link-square-alt ms-1"></i></a> project looks promising though.)</p>
<p>If there isn&rsquo;t a comprehensive <em>R-way</em> of doing something yet, it may be necessary to create it from scratch. Actually there are some options to do so by using <a href="https://aws.amazon.com/cli/" target="_blank" rel="noopener noreferrer">AWS Command Line Interface<i class="fas fa-external-link-square-alt ms-1"></i></a>, <a href="http://docs.aws.amazon.com/AmazonS3/latest/API/APIRest.html" target="_blank" rel="noopener noreferrer">AWS REST API<i class="fas fa-external-link-square-alt ms-1"></i></a> or wrapping functionality of another language.</p>]]></description></item><item><title>Packaging Analysis</title><link>https://jaehyeon.me/blog/2015-03-24-packaging-analysis/</link><pubDate>Tue, 24 Mar 2015 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2015-03-24-packaging-analysis/</guid><description><![CDATA[<p>When I imagine a workflow, it is performing the same or similar tasks regularly (daily or weekly) in an automated way. Although those tasks can be executed in a script or a *source()*d script, it may not be easy to maintain separate scripts while the size of tasks gets bigger or if they have to be executed in different machines. In academia, reproducible research shares similar ideas but the level of reproducibility introduced in <a href="https://christophergandrud.github.io/RepResR-RStudio/" target="_blank" rel="noopener noreferrer">Gandrud, 2013<i class="fas fa-external-link-square-alt ms-1"></i></a> may not suffice in a business environment as the focus is documenting in a reproducible way. A R package, however, can be an effective tool and it can be considered like a portable class library in C# or Java. Like a class library, it can include a set of necessary tasks (usually using functions) and, being portable, its dependency can be managed well - for example, it is possible to set so that dependent packages can also be installed if some of them are not installed already. Moreover the benefit of creating a R package would be significant if it has to be deployed in a production server as it&rsquo;d be a lot easier to convince system admin with the built-in unit tests, object documents and package vignettes. In this article an example of creating a R package is illustrated.</p>]]></description></item><item><title>Parallel Processing on Single Machine - Part III</title><link>https://jaehyeon.me/blog/2015-03-19-parallel-processing-on-single-machine-3/</link><pubDate>Thu, 19 Mar 2015 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2015-03-19-parallel-processing-on-single-machine-3/</guid><description><![CDATA[<p>In the <a href="/blog/2015-03-17-parallel-processing-on-single-machine-2">previous posts</a>, two groups of ways to implement parallel processing on a single machine are introduced. The first group is provided by the <strong>snow</strong> or <strong>parallel</strong> package and the functions are an extension of <code>lapply()</code> (<a href="/blog/2015-03-14-parallel-processing-on-single-machine-1">LINK</a>). The second group is based on an extension of the <em>for</em> construct (<em>foreach</em>, <em>%dopar%</em> and <em>%:%</em>). The <em>foreach</em> construct is provided by the <em>foreach</em> package while clusters are made and registered by the <strong>parallel</strong> and <strong>doParallel</strong> packages respectively (<a href="/blog/2015-03-17-parallel-processing-on-single-machine-2">LINK</a>). To conclude this series, three practical examples are discussed for comparison in this article.</p>]]></description></item><item><title>Parallel Processing on Single Machine - Part II</title><link>https://jaehyeon.me/blog/2015-03-17-parallel-processing-on-single-machine-2/</link><pubDate>Tue, 17 Mar 2015 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2015-03-17-parallel-processing-on-single-machine-2/</guid><description><![CDATA[<p>In the <a href="/blog/2015-03-14-parallel-processing-on-single-machine-1">previous article</a>, parallel processing on a single machine using the <strong>snow</strong> and <strong>parallel</strong> packages are introduced. The four functions are an extension of <code>lapply()</code> with an additional argument that specifies a cluster object. In spite of their effectiveness and ease of use, there may be cases where creating a function that can be sent into clusters is not easy or looping may be more natural. In this article, another way of implementing parallel processing on a single machine is introduced using the <strong>foreach</strong> and <strong>doParallel</strong> packages where clusters are created by the <strong>parallel</strong> package. Finally the <strong>iterators</strong> package is briefly covered as it can facilitate writing a loop. The examples here are largely based on the individual packages&rsquo; vignettes and further details can be found there.</p>]]></description></item><item><title>Parallel Processing on Single Machine - Part I</title><link>https://jaehyeon.me/blog/2015-03-14-parallel-processing-on-single-machine-1/</link><pubDate>Sat, 14 Mar 2015 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2015-03-14-parallel-processing-on-single-machine-1/</guid><description><![CDATA[<p>Lack of multi-threading and memory limitation are two outstanding weaknesses of base R. In fact, however, if the size of data is not so large that it can be read in RAM, the former would be relatively easily handled by parallel processing, provided that multiple processors are equipped. This article introduces to a way of implementing parallel processing on a single machine using the <strong>snow</strong> and <strong>parallel</strong> packages - the examples are largely based on <a href="http://shop.oreilly.com/product/0636920021421.do" target="_blank" rel="noopener noreferrer">McCallum and Weston (2012)<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>]]></description></item><item><title>Quick Trial of Adding Column</title><link>https://jaehyeon.me/blog/2015-01-14-quick-trial-of-adding-column/</link><pubDate>Wed, 14 Jan 2015 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2015-01-14-quick-trial-of-adding-column/</guid><description><![CDATA[<p>This is a quick trial of adding overall and conditional (by user) average columns in a data frame. <code>base</code>,<code>plyr</code>,<code>dplyr</code>,<code>data.table</code>,<code>dplyr + data.table</code> packages are used. Personally I perfer <code>dplyr + data.table</code> - <code>dplyr</code> for comperhensive syntax and <code>data.table</code> for speed.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="ln"> 1</span><span class="cl"><span class="c1">## set up variables</span>
</span></span><span class="line"><span class="ln"> 2</span><span class="cl"><span class="n">size</span> <span class="o">&lt;-</span> <span class="m">36000</span>
</span></span><span class="line"><span class="ln"> 3</span><span class="cl"><span class="n">numUsers</span> <span class="o">&lt;-</span> <span class="m">4900</span>
</span></span><span class="line"><span class="ln"> 4</span><span class="cl"><span class="c1"># roughly each user has 7 sessions</span>
</span></span><span class="line"><span class="ln"> 5</span><span class="cl"><span class="n">numSessions</span> <span class="o">&lt;-</span> <span class="p">(</span><span class="n">numUsers</span> <span class="o">/</span> <span class="m">7</span><span class="p">)</span> <span class="o">-</span> <span class="p">((</span><span class="n">numUsers</span> <span class="o">/</span> <span class="m">7</span><span class="p">)</span> <span class="o">%%</span> <span class="m">1</span><span class="p">)</span>
</span></span><span class="line"><span class="ln"> 6</span><span class="cl"> 
</span></span><span class="line"><span class="ln"> 7</span><span class="cl"><span class="c1">## create data frame</span>
</span></span><span class="line"><span class="ln"> 8</span><span class="cl"><span class="nf">set.seed</span><span class="p">(</span><span class="m">123457</span><span class="p">)</span>
</span></span><span class="line"><span class="ln"> 9</span><span class="cl"><span class="n">userIds</span> <span class="o">&lt;-</span> <span class="nf">sample.int</span><span class="p">(</span><span class="n">numUsers</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">10</span><span class="cl"><span class="n">ssIds</span> <span class="o">&lt;-</span> <span class="nf">sample.int</span><span class="p">(</span><span class="n">numSessions</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">11</span><span class="cl"><span class="n">scores</span> <span class="o">&lt;-</span> <span class="nf">sample.int</span><span class="p">(</span><span class="m">10</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">TRUE</span><span class="p">)</span> 
</span></span><span class="line"><span class="ln">12</span><span class="cl">
</span></span><span class="line"><span class="ln">13</span><span class="cl"><span class="n">preDf</span> <span class="o">&lt;-</span> <span class="nf">data.frame</span><span class="p">(</span><span class="n">User</span><span class="o">=</span><span class="n">userIds</span><span class="p">,</span> <span class="n">Session</span><span class="o">=</span><span class="n">ssIds</span><span class="p">,</span> <span class="n">Score</span><span class="o">=</span><span class="n">scores</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">14</span><span class="cl"><span class="n">preDf</span><span class="o">$</span><span class="n">User</span> <span class="o">&lt;-</span> <span class="nf">as.factor</span><span class="p">(</span><span class="n">preDf</span><span class="o">$</span><span class="n">User</span><span class="p">)</span> 
</span></span></code></pre></div>
<h2 id="adding-overall-average" data-numberify>Adding overall average<a class="anchor ms-1" href="#adding-overall-average"></a></h2>
<p>As calculating overall average is not complicated, I don&rsquo;t find a big difference among packages.</p>]]></description></item><item><title>Looping without for</title><link>https://jaehyeon.me/blog/2014-12-17-looping-without-for/</link><pubDate>Wed, 17 Dec 2014 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2014-12-17-looping-without-for/</guid><description><![CDATA[<p>Purely programming point of view, I consider <strong>for-loops</strong> would be better to be avoided in R as</p>
<ul>
<li>the script can be more readable</li>
<li>it is easier to handle errors</li>
</ul>
<p>Some articles on the web indicate that looping functions (or apply family of functions) don&rsquo;t guarantee faster execution and sometimes even slower. Although, assuming that the experiments are correct, in my opinion, code readability itself is beneficial enough to avoid for-loops. Even worse, R&rsquo;s dynamic typing system coupled with poor readability can result in a frustrating consequence as the code grows.</p>]]></description></item><item><title>Short R Examples</title><link>https://jaehyeon.me/blog/2014-12-03-short-r-examples/</link><pubDate>Wed, 03 Dec 2014 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2014-12-03-short-r-examples/</guid><description><![CDATA[<p>As I don&rsquo;t use R at work yet, I haven&rsquo;t got enough chances to learn R by doing. Together with teaching myself machine learning with R, I consider it would be a good idea to collect examples on the web. Recently I have been visiting a Linkedin group called <a href="http://www.linkedin.com/groups/R-Project-Statistical-Computing-77616?home=&amp;gid=77616&amp;trk=anet_ug_hm" target="_blank" rel="noopener noreferrer">The R Project for Statistical Computing<i class="fas fa-external-link-square-alt ms-1"></i></a> and suggesting scripts on data manipulation or programming topics. Actually I expected some of the topics may also be helpful to learn machine learning/statistics but, possibly due to lack of understaning of the topics in context, I&rsquo;ve found only a few - it may be necessary to look for another source. Anyway below is a summary of two examples.</p>]]></description></item><item><title>Summarise Stock Returns from Multiple Files</title><link>https://jaehyeon.me/blog/2014-11-27-summarise-stock-returns-from-multiple-files/</link><pubDate>Thu, 27 Nov 2014 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2014-11-27-summarise-stock-returns-from-multiple-files/</guid><description><![CDATA[<p>This post is a slight extension of the previous two articles (<a href="/blog/2014-11-20-download-stock-data-1">Download Stock Data - Part I</a>, <a href="/blog/2014-11-21-download-stock-data-2">Download Stock Data - Part II</a>) and we discuss how to produce gross returns, standard deviation and correlation of multiple shares.</p>
<p>The following packages are used.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="ln">1</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">knitr</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">lubridate</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">stringr</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">reshape2</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">plyr</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">6</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>
</span></span></code></pre></div><p>The script begins with creating a data folder in the format of <em>data_YYYY-MM-DD</em>.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="ln">1</span><span class="cl"><span class="c1"># create data folder</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="n">dataDir</span> <span class="o">&lt;-</span> <span class="nf">paste0</span><span class="p">(</span><span class="s">&#34;data&#34;</span><span class="p">,</span><span class="s">&#34;_&#34;</span><span class="p">,</span><span class="nf">format</span><span class="p">(</span><span class="nf">Sys.Date</span><span class="p">(),</span><span class="s">&#34;%Y-%m-%d&#34;</span><span class="p">))</span>
</span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="kr">if</span><span class="p">(</span><span class="nf">file.exists</span><span class="p">(</span><span class="n">dataDir</span><span class="p">))</span> <span class="p">{</span>
</span></span><span class="line"><span class="ln">4</span><span class="cl">  <span class="nf">unlink</span><span class="p">(</span><span class="n">dataDir</span><span class="p">,</span> <span class="n">recursive</span> <span class="o">=</span> <span class="kc">TRUE</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl">  <span class="nf">dir.create</span><span class="p">(</span><span class="n">dataDir</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">6</span><span class="cl"><span class="p">}</span> <span class="kr">else</span> <span class="p">{</span>
</span></span><span class="line"><span class="ln">7</span><span class="cl">  <span class="nf">dir.create</span><span class="p">(</span><span class="n">dataDir</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">8</span><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>Given company codes, URLs and file paths are created. Then data files are downloaded by <code>Map</code>, which is a wrapper of <code>mapply</code>. Note that R&rsquo;s <code>download.file</code> function is wrapped by <code>downloadFile</code> so that the function does not break when an error occurs.</p>]]></description></item><item><title>Download Stock Data - Part II</title><link>https://jaehyeon.me/blog/2014-11-21-download-stock-data-2/</link><pubDate>Fri, 21 Nov 2014 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2014-11-21-download-stock-data-2/</guid><description><![CDATA[<p>In an <a href="/blog/2014-11-20-download-stock-data-1">earlier article</a>, a way to download stock price data files from Google, save it into a local drive and merge them into a single data frame. If files are not large, however, it wouldn&rsquo;t be effective and, in this article, files are downloaded and merged internally.</p>
<p>The following packages are used.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="ln">1</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">knitr</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">lubridate</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">stringr</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">plyr</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>
</span></span></code></pre></div><p>Taking urls as file locations, files are directly read using <code>llply</code> and they are combined using <code>rbind_all</code>. As the merged data has multiple stocks&rsquo; records, <code>Code</code> column is created. Note that, when an error occurrs, the function returns a dummy data frame in order not to break the loop - values of the dummy data frame(s) are filtered out at the end.</p>]]></description></item><item><title>Download Stock Data - Part I</title><link>https://jaehyeon.me/blog/2014-11-20-download-stock-data-1/</link><pubDate>Thu, 20 Nov 2014 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2014-11-20-download-stock-data-1/</guid><description><![CDATA[<p>This article illustrates how to download stock price data files from Google, save it into a local drive and merge them into a single data frame. This script is slightly modified from a script which downloads RStudio package download log data. The original source can be found <a href="https://github.com/hadley/cran-logs-dplyr/blob/master/1-download.r" target="_blank" rel="noopener noreferrer">here<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>
<p>First of all, the following three packages are used.</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-r" data-lang="r"><span class="line"><span class="ln">1</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">knitr</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">2</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">lubridate</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">3</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">stringr</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">4</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">plyr</span><span class="p">)</span>
</span></span><span class="line"><span class="ln">5</span><span class="cl"><span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>
</span></span></code></pre></div><p>The script begins with creating a folder to save data files.</p>]]></description></item></channel></rss>