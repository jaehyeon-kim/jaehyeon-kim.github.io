<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Apache Spark on Jaehyeon's Personal Site</title><link>https://jaehyeon-kim.github.io/tags/apache-spark/</link><description>Recent content in Apache Spark on Jaehyeon's Personal Site</description><generator>Hugo -- gohugo.io</generator><copyright>Copyright © 2023-2023 Jaehyeon Kim. All Rights Reserved.</copyright><lastBuildDate>Tue, 01 Nov 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jaehyeon-kim.github.io/tags/apache-spark/index.xml" rel="self" type="application/rss+xml"/><item><title>Data Build Tool (dbt) for Effective Data Transformation on AWS – Part 4 EMR on EKS</title><link>https://jaehyeon-kim.github.io/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
The data build tool (dbt) is an effective data transformation tool and it supports key AWS analytics services - Redshift, Glue, EMR and Athena. In the previous posts, we discussed benefits of a common data transformation tool and the potential of dbt to cover a wide range of data projects from data warehousing to data lake to data lakehouse.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/featured.png" length="91067" type="image/png"/></item><item><title>Data Build Tool (dbt) for Effective Data Transformation on AWS – Part 3 EMR on EC2</title><link>https://jaehyeon-kim.github.io/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/</link><pubDate>Wed, 19 Oct 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
The data build tool (dbt) is an effective data transformation tool and it supports key AWS analytics services - Redshift, Glue, EMR and Athena. In the previous posts, we discussed benefits of a common data transformation tool and the potential of dbt to cover a wide range of data projects from data warehousing to data lake to data lakehouse.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/featured.png" length="91067" type="image/png"/></item><item><title>Data Build Tool (dbt) for Effective Data Transformation on AWS – Part 2 Glue</title><link>https://jaehyeon-kim.github.io/blog/2022-10-09-dbt-on-aws-part-2-glue/</link><pubDate>Sun, 09 Oct 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2022-10-09-dbt-on-aws-part-2-glue/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
The data build tool (dbt) is an effective data transformation tool and it supports key AWS analytics services - Redshift, Glue, EMR and Athena. In part 1, we discussed benefits of a common data transformation tool and the potential of dbt to cover a wide range of data projects from data warehousing to data lake to data lakehouse.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2022-10-09-dbt-on-aws-part-2-glue/featured.png" length="90647" type="image/png"/></item><item><title>Develop and Test Apache Spark Apps for EMR Remotely Using Visual Studio Code</title><link>https://jaehyeon-kim.github.io/blog/2022-09-07-emr-remote-dev/</link><pubDate>Wed, 07 Sep 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2022-09-07-emr-remote-dev/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
When we develop a Spark application on EMR, we can use docker for local development or notebooks via EMR Studio (or EMR Notebooks). However, the local development option is not viable if the size of data is large. Also, I am not a fan of notebooks as it is not possible to utilise the features my editor supports such as syntax highlighting, autocomplete and code formatting.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2022-09-07-emr-remote-dev/featured.png" length="72448" type="image/png"/></item><item><title>Manage EMR on EKS with Terraform</title><link>https://jaehyeon-kim.github.io/blog/2022-08-26-emr-on-eks-with-terraform/</link><pubDate>Fri, 26 Aug 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2022-08-26-emr-on-eks-with-terraform/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
Amazon EMR on EKS is a deployment option for Amazon EMR that allows you to automate the provisioning and management of open-source big data frameworks on EKS. While eksctl is popular for working with Amazon EKS clusters, it has limitations when it comes to building infrastructure that integrates multiple AWS services. Also, it is not straightforward to update EKS cluster resources incrementally with it.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2022-08-26-emr-on-eks-with-terraform/featured.png" length="67936" type="image/png"/></item><item><title>Data Warehousing ETL Demo with Apache Iceberg on EMR Local Environment</title><link>https://jaehyeon-kim.github.io/blog/2022-06-26-iceberg-etl-demo/</link><pubDate>Sun, 26 Jun 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2022-06-26-iceberg-etl-demo/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
Unlike traditional Data Lake, new table formats (Iceberg, Hudi and Delta Lake) support features that can be used to apply data warehousing patterns, which can bring a way to be rescued from Data Swamp. In this post, we&amp;rsquo;ll discuss how to implement ETL using retail analytics data. It has two dimension data (user and product) and a single fact data (order).</description><enclosure url="https://jaehyeon-kim.github.io/blog/2022-06-26-iceberg-etl-demo/featured.png" length="43604" type="image/png"/></item><item><title>Develop and Test Apache Spark Apps for EMR Locally Using Docker</title><link>https://jaehyeon-kim.github.io/blog/2022-05-08-emr-local-dev/</link><pubDate>Sun, 08 May 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2022-05-08-emr-local-dev/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
Amazon EMR is a managed service that simplifies running Apache Spark on AWS. It has multiple deployment options that cover EC2, EKS, Outposts and Serverless. For development and testing, EMR Notebooks or EMR Studio can be an option. Both provide a Jupyter Notebook environment and the former is only available for EMR on EC2. There are cases, however, that development (and learning) is performed in a local environment more efficiently.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2022-05-08-emr-local-dev/featured.png" length="25693" type="image/png"/></item><item><title>EMR on EKS by Example</title><link>https://jaehyeon-kim.github.io/blog/2022-01-17-emr-on-eks-by-example/</link><pubDate>Mon, 17 Jan 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2022-01-17-emr-on-eks-by-example/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
EMR on EKS provides a deployment option for Amazon EMR that allows you to automate the provisioning and management of open-source big data frameworks on Amazon EKS. While a wide range of open source big data components are available in EMR on EC2, only Apache Spark is available in EMR on EKS. It is more flexible, however, that applications of different EMR versions can be run in multiple availability zones on either EC2 or Fargate.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2022-01-17-emr-on-eks-by-example/featured.png" length="76740" type="image/png"/></item><item><title>Data Lake Demo using Change Data Capture (CDC) on AWS – Part 3 Implement Data Lake</title><link>https://jaehyeon-kim.github.io/blog/2021-12-19-datalake-demo-part3/</link><pubDate>Sun, 19 Dec 2021 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2021-12-19-datalake-demo-part3/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
In the previous post, we created a VPC that has private and public subnets in 2 availability zones in order to build and deploy the data lake solution on AWS. NAT instances are created to forward outbound traffic to the internet and a VPN bastion host is set up to facilitate deployment. An Aurora PostgreSQL cluster is deployed to host the source database and a Python command line app is used to create the database.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2021-12-19-datalake-demo-part3/featured.png" length="164526" type="image/png"/></item><item><title>Data Lake Demo using Change Data Capture (CDC) on AWS – Part 2 Implement CDC</title><link>https://jaehyeon-kim.github.io/blog/2021-12-12-datalake-demo-part2/</link><pubDate>Sun, 12 Dec 2021 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2021-12-12-datalake-demo-part2/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
In the previous post, we discussed a data lake solution where data ingestion is performed using change data capture (CDC) and the output files are upserted to an Apache Hudi table. Being registered to Glue Data Catalog, it can be used for ad-hoc queries and report/dashboard creation. The Northwind database is used as the source database and, following the transactional outbox pattern, order-related changes are _upserted _to an outbox table by triggers.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2021-12-12-datalake-demo-part2/featured.png" length="164526" type="image/png"/></item><item><title>Data Lake Demo using Change Data Capture (CDC) on AWS – Part 1 Local Development</title><link>https://jaehyeon-kim.github.io/blog/2021-12-05-datalake-demo-part1/</link><pubDate>Sun, 05 Dec 2021 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2021-12-05-datalake-demo-part1/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
Change data capture (CDC) is a proven data integration pattern that has a wide range of applications. Among those, data replication to data lakes is a good use case in data engineering. Coupled with best-in-breed data lake formats such as Apache Hudi, we can build an efficient data replication solution. This is the first post of the data lake demo series.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2021-12-05-datalake-demo-part1/featured.png" length="164526" type="image/png"/></item><item><title>Local Development of AWS Glue 3.0 and Later</title><link>https://jaehyeon-kim.github.io/blog/2021-11-14-glue-3-local-development/</link><pubDate>Sun, 14 Nov 2021 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2021-11-14-glue-3-local-development/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
In an earlier post, I demonstrated how to set up a local development environment for AWS Glue 1.0 and 2.0 using a docker image that is published by the AWS Glue team and the Visual Studio Code Remote – Containers extension. Recently AWS Glue 3.0 was released, but a docker image for this version is not published.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2021-11-14-glue-3-local-development/featured.png" length="30923" type="image/png"/></item><item><title>AWS Glue Local Development with Docker and Visual Studio Code</title><link>https://jaehyeon-kim.github.io/blog/2021-08-20-glue-local-development/</link><pubDate>Fri, 20 Aug 2021 00:00:00 +0000</pubDate><guid>https://jaehyeon-kim.github.io/blog/2021-08-20-glue-local-development/</guid><description>This article is originally posted in the Tech Insights of Cevo Australia - Link.
As described in the product page, AWS Glue is a serverless data integration service that makes it easy to discover, prepare, and combine data for analytics, machine learning, and application development. For development, a development endpoint is recommended, but it can be costly, inconvenient or unavailable (for Glue 2.0). The AWS Glue team published a Docker image that includes the AWS Glue binaries and all the dependencies packaged together.</description><enclosure url="https://jaehyeon-kim.github.io/blog/2021-08-20-glue-local-development/featured.png" length="19535" type="image/png"/></item></channel></rss>