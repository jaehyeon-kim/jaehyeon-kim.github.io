<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Jupyter Notebook on Jaehyeon Kim</title><link>https://jaehyeon.me/tags/jupyter-notebook/</link><description>Recent content in Jupyter Notebook on Jaehyeon Kim</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright Â© 2023-2024 Jaehyeon Kim. All Rights Reserved.</copyright><lastBuildDate>Thu, 18 Apr 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://jaehyeon.me/tags/jupyter-notebook/index.xml" rel="self" type="application/rss+xml"/><item><title>Apache Beam Local Development with Python - Part 3 Flink Runner</title><link>https://jaehyeon.me/blog/2024-04-18-beam-local-dev-3/</link><pubDate>Thu, 18 Apr 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-04-18-beam-local-dev-3/</guid><description><![CDATA[<p>In this series, we discuss local development of <a href="https://beam.apache.org/" target="_blank" rel="noopener noreferrer">Apache Beam<i class="fas fa-external-link-square-alt ms-1"></i></a> pipelines using Python. In the previous posts, we mainly talked about Batch pipelines with/without Beam SQL. Beam pipelines are portable between batch and streaming semantics, and we will discuss streaming pipeline development in this and the next posts. While there are multiple Beam Runners, not every Runner supports Python or some Runners have too limited features in streaming semantics - see <a href="https://beam.apache.org/documentation/runners/capability-matrix/" target="_blank" rel="noopener noreferrer">Beam Capability Matrix<i class="fas fa-external-link-square-alt ms-1"></i></a> for details. So far, the Apache Flink and Google Cloud Dataflow Runners are the best options, and we will use the <a href="https://beam.apache.org/documentation/runners/flink/" target="_blank" rel="noopener noreferrer">Flink Runner<i class="fas fa-external-link-square-alt ms-1"></i></a> in this series. This post begins with demonstrating the <em>portability layer</em> of Apache Beam as it helps understand (1) how a pipeline developed by the Python SDK can be executed in the Flink Runner that only understands Java JAR and (2) how multiple SDKs can be used in a single pipeline. Then we discuss how to start up/tear down local Flink and Kafka clusters using bash scripts. Finally, we end up demonstrating a simple streaming pipeline, which reads and writes website visit logs from and to Kafka topics.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-04-18-beam-local-dev-3/featured.png" length="262307" type="image/png"/></item><item><title>Apache Beam Local Development with Python - Part 2 Batch Pipelines</title><link>https://jaehyeon.me/blog/2024-04-04-beam-local-dev-2/</link><pubDate>Thu, 04 Apr 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-04-04-beam-local-dev-2/</guid><description><![CDATA[<p>In this series, we discuss local development of <a href="https://beam.apache.org/" target="_blank" rel="noopener noreferrer">Apache Beam<i class="fas fa-external-link-square-alt ms-1"></i></a> pipelines using Python. A basic Beam pipeline was introduced in <a href="/blog/2024-03-28-beam-local-dev-1">Part 1</a>, followed by demonstrating how to utilise Jupyter notebooks, <a href="https://beam.apache.org/documentation/dsls/sql/overview/" target="_blank" rel="noopener noreferrer">Beam SQL<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href="https://beam.apache.org/documentation/dsls/dataframes/overview/" target="_blank" rel="noopener noreferrer">Beam DataFrames<i class="fas fa-external-link-square-alt ms-1"></i></a>. In this post, we discuss Batch pipelines that aggregate website visit log by user and time. The pipelines are developed with and without <em>Beam SQL</em>. Additionally, each pipeline is implemented on a Jupyter notebook for demonstration.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-04-04-beam-local-dev-2/featured.png" length="55405" type="image/png"/></item><item><title>Apache Beam Local Development with Python - Part 1 Pipeline, Notebook, SQL and DataFrame</title><link>https://jaehyeon.me/blog/2024-03-28-beam-local-dev-1/</link><pubDate>Thu, 28 Mar 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-03-28-beam-local-dev-1/</guid><description><![CDATA[<p><a href="https://beam.apache.org/" target="_blank" rel="noopener noreferrer">Apache Beam<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href="https://flink.apache.org/" target="_blank" rel="noopener noreferrer">Apache Flink<i class="fas fa-external-link-square-alt ms-1"></i></a> are open-source frameworks for parallel, distributed data processing at scale. Flink has DataStream and Table/SQL APIs and the former has more capacity to develop sophisticated data streaming applications. The DataStream API of PyFlink, Flink&rsquo;s Python API, however, is not as complete as its Java counterpart, and it doesn&rsquo;t provide enough capability to extend when there are missing features in Python. Recently I had a chance to look through Apache Beam and found it supports more possibility to extend and/or customise its features.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-03-28-beam-local-dev-1/featured.png" length="88260" type="image/png"/></item></channel></rss>