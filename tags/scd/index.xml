<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>SCD on Jaehyeon Kim</title><link>https://jaehyeon.me/tags/scd/</link><description>Recent content in SCD on Jaehyeon Kim</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright Â© 2023-2024 Jaehyeon Kim. All Rights Reserved.</copyright><lastBuildDate>Sun, 26 Jun 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://jaehyeon.me/tags/scd/index.xml" rel="self" type="application/rss+xml"/><item><title>Data Warehousing ETL Demo with Apache Iceberg on EMR Local Environment</title><link>https://jaehyeon.me/blog/2022-06-26-iceberg-etl-demo/</link><pubDate>Sun, 26 Jun 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2022-06-26-iceberg-etl-demo/</guid><description><![CDATA[<p>Unlike traditional Data Lake, new table formats (<a href="https://iceberg.apache.org/" target="_blank" rel="noopener noreferrer">Iceberg<i class="fas fa-external-link-square-alt ms-1"></i></a>, <a href="https://hudi.apache.org/" target="_blank" rel="noopener noreferrer">Hudi<i class="fas fa-external-link-square-alt ms-1"></i></a> and <a href="https://delta.io/" target="_blank" rel="noopener noreferrer">Delta Lake<i class="fas fa-external-link-square-alt ms-1"></i></a>) support <a href="https://iceberg.apache.org/docs/latest/spark-writes/" target="_blank" rel="noopener noreferrer">features<i class="fas fa-external-link-square-alt ms-1"></i></a> that can be used to apply data warehousing patterns, which can bring a way to be rescued from <a href="https://www.gartner.com/en/newsroom/press-releases/2014-07-28-gartner-says-beware-of-the-data-lake-fallacy" target="_blank" rel="noopener noreferrer">Data Swamp<i class="fas fa-external-link-square-alt ms-1"></i></a>. In this post, we&rsquo;ll discuss how to implement ETL using retail analytics data. It has two dimension data (user and product) and a single fact data (order). The dimension data sets have different ETL strategies depending on whether to track historical changes. For the fact data, the primary keys of the dimension data are added to facilitate later queries. We&rsquo;ll use Iceberg for data storage/management and Spark for data processing. Instead of provisioning an EMR cluster, a local development environment will be used. Finally, the ETL results will be queried by Athena for verification.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2022-06-26-iceberg-etl-demo/featured.png" length="43604" type="image/png"/></item></channel></rss>