<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Data Build Tool (DBT) on Jaehyeon Kim</title><link>https://jaehyeon.me/tags/data-build-tool-dbt/</link><description>Recent content in Data Build Tool (DBT) on Jaehyeon Kim</description><generator>Hugo -- gohugo.io</generator><language>en</language><copyright>Copyright © 2023-2024 Jaehyeon Kim. All Rights Reserved.</copyright><lastBuildDate>Thu, 05 Sep 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://jaehyeon.me/tags/data-build-tool-dbt/index.xml" rel="self" type="application/rss+xml"/><item><title>DBT CI/CD Demo with BigQuery and GitHub Actions</title><link>https://jaehyeon.me/blog/2024-09-05-dbt-cicd-demo/</link><pubDate>Thu, 05 Sep 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-09-05-dbt-cicd-demo/</guid><description><![CDATA[<p>Continuous integration (CI) is the process of ensuring new code integrates with the larger code base, and it puts a great emphasis on testing automation to check that the application is not broken whenever new commits are integrated into the main branch. Continuous delivery (CD) is an extension of continuous integration since it automatically deploys all code changes to a testing and/or production environment after the build stage. CI/CD helps development teams avoid bugs and code failures while maintaining a continuous cycle of software development and updates. In this post, we discuss how to set up a CI/CD pipeline for a <a href="https://www.getdbt.com/" target="_blank" rel="noopener noreferrer">data build tool (<em>dbt</em>)<i class="fas fa-external-link-square-alt ms-1"></i></a> project using <a href="https://github.com/features/actions" target="_blank" rel="noopener noreferrer">GitHub Actions<i class="fas fa-external-link-square-alt ms-1"></i></a> where <a href="https://cloud.google.com/bigquery?hl=en" target="_blank" rel="noopener noreferrer">BigQuery<i class="fas fa-external-link-square-alt ms-1"></i></a> is used as the target data warehouse.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-09-05-dbt-cicd-demo/featured.png" length="60835" type="image/png"/></item><item><title>Data Build Tool (dbt) Pizza Shop Demo - Part 6 ETL on Amazon Athena via Airflow</title><link>https://jaehyeon.me/blog/2024-03-14-dbt-pizza-shop-6/</link><pubDate>Thu, 14 Mar 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-03-14-dbt-pizza-shop-6/</guid><description><![CDATA[<p>In <a href="/blog/2024-03-07-dbt-pizza-shop-5">Part 5</a>, we developed a <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">dbt<i class="fas fa-external-link-square-alt ms-1"></i></a> project that that targets <a href="https://iceberg.apache.org/" target="_blank" rel="noopener noreferrer">Apache Iceberg<i class="fas fa-external-link-square-alt ms-1"></i></a> where transformations are performed on <a href="https://aws.amazon.com/athena/" target="_blank" rel="noopener noreferrer">Amazon Athena<i class="fas fa-external-link-square-alt ms-1"></i></a>. Two dimension tables that keep product and user records are created as <a href="https://en.wikipedia.org/wiki/Slowly_changing_dimension" target="_blank" rel="noopener noreferrer">Type 2 slowly changing dimension (SCD Type 2)<i class="fas fa-external-link-square-alt ms-1"></i></a> tables, and one transactional fact table is built to keep pizza orders. To improve query performance, the fact table is denormalized to pre-join records from the dimension tables using the array and struct data types. In this post, we discuss how to set up an ETL process on the project using Apache Airflow.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-03-14-dbt-pizza-shop-6/featured.png" length="82921" type="image/png"/></item><item><title>Data Build Tool (dbt) Pizza Shop Demo - Part 5 Modelling on Amazon Athena</title><link>https://jaehyeon.me/blog/2024-03-07-dbt-pizza-shop-5/</link><pubDate>Thu, 07 Mar 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-03-07-dbt-pizza-shop-5/</guid><description><![CDATA[<p>In <a href="%28/blog/2024-01-18-dbt-pizza-shop-1%29">Part 1</a> and <a href="%28/blog/2024-02-08-dbt-pizza-shop-3%29">Part 3</a>, we developed <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">data build tool (dbt)<i class="fas fa-external-link-square-alt ms-1"></i></a> projects that target <em>PostgreSQL</em> and <em>BigQuery</em> using fictional pizza shop data. The data is modelled by <a href="https://en.wikipedia.org/wiki/Slowly_changing_dimension" target="_blank" rel="noopener noreferrer">SCD type 2<i class="fas fa-external-link-square-alt ms-1"></i></a> dimension tables and one transactional fact table. While the order records should be joined with dimension tables to get complete details for <em>PostgreSQL</em>, the fact table is denormalized using <a href="https://cloud.google.com/bigquery/docs/best-practices-performance-nested" target="_blank" rel="noopener noreferrer">nested and repeated fields<i class="fas fa-external-link-square-alt ms-1"></i></a> to improve query performance for <em>BigQuery</em>.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-03-07-dbt-pizza-shop-5/featured.png" length="61499" type="image/png"/></item><item><title>Data Build Tool (dbt) Pizza Shop Demo - Part 4 ETL on BigQuery via Airflow</title><link>https://jaehyeon.me/blog/2024-02-22-dbt-pizza-shop-4/</link><pubDate>Thu, 22 Feb 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-02-22-dbt-pizza-shop-4/</guid><description><![CDATA[<p>In <a href="/blog/2024-02-08-dbt-pizza-shop-3">Part 3</a>, we developed a <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">dbt<i class="fas fa-external-link-square-alt ms-1"></i></a> project that targets Google BigQuery with fictional pizza shop data. Two dimension tables that keep product and user records are created as <a href="https://en.wikipedia.org/wiki/Slowly_changing_dimension" target="_blank" rel="noopener noreferrer">Type 2 slowly changing dimension (SCD Type 2)<i class="fas fa-external-link-square-alt ms-1"></i></a> tables, and one transactional fact table is built to keep pizza orders. The fact table is denormalized using <a href="https://cloud.google.com/bigquery/docs/best-practices-performance-nested" target="_blank" rel="noopener noreferrer">nested and repeated fields<i class="fas fa-external-link-square-alt ms-1"></i></a> for improving query performance. In this post, we discuss how to set up an ETL process on the project using Apache Airflow.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-02-22-dbt-pizza-shop-4/featured.png" length="89588" type="image/png"/></item><item><title>Data Build Tool (dbt) Pizza Shop Demo - Part 3 Modelling on BigQuery</title><link>https://jaehyeon.me/blog/2024-02-08-dbt-pizza-shop-3/</link><pubDate>Thu, 08 Feb 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-02-08-dbt-pizza-shop-3/</guid><description><![CDATA[<p>In this series, we discuss practical examples of data warehouse and lakehouse development where data transformation is performed by the <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">data build tool (dbt)<i class="fas fa-external-link-square-alt ms-1"></i></a> and ETL is managed by <a href="https://airflow.apache.org/" target="_blank" rel="noopener noreferrer">Apache Airflow<i class="fas fa-external-link-square-alt ms-1"></i></a>. In <a href="/blog/2024-01-18-dbt-pizza-shop-1">Part 1</a>, we developed a <em>dbt</em> project on PostgreSQL using fictional pizza shop data. At the end, the data sets are modelled by two <a href="https://en.wikipedia.org/wiki/Slowly_changing_dimension" target="_blank" rel="noopener noreferrer">SCD type 2<i class="fas fa-external-link-square-alt ms-1"></i></a> dimension tables and one transactional fact table. In this post, we create a new <em>dbt</em> project that targets <a href="https://cloud.google.com/bigquery" target="_blank" rel="noopener noreferrer">Google BigQuery<i class="fas fa-external-link-square-alt ms-1"></i></a>. While the dimension tables are kept by the same SCD type 2 approach, the fact table is denormalized using <a href="https://cloud.google.com/bigquery/docs/best-practices-performance-nested" target="_blank" rel="noopener noreferrer">nested and repeated fields<i class="fas fa-external-link-square-alt ms-1"></i></a>, which potentially can improve query performance by pre-joining corresponding dimension records.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-02-08-dbt-pizza-shop-3/featured.png" length="70297" type="image/png"/></item><item><title>Data Build Tool (dbt) Pizza Shop Demo - Part 2 ETL on PostgreSQL via Airflow</title><link>https://jaehyeon.me/blog/2024-01-25-dbt-pizza-shop-2/</link><pubDate>Thu, 25 Jan 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-01-25-dbt-pizza-shop-2/</guid><description><![CDATA[<p>In this series of posts, we discuss data warehouse/lakehouse examples using <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">data build tool (dbt)<i class="fas fa-external-link-square-alt ms-1"></i></a> including ETL orchestration with Apache Airflow. In Part 1, we developed a <em>dbt</em> project on PostgreSQL with fictional pizza shop data. Two dimension tables that keep product and user records are created as <a href="https://en.wikipedia.org/wiki/Slowly_changing_dimension" target="_blank" rel="noopener noreferrer">Type 2 slowly changing dimension (SCD Type 2)<i class="fas fa-external-link-square-alt ms-1"></i></a> tables, and one transactional fact table is built to keep pizza orders. In this post, we discuss how to set up an ETL process on the project using Apache Airflow.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-01-25-dbt-pizza-shop-2/featured.png" length="77355" type="image/png"/></item><item><title>Data Build Tool (dbt) Pizza Shop Demo - Part 1 Modelling on PostgreSQL</title><link>https://jaehyeon.me/blog/2024-01-18-dbt-pizza-shop-1/</link><pubDate>Thu, 18 Jan 2024 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2024-01-18-dbt-pizza-shop-1/</guid><description><![CDATA[<p>The <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">data build tool (dbt)<i class="fas fa-external-link-square-alt ms-1"></i></a> is a popular data transformation tool for data warehouse development. Moreover, it can be used for <a href="https://www.databricks.com/glossary/data-lakehouse" target="_blank" rel="noopener noreferrer">data lakehouse<i class="fas fa-external-link-square-alt ms-1"></i></a> development thanks to open table formats such as Apache Iceberg, Apache Hudi and Delta Lake. <em>dbt</em> supports key AWS analytics services and I wrote a series of posts that discuss how to utilise <em>dbt</em> with <a href="/blog/2022-09-28-dbt-on-aws-part-1-redshift">Redshift</a>, <a href="/blog/2022-10-09-dbt-on-aws-part-2-glue">Glue</a>, <a href="/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2">EMR on EC2</a>, <a href="/blog/2022-11-01-dbt-on-aws-part-4-emr-eks">EMR on EKS</a>, and <a href="/blog/2023-04-12-integrate-glue-schema-registry">Athena</a>. Those posts focus on platform integration, however, they do not show realistic ETL scenarios.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2024-01-18-dbt-pizza-shop-1/featured.png" length="85093" type="image/png"/></item><item><title>Data Build Tool (dbt) for Effective Data Transformation on AWS – Part 5 Athena</title><link>https://jaehyeon.me/blog/2022-12-06-dbt-on-aws-part-5-athena/</link><pubDate>Tue, 06 Dec 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2022-12-06-dbt-on-aws-part-5-athena/</guid><description><![CDATA[<p>The <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">data build tool (dbt)<i class="fas fa-external-link-square-alt ms-1"></i></a> is an effective data transformation tool and it supports key AWS analytics services - Redshift, Glue, EMR and Athena. In the previous posts, we discussed benefits of a common data transformation tool and the potential of dbt to cover a wide range of data projects from data warehousing to data lake to data lakehouse. Demo data projects that target Redshift Serverless, Glue, EMR on EC2 and EMR on EKS are illustrated as well. In the last part of the dbt on AWS series, we discuss data transformation pipelines using dbt on <a href="https://aws.amazon.com/athena" target="_blank" rel="noopener noreferrer">Amazon Athena<i class="fas fa-external-link-square-alt ms-1"></i></a>. <a href="https://www.imdb.com/interfaces/" target="_blank" rel="noopener noreferrer">Subsets of IMDb data<i class="fas fa-external-link-square-alt ms-1"></i></a> are used as source and data models are developed in multiple layers according to the <a href="https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview" target="_blank" rel="noopener noreferrer">dbt best practices<i class="fas fa-external-link-square-alt ms-1"></i></a>. A list of posts of this series can be found below.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2022-12-06-dbt-on-aws-part-5-athena/featured.png" length="91796" type="image/png"/></item><item><title>Data Build Tool (dbt) for Effective Data Transformation on AWS – Part 4 EMR on EKS</title><link>https://jaehyeon.me/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/</link><pubDate>Tue, 01 Nov 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/</guid><description><![CDATA[<p>The <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">data build tool (dbt)<i class="fas fa-external-link-square-alt ms-1"></i></a> is an effective data transformation tool and it supports key AWS analytics services - Redshift, Glue, EMR and Athena. In the previous posts, we discussed benefits of a common data transformation tool and the potential of dbt to cover a wide range of data projects from data warehousing to data lake to data lakehouse. Demo data projects that target Redshift Serverless, Glue and EMR on EC2 are illustrated as well. In part 4 of the dbt on AWS series, we discuss data transformation pipelines using dbt on <a href="https://aws.amazon.com/emr/features/eks/" target="_blank" rel="noopener noreferrer">Amazon EMR on EKS<i class="fas fa-external-link-square-alt ms-1"></i></a>. As Spark Submit does not allow the spark thrift server to run in cluster mode on Kubernetes, a simple wrapper class is created to overcome the limitation and it makes the thrift server run indefinitely. <a href="https://www.imdb.com/interfaces/" target="_blank" rel="noopener noreferrer">Subsets of IMDb data<i class="fas fa-external-link-square-alt ms-1"></i></a> are used as source and data models are developed in multiple layers according to the <a href="https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview" target="_blank" rel="noopener noreferrer">dbt best practices<i class="fas fa-external-link-square-alt ms-1"></i></a>. A list of posts of this series can be found below.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2022-11-01-dbt-on-aws-part-4-emr-eks/featured.png" length="91067" type="image/png"/></item><item><title>Data Build Tool (dbt) for Effective Data Transformation on AWS – Part 3 EMR on EC2</title><link>https://jaehyeon.me/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/</link><pubDate>Wed, 19 Oct 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/</guid><description><![CDATA[<p>The <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">data build tool (dbt)<i class="fas fa-external-link-square-alt ms-1"></i></a> is an effective data transformation tool and it supports key AWS analytics services - Redshift, Glue, EMR and Athena. In the previous posts, we discussed benefits of a common data transformation tool and the potential of dbt to cover a wide range of data projects from data warehousing to data lake to data lakehouse. Demo data projects that target Redshift Serverless and Glue are illustrated as well. In part 3 of the dbt on AWS series, we discuss data transformation pipelines using dbt on <a href="https://aws.amazon.com/emr/" target="_blank" rel="noopener noreferrer">Amazon EMR<i class="fas fa-external-link-square-alt ms-1"></i></a>. <a href="https://www.imdb.com/interfaces/" target="_blank" rel="noopener noreferrer">Subsets of IMDb data<i class="fas fa-external-link-square-alt ms-1"></i></a> are used as source and data models are developed in multiple layers according to the <a href="https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview" target="_blank" rel="noopener noreferrer">dbt best practices<i class="fas fa-external-link-square-alt ms-1"></i></a>. A list of posts of this series can be found below.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2022-10-19-dbt-on-aws-part-3-emr-ec2/featured.png" length="91067" type="image/png"/></item><item><title>Data Build Tool (dbt) for Effective Data Transformation on AWS – Part 2 Glue</title><link>https://jaehyeon.me/blog/2022-10-09-dbt-on-aws-part-2-glue/</link><pubDate>Sun, 09 Oct 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2022-10-09-dbt-on-aws-part-2-glue/</guid><description><![CDATA[<p>The <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">data build tool (dbt)<i class="fas fa-external-link-square-alt ms-1"></i></a> is an effective data transformation tool and it supports key AWS analytics services - Redshift, Glue, EMR and Athena. In <a href="/blog/2022-09-28-dbt-on-aws-part-1-redshift">part 1</a>, we discussed benefits of a common data transformation tool and the potential of dbt to cover a wide range of data projects from data warehousing to data lake to data lakehouse. A demo data project that targets Redshift Serverless is illustrated as well. In part 2 of the dbt on AWS series, we discuss data transformation pipelines using dbt on <a href="https://aws.amazon.com/glue/" target="_blank" rel="noopener noreferrer">AWS Glue<i class="fas fa-external-link-square-alt ms-1"></i></a>. <a href="https://www.imdb.com/interfaces/" target="_blank" rel="noopener noreferrer">Subsets of IMDb data<i class="fas fa-external-link-square-alt ms-1"></i></a> are used as source and data models are developed in multiple layers according to the <a href="https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview" target="_blank" rel="noopener noreferrer">dbt best practices<i class="fas fa-external-link-square-alt ms-1"></i></a>. A list of posts of this series can be found below.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2022-10-09-dbt-on-aws-part-2-glue/featured.png" length="90647" type="image/png"/></item><item><title>Data Build Tool (dbt) for Effective Data Transformation on AWS – Part 1 Redshift</title><link>https://jaehyeon.me/blog/2022-09-28-dbt-on-aws-part-1-redshift/</link><pubDate>Wed, 28 Sep 2022 00:00:00 +0000</pubDate><guid>https://jaehyeon.me/blog/2022-09-28-dbt-on-aws-part-1-redshift/</guid><description><![CDATA[<p>The <a href="https://docs.getdbt.com/docs/introduction" target="_blank" rel="noopener noreferrer">data build tool (dbt)<i class="fas fa-external-link-square-alt ms-1"></i></a> is an effective data transformation tool and it supports key AWS analytics services - Redshift, Glue, EMR and Athena. In part 1 of the dbt on AWS series, we discuss data transformation pipelines using dbt on <a href="https://aws.amazon.com/redshift/redshift-serverless/" target="_blank" rel="noopener noreferrer">Redshift Serverless<i class="fas fa-external-link-square-alt ms-1"></i></a>. <a href="https://www.imdb.com/interfaces/" target="_blank" rel="noopener noreferrer">Subsets of IMDb data<i class="fas fa-external-link-square-alt ms-1"></i></a> are used as source and data models are developed in multiple layers according to the <a href="https://docs.getdbt.com/guides/best-practices/how-we-structure/1-guide-overview" target="_blank" rel="noopener noreferrer">dbt best practices<i class="fas fa-external-link-square-alt ms-1"></i></a>.</p>]]></description><enclosure url="https://jaehyeon.me/blog/2022-09-28-dbt-on-aws-part-1-redshift/featured.png" length="97234" type="image/png"/></item></channel></rss>