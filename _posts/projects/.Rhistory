## knn
k = 3 # hyper (or tuning) parameter set to be 3
knn.feat.train = subset(Smarket, Year!=2005, select=c(Lag1,Lag2))
knn.feat.test = subset(Smarket, Year==2005, select=c(Lag1,Lag2))
knn.resp.train = subset(Smarket, Year!=2005, select=c(Direction), drop=TRUE) # should be factors
knn.pred = knn(train=knn.feat.train, test=knn.feat.test, cl=knn.resp.train, k=k)
knn.cm = table(data.frame(response=knn.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
knn.mmce = 1 - sum(diag(knn.cm)) / sum(knn.cm)
knn.mmce
# keep output
model = c(model,"knn")
hyper = c(hyper,3)
mmce = c(mmce,knn.mmce)
## consolidate output
output = data.frame(model=model, hyper=hyper, mmce=mmce)
output
library(MASS) # lda
lda.fit = lda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
lda.fit
lda.pred = predict(lda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))
head(glm.pred)
head(lda.pred)
head(glm.pred)
head(lda.pred)
lda.pred = predict(lda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
head(lda.pred)
head(glm.pred)
lda.fit = lda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
lda.pred = predict(lda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
lda.cm = table(data.frame(response=lda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
lda.cm
rm(list = ls())
## glm
# test on Year == 2005
glm.fit = glm(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), family=binomial, subset=Smarket$Year!=2005)
glm.probs = predict(glm.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)), type="response")
glm.pred = sapply(glm.probs, function(p) { ifelse(p>.5,"Up","Down") })
glm.cm = table(data.frame(response=glm.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
glm.mmce = 1 - sum(diag(glm.cm)) / sum(glm.cm)
# keep output
model = c("glm")
hyper = c(NA)
mmce = c(glm.mmce)
## lda
lda.fit = lda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
lda.pred = predict(lda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
lda.cm = table(data.frame(response=lda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
lda.mmce = 1 - sum(diag(lda.cm)) / sum(lda.cm)
# keep output
model = c(model,"lda")
hyper = c(hyper, NA)
mmce = c(mmce, lda.mmce)
## knn
k = 3 # hyper (or tuning) parameter set to be 3
knn.feat.train = subset(Smarket, Year!=2005, select=c(Lag1,Lag2))
knn.feat.test = subset(Smarket, Year==2005, select=c(Lag1,Lag2))
knn.resp.train = subset(Smarket, Year!=2005, select=c(Direction), drop=TRUE) # should be factors
knn.pred = knn(train=knn.feat.train, test=knn.feat.test, cl=knn.resp.train, k=k)
knn.cm = table(data.frame(response=knn.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
knn.mmce = 1 - sum(diag(knn.cm)) / sum(knn.cm)
knn.mmce
# keep output
model = c(model,"knn")
hyper = c(hyper,3)
mmce = c(mmce,knn.mmce)
## consolidate output
output = data.frame(model=model, hyper=hyper, mmce=mmce)
output
output[1,3]
output[1,3] - output[2,3]
rm(list = ls())
## glm
# test on Year == 2005
glm.fit = glm(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), family=binomial, subset=Smarket$Year!=2005)
glm.probs = predict(glm.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)), type="response")
glm.pred = sapply(glm.probs, function(p) { ifelse(p>.5,"Up","Down") })
glm.cm = table(data.frame(response=glm.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
glm.mmce = 1 - sum(diag(glm.cm)) / sum(glm.cm)
# keep output
model = c("glm")
hyper = c(NA)
mmce = c(glm.mmce)
## lda
lda.fit = lda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
lda.pred = predict(lda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
lda.cm = table(data.frame(response=lda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
lda.mmce = 1 - sum(diag(lda.cm)) / sum(lda.cm)
# keep output
model = c(model,"lda")
hyper = c(hyper, NA)
mmce = c(mmce, lda.mmce)
## qda
qda.fit = qda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
qda.pred = predict(qda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
qda.cm = table(data.frame(response=qda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
qda.mmce = 1 - sum(diag(qda.cm)) / sum(qda.cm)
# keep output
model = c(model,"qda")
hyper = c(hyper, NA)
mmce = c(mmce, qda.mmce)
## knn
k = 3 # hyper (or tuning) parameter set to be 3
knn.feat.train = subset(Smarket, Year!=2005, select=c(Lag1,Lag2))
knn.feat.test = subset(Smarket, Year==2005, select=c(Lag1,Lag2))
knn.resp.train = subset(Smarket, Year!=2005, select=c(Direction), drop=TRUE) # should be factors
knn.pred = knn(train=knn.feat.train, test=knn.feat.test, cl=knn.resp.train, k=k)
knn.cm = table(data.frame(response=knn.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
knn.mmce = 1 - sum(diag(knn.cm)) / sum(knn.cm)
knn.mmce
# keep output
model = c(model,"knn")
hyper = c(hyper,3)
mmce = c(mmce,knn.mmce)
## consolidate output
output = data.frame(model=model, hyper=hyper, mmce=mmce)
output
rm(list = ls())
task = makeClassifTask(id="Smarket", data=subset(Smarket, select=c(Lag1,Lag2,Direction)), positive="Up", target="Direction")
task
knn.lrn = makeLearner("classif.knn", predict.type="prob")
knn.lrn
knn.lrn = makeLearner("classif.knn")
knn.lrn
glm.lrn = makeLearner("classif.binomial")
glm.lrn
listMeasures(task)
rm(list = ls())
rm(list = ls())
library(ISLR)
library(MASS) # lda/qda
library(class) # knn
library(mlr)
## use only Lag1 and Lag2 as features / Direction as response
str(Smarket)
#### ISLR
## glm
# test on Year == 2005
glm.fit = glm(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), family=binomial, subset=Smarket$Year!=2005)
glm.probs = predict(glm.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)), type="response")
glm.pred = sapply(glm.probs, function(p) { ifelse(p>.5,"Up","Down") })
glm.cm = table(data.frame(response=glm.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
glm.mmce = 1 - sum(diag(glm.cm)) / sum(glm.cm)
# keep output
model = c("glm")
hyper = c(NA)
mmce = c(glm.mmce)
## lda
lda.fit = lda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
lda.pred = predict(lda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
lda.cm = table(data.frame(response=lda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
lda.mmce = 1 - sum(diag(lda.cm)) / sum(lda.cm)
# keep output
model = c(model,"lda")
hyper = c(hyper, NA)
mmce = c(mmce, lda.mmce)
## qda
qda.fit = qda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
qda.pred = predict(qda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
qda.cm = table(data.frame(response=qda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
qda.mmce = 1 - sum(diag(qda.cm)) / sum(qda.cm)
# keep output
model = c(model,"qda")
hyper = c(hyper, NA)
mmce = c(mmce, qda.mmce)
## knn
k = 3 # hyper (or tuning) parameter set to be 3
knn.feat.train = subset(Smarket, Year!=2005, select=c(Lag1,Lag2))
knn.feat.test = subset(Smarket, Year==2005, select=c(Lag1,Lag2))
knn.resp.train = subset(Smarket, Year!=2005, select=c(Direction), drop=TRUE) # should be factors
knn.pred = knn(train=knn.feat.train, test=knn.feat.test, cl=knn.resp.train, k=k)
knn.cm = table(data.frame(response=knn.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
knn.mmce = 1 - sum(diag(knn.cm)) / sum(knn.cm)
# keep output
model = c(model,"knn")
hyper = c(hyper,3)
mmce = c(mmce,knn.mmce)
## consolidate output
output = data.frame(model=model, hyper=hyper, mmce=mmce)
output
#### MLR
### task
task = makeClassifTask(id="Smarket", data=subset(Smarket, select=c(Lag1,Lag2,Direction)), positive="Up", target="Direction")
task
### learner
## no need to set up learner if kept default setup
## glm
glm.lrn = makeLearner("classif.binomial")
glm.lrn
## lda
lda.lrn = makeLearner("classif.lda")
lda.lrn
## qda
qda.lrn = makeLearner("classif.qda")
qda.lrn
## knn
knn.lrn = makeLearner("classif.knn")
knn.lrn
knn.lrn
showHyperParameters(knn.lrn)
showHyperPars(knn.lrn)
getHyperPars(knn.lrn)
knn.lrn$par.vals
?getHyperPars
setHyperPars(knn.lrn, k=3)
knn.lrn
knn.lrn = setHyperpars(knn.lrn, k=4)
knn.lrn = setHyperPars(knn.lrn, k=4)
knn.lrn
?make.learner
?makeLearner
knn.lrn = makeLearner("classif.knn", par.vals=list(k=4))
knn.lrn
knn.lrn = makeLearner("classif.knn", par.vals=list(k=3))
knn.lrn
listMeasures(knn.lrn)
?makeResampleDesc
rdesc = makeResampleDesc("Holdout")
rdesc
?HoldoutDesc
Smarket$Year
Smarket$Year[990:1250]
Smarket$Year[996:1250]
Smarket$Year[998:1250]
Smarket$Year[999:1250]
length(Smarket$Direction)
length(Smarket$Yeare) - length(Smarket$Direction[SmarketDirection$Year==2005])
length(Smarket$Yeare) - length(Smarket$Direction[Smarket$Direction$Year==2005])
length(Smarket$Yeare) - length(Smarket$Direction[Smarket$Year==2005])
length(Smarket$Year) - length(Smarket$Direction[Smarket$Year==2005])
length(Smarket$Year) - length(Smarket$Direction[Smarket$Year==2005]) + 1
len(Smarket)
length(Smarket)
rdesc = makeResampleDesc("Holdout")
rdesc
start = length(Smarket$Year) - length(Smarket$Direction[Smarket$Year==2005]) + 1
end = length(Smarket$Year)
rin = makeFixedHoldoutInstance(train.inds=1:start-1, test.Inds=start:end, size=end)
rin
?makeFixedHoldoutInstance
rdesc = makeResampleDesc("Holdout")
rdesc
start = length(Smarket$Year) - length(Smarket$Direction[Smarket$Year==2005]) + 1
end = length(Smarket$Year)
rin = makeFixedHoldoutInstance(train.inds=1:(start-1), test.inds=start:end, size=end)
rin
str(rdesc)
?resample
?benchmark
listMeasures(task)
rm(list = ls())
task = makeClassifTask(id="Smarket", data=subset(Smarket, select=c(Lag1,Lag2,Direction)), positive="Up", target="Direction")
task
glm.lrn = makeLearner("classif.binomial")
glm.lrn
## lda
lda.lrn = makeLearner("classif.lda")
lda.lrn
## qda
qda.lrn = makeLearner("classif.qda")
qda.lrn
## knn
knn.lrn = makeLearner("classif.knn", par.vals=list(k=3)) # set hyper parameter
knn.lrn
start = length(Smarket$Year) - length(Smarket$Direction[Smarket$Year==2005]) + 1
end = length(Smarket$Year)
rin = makeFixedHoldoutInstance(train.inds=1:(start-1), test.inds=start:end, size=end)
rin
tasks = list(task)
learners = list(glm.lrn, lda.lrn, qda.lrn, knn.lrn)
resamplings = list(rin) # [(list of) ResampleDesc | ResampleInstance]
res = benchmark(learners=lrns, tasks=tasks, resamplings=rin, measures="mmce")
res
res = benchmark(learners=learners, tasks=tasks, resamplings=resamplings, measures="mmce")
res
res = benchmark(learners=learners, tasks=tasks, resamplings=resamplings, measures=list("mmce"))
res = benchmark(learners=learners, tasks=tasks, resamplings=resamplings)
res
rm(list = ls())
library(ISLR)
library(MASS) # lda/qda
library(class) # knn
library(mlr)
## use only Lag1 and Lag2 as features / Direction as response
str(Smarket)
#### ISLR
## glm
# test on Year == 2005
glm.fit = glm(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), family=binomial, subset=Smarket$Year!=2005)
glm.probs = predict(glm.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)), type="response")
glm.pred = sapply(glm.probs, function(p) { ifelse(p>.5,"Up","Down") })
glm.cm = table(data.frame(response=glm.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
glm.mmce = 1 - sum(diag(glm.cm)) / sum(glm.cm)
# keep output
model = c("glm")
hyper = c(NA)
mmce = c(glm.mmce)
## lda
lda.fit = lda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
lda.pred = predict(lda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
lda.cm = table(data.frame(response=lda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
lda.mmce = 1 - sum(diag(lda.cm)) / sum(lda.cm)
# keep output
model = c(model,"lda")
hyper = c(hyper, NA)
mmce = c(mmce, lda.mmce)
## qda
qda.fit = qda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
qda.pred = predict(qda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
qda.cm = table(data.frame(response=qda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
qda.mmce = 1 - sum(diag(qda.cm)) / sum(qda.cm)
# keep output
model = c(model,"qda")
hyper = c(hyper, NA)
mmce = c(mmce, qda.mmce)
## knn
k = 3 # hyper (or tuning) parameter set to be 3
knn.feat.train = subset(Smarket, Year!=2005, select=c(Lag1,Lag2))
knn.feat.test = subset(Smarket, Year==2005, select=c(Lag1,Lag2))
knn.resp.train = subset(Smarket, Year!=2005, select=c(Direction), drop=TRUE) # should be factors
knn.pred = knn(train=knn.feat.train, test=knn.feat.test, cl=knn.resp.train, k=k)
knn.cm = table(data.frame(response=knn.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
knn.mmce = 1 - sum(diag(knn.cm)) / sum(knn.cm)
# keep output
model = c(model,"knn")
hyper = c(hyper,3)
mmce = c(mmce,knn.mmce)
## consolidate output
output = data.frame(model=model, hyper=hyper, mmce=mmce)
output
#### MLR
### task
task = makeClassifTask(id="Smarket", data=subset(Smarket, select=c(Lag1,Lag2,Direction)), positive="Up", target="Direction")
task
### learner
## no need to set up learner if kept default setup
## glm
glm.lrn = makeLearner("classif.binomial")
glm.lrn
## lda
lda.lrn = makeLearner("classif.lda")
lda.lrn
## qda
qda.lrn = makeLearner("classif.qda")
qda.lrn
## knn
knn.lrn = makeLearner("classif.knn", par.vals=list(k=3)) # set hyper parameter
knn.lrn
### resampling - holdout validation
start = length(Smarket$Year) - length(Smarket$Direction[Smarket$Year==2005]) + 1
end = length(Smarket$Year)
rin = makeFixedHoldoutInstance(train.inds=1:(start-1), test.inds=start:end, size=end)
rin
### benchmark
tasks = list(task)
learners = list(glm.lrn, lda.lrn, qda.lrn, knn.lrn)
resamplings = list(rin) # [(list of) ResampleDesc | ResampleInstance]
# default measure for classification - mean misclassification error
# check available measures - listMeasures(task.name)
res = benchmark(learners=learners, tasks=tasks, resamplings=resamplings)
res
output
rdesc = makeResampleDesc("CV", iters=10)
rdesc
resamplings = list(rin, rdesc)
res = benchmark(learners=learners, tasks=tasks, resamplings=resamplings)
res
resamplings = list(rdesc)
res = benchmark(learners=learners, tasks=tasks, resamplings=resamplings)
res
rm(list = ls())
library(ISLR)
library(MASS) # lda/qda
library(class) # knn
library(mlr)
## use only Lag1 and Lag2 as features / Direction as response
str(Smarket)
#### ISLR
## glm
# test on Year == 2005
glm.fit = glm(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), family=binomial, subset=Smarket$Year!=2005)
glm.probs = predict(glm.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)), type="response")
glm.pred = sapply(glm.probs, function(p) { ifelse(p>.5,"Up","Down") })
glm.cm = table(data.frame(response=glm.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
glm.mmce = 1 - sum(diag(glm.cm)) / sum(glm.cm)
# keep output
model = c("glm")
hyper = c(NA)
mmce = c(glm.mmce)
## lda
lda.fit = lda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
lda.pred = predict(lda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
lda.cm = table(data.frame(response=lda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
lda.mmce = 1 - sum(diag(lda.cm)) / sum(lda.cm)
# keep output
model = c(model,"lda")
hyper = c(hyper, NA)
mmce = c(mmce, lda.mmce)
## qda
qda.fit = qda(Direction ~ ., data=subset(Smarket, select=c(Lag1,Lag2,Direction)), subset=Smarket$Year!=2005)
qda.pred = predict(qda.fit, subset(Smarket, Year==2005, select=c(Lag1,Lag2,Direction)))$class
qda.cm = table(data.frame(response=qda.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
qda.mmce = 1 - sum(diag(qda.cm)) / sum(qda.cm)
# keep output
model = c(model,"qda")
hyper = c(hyper, NA)
mmce = c(mmce, qda.mmce)
## knn
k = 3 # hyper (or tuning) parameter set to be 3
knn.feat.train = subset(Smarket, Year!=2005, select=c(Lag1,Lag2))
knn.feat.test = subset(Smarket, Year==2005, select=c(Lag1,Lag2))
knn.resp.train = subset(Smarket, Year!=2005, select=c(Direction), drop=TRUE) # should be factors
knn.pred = knn(train=knn.feat.train, test=knn.feat.test, cl=knn.resp.train, k=k)
knn.cm = table(data.frame(response=knn.pred, truth=subset(Smarket, Year==2005, select=c("Direction"))))
knn.mmce = 1 - sum(diag(knn.cm)) / sum(knn.cm)
# keep output
model = c(model,"knn")
hyper = c(hyper,3)
mmce = c(mmce,knn.mmce)
## consolidate output
holdout.res = data.frame(model=model, hyper=hyper, mmce=mmce)
#### MLR
### task
task = makeClassifTask(id="Smarket", data=subset(Smarket, select=c(Lag1,Lag2,Direction)), positive="Up", target="Direction")
task
### learner
## no need to set up learner if kept default setup
## glm
glm.lrn = makeLearner("classif.binomial")
glm.lrn
## lda
lda.lrn = makeLearner("classif.lda")
lda.lrn
## qda
qda.lrn = makeLearner("classif.qda")
qda.lrn
## knn
knn.lrn = makeLearner("classif.knn", par.vals=list(k=3)) # set hyper parameter
knn.lrn
### resampling
# for holdout validation, resampling instance can be specified
start = length(Smarket$Year) - length(Smarket$Direction[Smarket$Year==2005]) + 1
end = length(Smarket$Year)
rin = makeFixedHoldoutInstance(train.inds=1:(start-1), test.inds=start:end, size=end)
rin
# for others, resampling description can be created
rdesc = makeResampleDesc("CV", iters=10)
rdesc
### benchmark
tasks = list(task)
learners = list(glm.lrn, lda.lrn, qda.lrn, knn.lrn)
holdout.resample = list(rin)
cv.resample = list(rdesc)
# default measure for classification - mean misclassification error
# check available measures - listMeasures(task.name)
mlr.holdout.res = benchmark(learners=learners, tasks=tasks, resamplings=holdout.resample)
mlr.cv.res = benchmark(learners=learners, tasks=tasks, resamplings=cv.resample)
### ISLR - holdout validation
holdout.res
### MLR - holdout validation
mlr.holdout.res
### MLR - 10-fold cross validation
mlr.cv.res
rm(list = ls())
source("src/knitSrc.R")
knitPost("2015-01-18-Second-Look-on-MLR")
rm(list=ls())
source("src/knitSrc.R")
knitPost("2015-01-18-Second-Look-on-MLR")
source("src/knitSrc.R")
knitPost("2015-01-18-Learning-Scala-Ch5")
source("src/knitSrc.R")
knitPost("2015-01-18-Learning-Scala-Ch5")
library(kerlab)
library(kernlab)
?svm
library(caret)
?GermanCredit
?sigest
source("src/knitSrc.R")
knitPost("2015-01-24-Benchmark-Example-in-MLR-Part-I")
source("src/knitSrc.R")
knitPost("2015-01-26-Benchmark-Example-in-MLR-Part-II")
source("src/knitSrc.R")
knitPost("2015-01-26-Benchmark-Example-in-MLR-Part-II")
source("src/knitSrc.R")
knitPost("2015-01-26-Benchmark-Example-in-MLR-Part-II")
install.packages("rpart")
install.packages("doMC")
install.packages("doMC")
demo()
?install.packages
source("src/knitSrc.R")
knitPost("2015-02-01-Tree-Based-Methods-Part-I")
prp(fit.cl
,main="CART Model Tree"
,extra=106           # display prob of survival and percent of obs
,nn=TRUE             # display the node numbers
,fallen.leaves=TRUE  # put the leaves on the bottom of the page
,branch=.5           # change angle of branch lines
,faclen=0            # do not abbreviate factor levels
,trace=1             # print the automatically calculated cex
,shadow.col="gray"   # shadows under the leaves
,branch.lty=3        # draw branches using dotted lines
,split.cex=1.2       # make the split text larger than the node text
,split.prefix="is "  # put "is " before split text
,split.suffix="?"    # put "?" after split text
,col=cols, border.col=cols   # green if survived
,split.box.col="lightgray"   # lightgray split boxes (default is white)
,split.border.col="darkgray" # darkgray border on split boxes
,split.round=.5)
source("src/knitSrc.R")
knitPost("2015-02-01-Tree-Based-Methods-Part-I")
